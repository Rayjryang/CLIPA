nohup: ignoring input
2024-01-28 06:57:31.231903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-28 06:57:31.865019: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-28 06:57:31.865142: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-28 06:57:31.865157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-01-28 06:57:34.336278: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-28 06:57:34.336345: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
I0128 06:57:37.387363 139849920552000 flexi_main.py:90] [33mHello from process 0 holding 8/8 devices and writing to workdir gs://lxh_jaxtpu_eu_ckpt/jinruiyang_ckpt/clipa/tpu-v3-128-pod-vm-spot-flexivit-b16-debug.[0m
[nltk_data] Downloading package punkt to /home/jyang347/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/jyang347/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
I0128 06:57:37.803187 139849920552000 flexi_main.py:120] [33mNOTE[0m: Initializing...
I0128 06:57:37.804683 139849920552000 flexi_main.py:120] [33mNOTE[0m: Global batch size 16 on 1 hosts results in 16 local batch size. With 8 dev per host (8 dev total), that's a 2 per-device batch size.
I0128 06:57:37.911741 139849920552000 flexi_main.py:120] [33mNOTE[0m: Initializing train dataset...
I0128 06:57:38.333107 139849920552000 dataset_info.py:566] Load dataset info from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0128 06:57:40.599086 139849920552000 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0128 06:57:41.916854 139849920552000 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
I0128 06:57:41.996708 139849920552000 logging_logger.py:49] Constructing tf.data.Dataset laion400m for split _EvenSplit(split='full-filter', index=0, count=1, drop_remainder=False), from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0128 06:57:47.828979 139849920552000 api.py:459] Data before pre-processing:
{'LICENSE': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'NSFW': <tf.Tensor 'args_1:0' shape=() dtype=string>, 'caption': <tf.Tensor 'args_2:0' shape=() dtype=string>, 'error_message': <tf.Tensor 'args_3:0' shape=() dtype=string>, 'exif': <tf.Tensor 'args_4:0' shape=() dtype=string>, 'height': <tf.Tensor 'args_5:0' shape=() dtype=int64>, 'jpg': <tf.Tensor 'args_6:0' shape=(None, None, 3) dtype=uint8>, 'key': <tf.Tensor 'args_7:0' shape=() dtype=string>, 'original_height': <tf.Tensor 'args_8:0' shape=() dtype=int64>, 'original_width': <tf.Tensor 'args_9:0' shape=() dtype=int64>, 'sha256': <tf.Tensor 'args_10:0' shape=() dtype=string>, 'status': <tf.Tensor 'args_11:0' shape=() dtype=string>, 'txt': <tf.Tensor 'args_13:0' shape=() dtype=string>, 'url': <tf.Tensor 'args_14:0' shape=() dtype=string>, 'width': <tf.Tensor 'args_15:0' shape=() dtype=int64>, 'tfds_id': <tf.Tensor 'args_12:0' shape=() dtype=string>}
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0128 06:57:47.968671 139849920552000 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
/tmp/__autograph_generated_filetllkark9.py:11: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  ag__.converted_call(ag__.ld(warnings).warn, (f'jax.{ag__.ld(f).__name__} is deprecated, and will be removed in a future release. Use jax.tree_util.{ag__.ld(f).__name__} instead.',), dict(category=ag__.ld(FutureWarning), stacklevel=2), fscope)
I0128 06:57:49.681067 139849920552000 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'Cast:0' shape=(240, 240, 3) dtype=uint8>, 'labels': <tf.Tensor 'cond/Identity:0' shape=(16,) dtype=int32>}
I0128 06:57:49.995800 139849920552000 flexi_main.py:120] [33mNOTE[0m: Running for 114716000 steps, that means 7.000000 epochs
I0128 06:57:49.996056 139849920552000 flexi_main.py:120] [33mNOTE[0m: Initializing two_towers model...
W0128 06:57:50.164598 139849920552000 checkpoints.py:55] GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.
I0128 06:58:32.804455 139849920552000 utils.py:844] [35m[0][0m z/secs/init = 42.66192595695611
I0128 06:58:32.804936 139849920552000 utils.py:427] TIMING[z/secs/init]: 42.66192595695611
/home/jyang347/CLIPA/clipa_jax/flexi_main.py:252: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  num_params = sum(p.size for p in jax.tree_leaves(params_cpu))
I0128 06:58:33.089304 139849920552000 parameter_overview.py:264] 
init params
+-----------------------------------------------------------------------------+----------------+------------+-----------+----------+
| Name                                                                        | Shape          | Size       | Mean      | Std      |
+-----------------------------------------------------------------------------+----------------+------------+-----------+----------+
| img/Transformer/encoder_norm/bias                                           | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoder_norm/scale                                          | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_0/LayerNorm_0/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_0/LayerNorm_0/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_0/LayerNorm_1/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_0/LayerNorm_1/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias                      | (3072,)        | 3,072      | -3.38e-08 | 9.75e-07 |
| img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel                    | (768, 3072)    | 2,359,296  | -6.72e-06 | 0.0228   |
| img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias                      | (768,)         | 768        | -1.79e-09 | 1.01e-06 |
| img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel                    | (3072, 768)    | 2,359,296  | 2.95e-05  | 0.0228   |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias      | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel    | (768, 12, 64)  | 589,824    | -1.04e-05 | 0.0361   |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias      | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel    | (12, 64, 768)  | 589,824    | 3.53e-05  | 0.0361   |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel  | (768, 12, 64)  | 589,824    | 3.68e-05  | 0.0361   |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel  | (768, 12, 64)  | 589,824    | -4.72e-05 | 0.0361   |
| img/Transformer/encoderblock_1/LayerNorm_0/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_1/LayerNorm_0/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_1/LayerNorm_1/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_1/LayerNorm_1/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias                      | (3072,)        | 3,072      | -2.27e-10 | 1e-06    |
| img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel                    | (768, 3072)    | 2,359,296  | 7.57e-06  | 0.0228   |
| img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias                      | (768,)         | 768        | -5.43e-08 | 1e-06    |
| img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel                    | (3072, 768)    | 2,359,296  | -1.13e-05 | 0.0228   |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias      | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel    | (768, 12, 64)  | 589,824    | -2.07e-05 | 0.0361   |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias      | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel    | (12, 64, 768)  | 589,824    | -3.42e-05 | 0.0361   |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel  | (768, 12, 64)  | 589,824    | -6.93e-05 | 0.0361   |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel  | (768, 12, 64)  | 589,824    | -5.87e-05 | 0.0361   |
| img/Transformer/encoderblock_10/LayerNorm_0/bias                            | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_10/LayerNorm_0/scale                           | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_10/LayerNorm_1/bias                            | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_10/LayerNorm_1/scale                           | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias                     | (3072,)        | 3,072      | 1.1e-08   | 1e-06    |
| img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel                   | (768, 3072)    | 2,359,296  | -4.03e-05 | 0.0228   |
| img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias                     | (768,)         | 768        | 2.8e-08   | 9.93e-07 |
| img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel                   | (3072, 768)    | 2,359,296  | -5.91e-06 | 0.0228   |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias     | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel   | (768, 12, 64)  | 589,824    | 1.24e-05  | 0.0361   |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias     | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel   | (12, 64, 768)  | 589,824    | 9.98e-06  | 0.0361   |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias   | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel | (768, 12, 64)  | 589,824    | 4.96e-05  | 0.0361   |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias   | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel | (768, 12, 64)  | 589,824    | -4.86e-05 | 0.036    |
| img/Transformer/encoderblock_11/LayerNorm_0/bias                            | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_11/LayerNorm_0/scale                           | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_11/LayerNorm_1/bias                            | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_11/LayerNorm_1/scale                           | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias                     | (3072,)        | 3,072      | 2.22e-08  | 9.96e-07 |
| img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel                   | (768, 3072)    | 2,359,296  | 1.6e-05   | 0.0228   |
| img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias                     | (768,)         | 768        | 4.45e-08  | 9.78e-07 |
| img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel                   | (3072, 768)    | 2,359,296  | 7.8e-06   | 0.0228   |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias     | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel   | (768, 12, 64)  | 589,824    | -3.21e-05 | 0.0361   |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias     | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel   | (12, 64, 768)  | 589,824    | -2.72e-05 | 0.0361   |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias   | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel | (768, 12, 64)  | 589,824    | -1.56e-05 | 0.0361   |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias   | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel | (768, 12, 64)  | 589,824    | 3.44e-05  | 0.0361   |
| img/Transformer/encoderblock_2/LayerNorm_0/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_2/LayerNorm_0/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_2/LayerNorm_1/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_2/LayerNorm_1/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias                      | (3072,)        | 3,072      | 2.5e-08   | 9.92e-07 |
| img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel                    | (768, 3072)    | 2,359,296  | 1.01e-05  | 0.0228   |
| img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias                      | (768,)         | 768        | 1.23e-08  | 1.03e-06 |
| img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel                    | (3072, 768)    | 2,359,296  | 5.56e-06  | 0.0228   |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias      | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel    | (768, 12, 64)  | 589,824    | -3.56e-05 | 0.0361   |
I0128 06:58:33.089565 139849920552000 parameter_overview.py:264] 
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias      | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel    | (12, 64, 768)  | 589,824    | 3.68e-05  | 0.0361   |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel  | (768, 12, 64)  | 589,824    | 5.17e-06  | 0.0361   |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel  | (768, 12, 64)  | 589,824    | -4.86e-05 | 0.0361   |
| img/Transformer/encoderblock_3/LayerNorm_0/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_3/LayerNorm_0/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_3/LayerNorm_1/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_3/LayerNorm_1/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias                      | (3072,)        | 3,072      | -2.99e-10 | 1e-06    |
| img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel                    | (768, 3072)    | 2,359,296  | 7.05e-06  | 0.0228   |
| img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias                      | (768,)         | 768        | -4.96e-08 | 9.94e-07 |
| img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel                    | (3072, 768)    | 2,359,296  | 8.92e-06  | 0.0228   |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias      | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel    | (768, 12, 64)  | 589,824    | 1.85e-06  | 0.0361   |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias      | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel    | (12, 64, 768)  | 589,824    | 1.2e-05   | 0.0361   |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel  | (768, 12, 64)  | 589,824    | -1.63e-05 | 0.0361   |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel  | (768, 12, 64)  | 589,824    | -8.69e-05 | 0.036    |
| img/Transformer/encoderblock_4/LayerNorm_0/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_4/LayerNorm_0/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_4/LayerNorm_1/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_4/LayerNorm_1/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias                      | (3072,)        | 3,072      | -4.4e-09  | 9.98e-07 |
| img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel                    | (768, 3072)    | 2,359,296  | -5.64e-06 | 0.0228   |
| img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias                      | (768,)         | 768        | 5.12e-09  | 1.02e-06 |
| img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel                    | (3072, 768)    | 2,359,296  | -3.41e-05 | 0.0228   |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias      | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel    | (768, 12, 64)  | 589,824    | 5.01e-05  | 0.0361   |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias      | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel    | (12, 64, 768)  | 589,824    | -5.61e-05 | 0.0361   |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel  | (768, 12, 64)  | 589,824    | 1.29e-05  | 0.0361   |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel  | (768, 12, 64)  | 589,824    | 3.39e-05  | 0.0361   |
| img/Transformer/encoderblock_5/LayerNorm_0/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_5/LayerNorm_0/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_5/LayerNorm_1/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_5/LayerNorm_1/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias                      | (3072,)        | 3,072      | 4.46e-10  | 1.03e-06 |
| img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel                    | (768, 3072)    | 2,359,296  | 1.26e-05  | 0.0228   |
| img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias                      | (768,)         | 768        | 5.08e-09  | 1.03e-06 |
| img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel                    | (3072, 768)    | 2,359,296  | 1.85e-05  | 0.0228   |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias      | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel    | (768, 12, 64)  | 589,824    | -0.000142 | 0.0361   |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias      | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel    | (12, 64, 768)  | 589,824    | -4.05e-05 | 0.0361   |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel  | (768, 12, 64)  | 589,824    | 5.09e-05  | 0.0361   |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel  | (768, 12, 64)  | 589,824    | 1.98e-05  | 0.036    |
| img/Transformer/encoderblock_6/LayerNorm_0/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_6/LayerNorm_0/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_6/LayerNorm_1/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_6/LayerNorm_1/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias                      | (3072,)        | 3,072      | -6.91e-10 | 9.98e-07 |
| img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel                    | (768, 3072)    | 2,359,296  | -5.17e-06 | 0.0228   |
| img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias                      | (768,)         | 768        | 7.58e-08  | 9.69e-07 |
| img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel                    | (3072, 768)    | 2,359,296  | -3.71e-08 | 0.0228   |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias      | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel    | (768, 12, 64)  | 589,824    | 5.95e-05  | 0.0361   |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias      | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel    | (12, 64, 768)  | 589,824    | 0.00011   | 0.0361   |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel  | (768, 12, 64)  | 589,824    | -5.99e-05 | 0.0361   |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel  | (768, 12, 64)  | 589,824    | -2.43e-05 | 0.0361   |
| img/Transformer/encoderblock_7/LayerNorm_0/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_7/LayerNorm_0/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_7/LayerNorm_1/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_7/LayerNorm_1/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias                      | (3072,)        | 3,072      | 3.68e-09  | 1.01e-06 |
| img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel                    | (768, 3072)    | 2,359,296  | -1.89e-06 | 0.0228   |
| img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias                      | (768,)         | 768        | 6.46e-08  | 9.97e-07 |
| img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel                    | (3072, 768)    | 2,359,296  | 1.54e-05  | 0.0228   |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias      | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel    | (768, 12, 64)  | 589,824    | 2.41e-05  | 0.0361   |
I0128 06:58:33.089644 139849920552000 parameter_overview.py:264] 
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias      | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel    | (12, 64, 768)  | 589,824    | -2.31e-05 | 0.0361   |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel  | (768, 12, 64)  | 589,824    | 1.81e-05  | 0.0361   |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel  | (768, 12, 64)  | 589,824    | -2.96e-05 | 0.0361   |
| img/Transformer/encoderblock_8/LayerNorm_0/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_8/LayerNorm_0/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_8/LayerNorm_1/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_8/LayerNorm_1/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias                      | (3072,)        | 3,072      | -1.89e-08 | 1e-06    |
| img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel                    | (768, 3072)    | 2,359,296  | 5.25e-06  | 0.0228   |
| img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias                      | (768,)         | 768        | -2.66e-08 | 9.95e-07 |
| img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel                    | (3072, 768)    | 2,359,296  | 7.32e-06  | 0.0228   |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias      | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel    | (768, 12, 64)  | 589,824    | -3.92e-05 | 0.0361   |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias      | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel    | (12, 64, 768)  | 589,824    | 2.95e-05  | 0.0361   |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel  | (768, 12, 64)  | 589,824    | 8.9e-05   | 0.0361   |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel  | (768, 12, 64)  | 589,824    | -6.7e-05  | 0.036    |
| img/Transformer/encoderblock_9/LayerNorm_0/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_9/LayerNorm_0/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_9/LayerNorm_1/bias                             | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_9/LayerNorm_1/scale                            | (768,)         | 768        | 1.0       | 0.0      |
| img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias                      | (3072,)        | 3,072      | 8.53e-10  | 9.96e-07 |
| img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel                    | (768, 3072)    | 2,359,296  | -3.04e-06 | 0.0228   |
| img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias                      | (768,)         | 768        | -3.95e-08 | 1e-06    |
| img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel                    | (3072, 768)    | 2,359,296  | -3.31e-06 | 0.0228   |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias      | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel    | (768, 12, 64)  | 589,824    | 3.72e-05  | 0.0361   |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias      | (768,)         | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel    | (12, 64, 768)  | 589,824    | -1.82e-05 | 0.0361   |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel  | (768, 12, 64)  | 589,824    | 3.77e-05  | 0.0361   |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias    | (12, 64)       | 768        | 0.0       | 0.0      |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel  | (768, 12, 64)  | 589,824    | 2.15e-05  | 0.036    |
| img/cls                                                                     | (1, 1, 768)    | 768        | 0.0       | 0.0      |
| img/embedding/bias                                                          | (768,)         | 768        | 0.0       | 0.0      |
| img/embedding/kernel                                                        | (8, 8, 3, 768) | 147,456    | -0.000105 | 0.0361   |
| img/head/bias                                                               | (512,)         | 512        | 0.0       | 0.0      |
| img/head/kernel                                                             | (768, 512)     | 393,216    | -3.4e-05  | 0.0361   |
| img/pos_embedding                                                           | (1, 49, 768)   | 37,632     | 0.000381  | 0.0361   |
| t                                                                           | (1,)           | 1          | 2.66      | 0.0      |
| txt/Embed_0/embedding                                                       | (32000, 512)   | 16,384,000 | 4e-06     | 0.02     |
| txt/Transformer/encoderblock_0/LayerNorm_0/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_0/LayerNorm_0/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_0/LayerNorm_1/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_0/LayerNorm_1/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias                      | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel                    | (512, 2048)    | 1,048,576  | 2.28e-05  | 0.0313   |
| txt/Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias                      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel                    | (2048, 512)    | 1,048,576  | -6.61e-06 | 0.00902  |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias      | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)   | 262,144    | -5.43e-05 | 0.0442   |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)   | 262,144    | 4.5e-06   | 0.00903  |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)   | 262,144    | 2.26e-05  | 0.0442   |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)   | 262,144    | 3.43e-05  | 0.0442   |
| txt/Transformer/encoderblock_1/LayerNorm_0/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_1/LayerNorm_0/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_1/LayerNorm_1/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_1/LayerNorm_1/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias                      | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel                    | (512, 2048)    | 1,048,576  | 2.36e-06  | 0.0313   |
| txt/Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias                      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel                    | (2048, 512)    | 1,048,576  | 2.28e-06  | 0.00902  |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias      | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)   | 262,144    | 7.03e-05  | 0.0442   |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)   | 262,144    | -1.81e-05 | 0.00902  |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)   | 262,144    | 4.3e-06   | 0.0441   |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)   | 262,144    | 5.16e-05  | 0.0441   |
| txt/Transformer/encoderblock_10/LayerNorm_0/bias                            | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_10/LayerNorm_0/scale                           | (512,)         | 512        | 1.0       | 0.0      |
I0128 06:58:33.089712 139849920552000 parameter_overview.py:264] 
| txt/Transformer/encoderblock_10/LayerNorm_1/bias                            | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_10/LayerNorm_1/scale                           | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias                     | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel                   | (512, 2048)    | 1,048,576  | -9.68e-06 | 0.0312   |
| txt/Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias                     | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel                   | (2048, 512)    | 1,048,576  | -7.3e-06  | 0.00901  |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias     | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel   | (512, 8, 64)   | 262,144    | 2.7e-05   | 0.0442   |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias     | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel   | (8, 64, 512)   | 262,144    | -7.14e-06 | 0.00903  |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias   | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel | (512, 8, 64)   | 262,144    | 3.06e-05  | 0.0441   |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias   | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel | (512, 8, 64)   | 262,144    | -0.000111 | 0.0442   |
| txt/Transformer/encoderblock_11/LayerNorm_0/bias                            | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_11/LayerNorm_0/scale                           | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_11/LayerNorm_1/bias                            | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_11/LayerNorm_1/scale                           | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias                     | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel                   | (512, 2048)    | 1,048,576  | -2.45e-05 | 0.0313   |
| txt/Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias                     | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel                   | (2048, 512)    | 1,048,576  | 5.18e-06  | 0.00901  |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias     | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel   | (512, 8, 64)   | 262,144    | 2.29e-05  | 0.0441   |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias     | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel   | (8, 64, 512)   | 262,144    | 8.92e-06  | 0.00904  |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias   | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel | (512, 8, 64)   | 262,144    | -0.000123 | 0.0442   |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias   | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel | (512, 8, 64)   | 262,144    | 0.000117  | 0.0442   |
| txt/Transformer/encoderblock_2/LayerNorm_0/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_2/LayerNorm_0/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_2/LayerNorm_1/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_2/LayerNorm_1/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias                      | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel                    | (512, 2048)    | 1,048,576  | 1.85e-05  | 0.0312   |
| txt/Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias                      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel                    | (2048, 512)    | 1,048,576  | 1.13e-05  | 0.00902  |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias      | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)   | 262,144    | 2.76e-05  | 0.0441   |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)   | 262,144    | 1.78e-05  | 0.00902  |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)   | 262,144    | 8.18e-05  | 0.0442   |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)   | 262,144    | -1.15e-05 | 0.0443   |
| txt/Transformer/encoderblock_3/LayerNorm_0/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_3/LayerNorm_0/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_3/LayerNorm_1/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_3/LayerNorm_1/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias                      | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel                    | (512, 2048)    | 1,048,576  | 2.61e-05  | 0.0312   |
| txt/Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias                      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel                    | (2048, 512)    | 1,048,576  | -1.15e-05 | 0.00903  |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias      | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)   | 262,144    | -3.85e-05 | 0.0443   |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)   | 262,144    | 1.74e-05  | 0.00902  |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)   | 262,144    | -8.37e-05 | 0.0441   |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)   | 262,144    | -0.000173 | 0.0444   |
| txt/Transformer/encoderblock_4/LayerNorm_0/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_4/LayerNorm_0/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_4/LayerNorm_1/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_4/LayerNorm_1/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias                      | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel                    | (512, 2048)    | 1,048,576  | 7.67e-05  | 0.0313   |
| txt/Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias                      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel                    | (2048, 512)    | 1,048,576  | 9.1e-06   | 0.00901  |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias      | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)   | 262,144    | 4.27e-05  | 0.0444   |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)   | 262,144    | 1.37e-05  | 0.00902  |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)   | 262,144    | 0.000109  | 0.0441   |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)   | 262,144    | -0.000132 | 0.0441   |
| txt/Transformer/encoderblock_5/LayerNorm_0/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_5/LayerNorm_0/scale                            | (512,)         | 512        | 1.0       | 0.0      |
I0128 06:58:33.089771 139849920552000 parameter_overview.py:264] 
| txt/Transformer/encoderblock_5/LayerNorm_1/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_5/LayerNorm_1/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias                      | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel                    | (512, 2048)    | 1,048,576  | 4.78e-05  | 0.0312   |
| txt/Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias                      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel                    | (2048, 512)    | 1,048,576  | -5.45e-06 | 0.00903  |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias      | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)   | 262,144    | -0.000206 | 0.0442   |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)   | 262,144    | -3.86e-06 | 0.00901  |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)   | 262,144    | 2.11e-05  | 0.0442   |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)   | 262,144    | 2.62e-05  | 0.0442   |
| txt/Transformer/encoderblock_6/LayerNorm_0/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_6/LayerNorm_0/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_6/LayerNorm_1/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_6/LayerNorm_1/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias                      | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel                    | (512, 2048)    | 1,048,576  | -6.34e-05 | 0.0313   |
| txt/Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias                      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel                    | (2048, 512)    | 1,048,576  | -6.81e-06 | 0.00903  |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias      | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)   | 262,144    | 7.69e-05  | 0.0442   |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)   | 262,144    | -8.59e-06 | 0.00902  |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)   | 262,144    | -2.12e-05 | 0.0443   |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)   | 262,144    | -7.48e-05 | 0.0442   |
| txt/Transformer/encoderblock_7/LayerNorm_0/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_7/LayerNorm_0/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_7/LayerNorm_1/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_7/LayerNorm_1/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias                      | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel                    | (512, 2048)    | 1,048,576  | -2.7e-05  | 0.0312   |
| txt/Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias                      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel                    | (2048, 512)    | 1,048,576  | 9.78e-06  | 0.00902  |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias      | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)   | 262,144    | 4.24e-05  | 0.0442   |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)   | 262,144    | -7.1e-06  | 0.00903  |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)   | 262,144    | -7.34e-05 | 0.0443   |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)   | 262,144    | -4.52e-05 | 0.0442   |
| txt/Transformer/encoderblock_8/LayerNorm_0/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_8/LayerNorm_0/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_8/LayerNorm_1/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_8/LayerNorm_1/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias                      | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel                    | (512, 2048)    | 1,048,576  | 2.52e-05  | 0.0313   |
| txt/Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias                      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel                    | (2048, 512)    | 1,048,576  | -6.68e-06 | 0.00902  |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias      | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)   | 262,144    | -2.64e-05 | 0.0442   |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)   | 262,144    | 1.66e-05  | 0.00902  |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)   | 262,144    | 6.85e-05  | 0.0442   |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)   | 262,144    | 4.4e-05   | 0.0442   |
| txt/Transformer/encoderblock_9/LayerNorm_0/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_9/LayerNorm_0/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_9/LayerNorm_1/bias                             | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_9/LayerNorm_1/scale                            | (512,)         | 512        | 1.0       | 0.0      |
| txt/Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias                      | (2048,)        | 2,048      | 0.0       | 0.0      |
| txt/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel                    | (512, 2048)    | 1,048,576  | 3.33e-05  | 0.0313   |
| txt/Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias                      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel                    | (2048, 512)    | 1,048,576  | 1.11e-06  | 0.00902  |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias      | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)   | 262,144    | -2.11e-05 | 0.0442   |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias      | (512,)         | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)   | 262,144    | 1.05e-05  | 0.00904  |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)   | 262,144    | 1.34e-06  | 0.0442   |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias    | (8, 64)        | 512        | 0.0       | 0.0      |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)   | 262,144    | 4.68e-05  | 0.0442   |
| txt/encoder_norm/bias                                                       | (512,)         | 512        | 0.0       | 0.0      |
| txt/encoder_norm/scale                                                      | (512,)         | 512        | 1.0       | 0.0      |
I0128 06:58:33.089819 139849920552000 parameter_overview.py:264] 
| txt/head/kernel                                                             | (512, 512)     | 262,144    | 6.96e-05  | 0.0441   |
| txt/pos_embedding                                                           | (1, 16, 512)   | 8,192      | -3.76e-05 | 0.0101   |
+-----------------------------------------------------------------------------+----------------+------------+-----------+----------+
Total: 140,120,321
I0128 06:58:33.089937 139849920552000 utils.py:844] [35m[0][0m num_params = 140120321.0
I0128 06:58:33.090053 139849920552000 flexi_main.py:120] [33mNOTE[0m: Initializing scale_by_adam optimizer...
/home/jyang347/CLIPA/clipa_jax/helpers/utils.py:492: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  vals, tree_def = jax.tree_flatten(tree)
I0128 06:58:33.092514 139849920552000 utils.py:769] config.schedule: img/Transformer/encoder_norm/bias - matched by .*
I0128 06:58:33.092650 139849920552000 utils.py:769] config.schedule: img/Transformer/encoder_norm/scale - matched by .*
I0128 06:58:33.092705 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/LayerNorm_0/bias - matched by .*
I0128 06:58:33.092746 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/LayerNorm_0/scale - matched by .*
I0128 06:58:33.092783 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/LayerNorm_1/bias - matched by .*
I0128 06:58:33.092820 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/LayerNorm_1/scale - matched by .*
I0128 06:58:33.092865 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.092901 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.092936 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.092971 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.093006 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.093041 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.093075 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.093110 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.093144 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.093178 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.093212 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.093246 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.093280 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/LayerNorm_0/bias - matched by .*
I0128 06:58:33.093313 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/LayerNorm_0/scale - matched by .*
I0128 06:58:33.093347 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/LayerNorm_1/bias - matched by .*
I0128 06:58:33.093381 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/LayerNorm_1/scale - matched by .*
I0128 06:58:33.093416 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.093450 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.093483 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.093517 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.093552 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.093585 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.093619 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.093660 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.093695 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.093729 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.093763 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.093797 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.093832 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/LayerNorm_0/bias - matched by .*
I0128 06:58:33.093873 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/LayerNorm_0/scale - matched by .*
I0128 06:58:33.093908 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/LayerNorm_1/bias - matched by .*
I0128 06:58:33.093942 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/LayerNorm_1/scale - matched by .*
I0128 06:58:33.093976 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.094010 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.094044 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.094078 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.094112 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.094146 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.094180 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.094214 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.094247 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.094281 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.094316 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.094350 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.094384 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/LayerNorm_0/bias - matched by .*
I0128 06:58:33.094418 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/LayerNorm_0/scale - matched by .*
I0128 06:58:33.094452 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/LayerNorm_1/bias - matched by .*
I0128 06:58:33.094486 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/LayerNorm_1/scale - matched by .*
I0128 06:58:33.094520 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.094557 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.094600 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.094635 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.094670 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.094704 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.094738 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.094773 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.094807 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.094841 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.094883 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.094918 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.094967 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/LayerNorm_0/bias - matched by .*
I0128 06:58:33.095002 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/LayerNorm_0/scale - matched by .*
I0128 06:58:33.095036 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/LayerNorm_1/bias - matched by .*
I0128 06:58:33.095071 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/LayerNorm_1/scale - matched by .*
I0128 06:58:33.095105 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.095139 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.095174 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.095209 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.095243 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.095277 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.095311 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.095345 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.095380 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.095413 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.095450 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.095485 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.095520 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/LayerNorm_0/bias - matched by .*
I0128 06:58:33.095554 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/LayerNorm_0/scale - matched by .*
I0128 06:58:33.095599 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/LayerNorm_1/bias - matched by .*
I0128 06:58:33.095635 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/LayerNorm_1/scale - matched by .*
I0128 06:58:33.095669 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.095703 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.095738 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.095772 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.095807 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.095840 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.095880 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.095915 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.095949 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.095982 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.096016 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.096050 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.096084 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/LayerNorm_0/bias - matched by .*
I0128 06:58:33.096118 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/LayerNorm_0/scale - matched by .*
I0128 06:58:33.096151 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/LayerNorm_1/bias - matched by .*
I0128 06:58:33.096187 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/LayerNorm_1/scale - matched by .*
I0128 06:58:33.096222 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.096255 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.096289 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.096323 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.096357 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.096390 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.096424 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.096457 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.096491 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.096531 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.096565 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.096602 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.096636 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/LayerNorm_0/bias - matched by .*
I0128 06:58:33.096670 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/LayerNorm_0/scale - matched by .*
I0128 06:58:33.096704 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/LayerNorm_1/bias - matched by .*
I0128 06:58:33.096738 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/LayerNorm_1/scale - matched by .*
I0128 06:58:33.096772 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.096805 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.096839 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.096879 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.096913 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.096947 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.096981 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.097015 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.097048 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.097083 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.097117 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.097151 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.097185 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/LayerNorm_0/bias - matched by .*
I0128 06:58:33.097220 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/LayerNorm_0/scale - matched by .*
I0128 06:58:33.097254 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/LayerNorm_1/bias - matched by .*
I0128 06:58:33.097287 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/LayerNorm_1/scale - matched by .*
I0128 06:58:33.097321 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.097355 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.097388 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.097422 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.097470 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.097518 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.097554 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.097589 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.097623 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.097657 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.097691 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.097725 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.097759 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/LayerNorm_0/bias - matched by .*
I0128 06:58:33.097794 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/LayerNorm_0/scale - matched by .*
I0128 06:58:33.097828 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/LayerNorm_1/bias - matched by .*
I0128 06:58:33.097868 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/LayerNorm_1/scale - matched by .*
I0128 06:58:33.097903 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.097937 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.097970 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.098004 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.098037 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.098071 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.098105 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.098138 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.098172 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.098206 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.098240 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.098273 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.098307 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/LayerNorm_0/bias - matched by .*
I0128 06:58:33.098340 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/LayerNorm_0/scale - matched by .*
I0128 06:58:33.098374 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/LayerNorm_1/bias - matched by .*
I0128 06:58:33.098407 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/LayerNorm_1/scale - matched by .*
I0128 06:58:33.098441 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.098486 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.098522 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.098556 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.098593 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.098648 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.098689 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.098729 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.098769 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.098812 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.098863 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.098904 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.098957 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/LayerNorm_0/bias - matched by .*
I0128 06:58:33.098999 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/LayerNorm_0/scale - matched by .*
I0128 06:58:33.099039 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/LayerNorm_1/bias - matched by .*
I0128 06:58:33.099079 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/LayerNorm_1/scale - matched by .*
I0128 06:58:33.099119 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.099159 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.099200 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.099240 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.099280 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.099320 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.099360 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.099399 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.099439 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.099478 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.099518 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.099558 139849920552000 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.099608 139849920552000 utils.py:769] config.schedule: img/cls - matched by .*
I0128 06:58:33.099649 139849920552000 utils.py:769] config.schedule: img/embedding/bias - matched by .*
I0128 06:58:33.099690 139849920552000 utils.py:769] config.schedule: img/embedding/kernel - matched by .*
I0128 06:58:33.099730 139849920552000 utils.py:769] config.schedule: img/head/bias - matched by .*
I0128 06:58:33.099771 139849920552000 utils.py:769] config.schedule: img/head/kernel - matched by .*
I0128 06:58:33.099811 139849920552000 utils.py:769] config.schedule: img/pos_embedding - matched by .*
I0128 06:58:33.099858 139849920552000 utils.py:769] config.schedule: t - matched by .*
I0128 06:58:33.099899 139849920552000 utils.py:769] config.schedule: txt/Embed_0/embedding - matched by .*
I0128 06:58:33.099940 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/LayerNorm_0/bias - matched by .*
I0128 06:58:33.099980 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/LayerNorm_0/scale - matched by .*
I0128 06:58:33.100020 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/LayerNorm_1/bias - matched by .*
I0128 06:58:33.100060 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/LayerNorm_1/scale - matched by .*
I0128 06:58:33.100100 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.100140 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.100180 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.100219 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.100259 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.100299 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.100339 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.100379 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.100419 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.100462 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.100503 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.100543 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.100582 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/LayerNorm_0/bias - matched by .*
I0128 06:58:33.100622 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/LayerNorm_0/scale - matched by .*
I0128 06:58:33.100662 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/LayerNorm_1/bias - matched by .*
I0128 06:58:33.100702 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/LayerNorm_1/scale - matched by .*
I0128 06:58:33.100753 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.100787 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.100820 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.100864 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.100900 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.100934 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.100968 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.101001 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.101035 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.101068 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.101102 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.101135 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.101169 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/LayerNorm_0/bias - matched by .*
I0128 06:58:33.101202 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/LayerNorm_0/scale - matched by .*
I0128 06:58:33.101236 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/LayerNorm_1/bias - matched by .*
I0128 06:58:33.101270 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/LayerNorm_1/scale - matched by .*
I0128 06:58:33.101304 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.101337 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.101371 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.101404 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.101438 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.101471 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.101505 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.101539 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.101572 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.101606 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.101639 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.101672 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.101706 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/LayerNorm_0/bias - matched by .*
I0128 06:58:33.101739 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/LayerNorm_0/scale - matched by .*
I0128 06:58:33.101773 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/LayerNorm_1/bias - matched by .*
I0128 06:58:33.101814 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/LayerNorm_1/scale - matched by .*
I0128 06:58:33.101853 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.101888 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.101922 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.101956 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.101990 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.102023 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.102057 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.102091 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.102124 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.102158 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.102192 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.102226 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.102259 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/LayerNorm_0/bias - matched by .*
I0128 06:58:33.102293 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/LayerNorm_0/scale - matched by .*
I0128 06:58:33.102327 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/LayerNorm_1/bias - matched by .*
I0128 06:58:33.102360 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/LayerNorm_1/scale - matched by .*
I0128 06:58:33.102393 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.102427 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.102460 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.102494 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.102527 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.102561 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.102595 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.102628 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.102661 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.102694 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.102734 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.102769 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.102803 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/LayerNorm_0/bias - matched by .*
I0128 06:58:33.102837 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/LayerNorm_0/scale - matched by .*
I0128 06:58:33.102877 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/LayerNorm_1/bias - matched by .*
I0128 06:58:33.102911 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/LayerNorm_1/scale - matched by .*
I0128 06:58:33.102963 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.102998 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.103032 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.103066 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.103100 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.103136 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.103170 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.103204 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.103237 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.103272 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.103305 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.103339 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.103373 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/LayerNorm_0/bias - matched by .*
I0128 06:58:33.103407 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/LayerNorm_0/scale - matched by .*
I0128 06:58:33.103440 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/LayerNorm_1/bias - matched by .*
I0128 06:58:33.103474 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/LayerNorm_1/scale - matched by .*
I0128 06:58:33.103508 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.103542 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.103575 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.103609 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.103643 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.103676 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.103716 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.103750 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.103785 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.103818 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.103858 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.103893 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.103928 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/LayerNorm_0/bias - matched by .*
I0128 06:58:33.103961 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/LayerNorm_0/scale - matched by .*
I0128 06:58:33.103995 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/LayerNorm_1/bias - matched by .*
I0128 06:58:33.104029 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/LayerNorm_1/scale - matched by .*
I0128 06:58:33.104063 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.104097 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.104131 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.104165 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.104199 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.104233 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.104266 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.104300 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.104334 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.104368 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.104401 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.104435 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.104471 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/LayerNorm_0/bias - matched by .*
I0128 06:58:33.104505 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/LayerNorm_0/scale - matched by .*
I0128 06:58:33.104539 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/LayerNorm_1/bias - matched by .*
I0128 06:58:33.104573 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/LayerNorm_1/scale - matched by .*
I0128 06:58:33.104607 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.104640 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.104679 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.104714 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.104747 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.104781 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.104815 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.104854 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.104890 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.104924 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.104958 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.104991 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.105025 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/LayerNorm_0/bias - matched by .*
I0128 06:58:33.105058 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/LayerNorm_0/scale - matched by .*
I0128 06:58:33.105091 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/LayerNorm_1/bias - matched by .*
I0128 06:58:33.105125 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/LayerNorm_1/scale - matched by .*
I0128 06:58:33.105158 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.105191 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.105225 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.105258 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.105292 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.105326 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.105359 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.105392 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.105425 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.105459 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.105492 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.105525 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.105558 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/LayerNorm_0/bias - matched by .*
I0128 06:58:33.105596 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/LayerNorm_0/scale - matched by .*
I0128 06:58:33.105630 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/LayerNorm_1/bias - matched by .*
I0128 06:58:33.105664 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/LayerNorm_1/scale - matched by .*
I0128 06:58:33.105697 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.105731 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.105764 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.105798 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.105831 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.105872 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.105911 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.105945 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.105979 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.106013 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.106046 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.106080 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.106114 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/LayerNorm_0/bias - matched by .*
I0128 06:58:33.106148 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/LayerNorm_0/scale - matched by .*
I0128 06:58:33.106181 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/LayerNorm_1/bias - matched by .*
I0128 06:58:33.106215 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/LayerNorm_1/scale - matched by .*
I0128 06:58:33.106248 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias - matched by .*
I0128 06:58:33.106282 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel - matched by .*
I0128 06:58:33.106316 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias - matched by .*
I0128 06:58:33.106349 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel - matched by .*
I0128 06:58:33.106383 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0128 06:58:33.106417 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0128 06:58:33.106450 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0128 06:58:33.106483 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0128 06:58:33.106517 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0128 06:58:33.106556 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0128 06:58:33.106590 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0128 06:58:33.106624 139849920552000 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0128 06:58:33.106657 139849920552000 utils.py:769] config.schedule: txt/encoder_norm/bias - matched by .*
I0128 06:58:33.106691 139849920552000 utils.py:769] config.schedule: txt/encoder_norm/scale - matched by .*
I0128 06:58:33.106725 139849920552000 utils.py:769] config.schedule: txt/head/kernel - matched by .*
I0128 06:58:33.106759 139849920552000 utils.py:769] config.schedule: txt/pos_embedding - matched by .*
/home/jyang347/CLIPA/clipa_jax/optim/build_optax.py:292: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  assert not any(jax.tree_flatten(all_false)[0]), (
I0128 06:58:33.112660 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.112768 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.112821 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.112871 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.112913 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.112952 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.112993 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.113032 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.113069 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.113105 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.113141 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.113177 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.113218 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.113253 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.113289 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.113325 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.113362 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.113397 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.113437 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.113481 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.113519 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.113555 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.113590 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.113626 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.113667 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.113703 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.113738 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.113773 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.113809 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.113844 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.113896 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.113932 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.113968 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.114003 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.114038 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.114074 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.114113 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.114148 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.114184 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.114219 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.114255 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.114290 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.114330 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.114369 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.114411 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.114452 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.114490 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.114526 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.114572 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.114608 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.114645 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.114681 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.114716 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.114752 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.114792 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.114828 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.114869 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.114905 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.114956 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.114994 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.115034 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.115070 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.115106 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.115141 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.115177 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.115212 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.115252 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.115287 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.115323 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.115368 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.115405 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.115441 139849920552000 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.115478 139849920552000 utils.py:769] config.wd_mults: img/embedding/kernel - matched by .*/kernel$
I0128 06:58:33.115515 139849920552000 utils.py:769] config.wd_mults: img/head/kernel - matched by .*/kernel$
I0128 06:58:33.115558 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.115609 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.115645 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.115681 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.115718 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.115753 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.115793 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.115829 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.115871 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.115907 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.115942 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.115978 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.116019 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.116055 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.116091 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.116127 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.116164 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.116200 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.116239 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.116280 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.116316 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.116358 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.116394 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.116430 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.116471 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.116511 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.116547 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.116583 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.116619 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.116655 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.116695 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.116731 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.116767 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.116803 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.116838 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.116880 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.116921 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.116957 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.116992 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.117028 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.117064 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.117100 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.117140 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.117176 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.117212 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.117248 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.117284 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.117326 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.117367 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.117402 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.117456 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.117494 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.117530 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.117566 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.117606 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.117641 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.117677 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.117713 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.117748 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.117784 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.117823 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.117868 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.117906 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.117947 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.117983 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.118019 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.118059 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0128 06:58:33.118095 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0128 06:58:33.118130 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0128 06:58:33.118165 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0128 06:58:33.118201 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0128 06:58:33.118236 139849920552000 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0128 06:58:33.118281 139849920552000 utils.py:769] config.wd_mults: txt/head/kernel - matched by .*/kernel$
I0128 06:58:36.561829 139849920552000 flexi_main.py:120] [33mNOTE[0m: Resume training from checkpoint...
tcmalloc: large alloc 1401651200 bytes == 0xfb0a0000 @  0x7f3159382680 0x7f31593a3824 0x7f314df549ec 0x7f3142ea5adb 0x7f3142e9e4b1 0x5d5499 0x5d6066 0x4e22b3 0x54c8a9 0x54552a 0x5d5a23 0x547447 0x5d5846 0x547265 0x5d5846 0x547265 0x54552a 0x5d5a23 0x547265 0x5d5846 0x547265 0x54552a 0x5d5a23 0x54c8a9 0x54552a 0x684327 0x5e1514 0x5a27d0 0x547265 0x54552a 0x5d5a23
tcmalloc: large alloc 1401651200 bytes == 0x15295a000 @  0x7f3159382680 0x7f31593a2ff4 0x7f3142e8d01e 0x7f3142ea5b44 0x7f3142e9e4b1 0x5d5499 0x5d6066 0x4e22b3 0x54c8a9 0x54552a 0x5d5a23 0x547447 0x5d5846 0x547265 0x5d5846 0x547265 0x54552a 0x5d5a23 0x547265 0x5d5846 0x547265 0x54552a 0x5d5a23 0x54c8a9 0x54552a 0x684327 0x5e1514 0x5a27d0 0x547265 0x54552a 0x5d5a23
tcmalloc: large alloc 1401651200 bytes == 0x1a6212000 @  0x7f3159382680 0x7f31593a3824 0x5d93d1 0x7f3142ea5b51 0x7f3142e9e4b1 0x5d5499 0x5d6066 0x4e22b3 0x54c8a9 0x54552a 0x5d5a23 0x547447 0x5d5846 0x547265 0x5d5846 0x547265 0x54552a 0x5d5a23 0x547265 0x5d5846 0x547265 0x54552a 0x5d5a23 0x54c8a9 0x54552a 0x684327 0x5e1514 0x5a27d0 0x547265 0x54552a 0x5d5a23
/home/jyang347/CLIPA/clipa_jax/flexi_main.py:474: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.
  checkpoint_tree = jax.tree_structure(checkpoint)
I0128 06:58:51.487939 139849920552000 flexi_main.py:120] [33mNOTE[0m: Kicking off misc stuff...
I0128 06:58:51.489326 139849920552000 flexi_main.py:120] [33mNOTE[0m: Replicating...
Steps:1/114716000 [0.0%]
I0128 06:58:54.294177 139849920552000 flexi_main.py:120] [33mNOTE[0m: First step compilations...
Steps:1/114716000 [0.0%]
I0128 06:59:08.258829 139849920552000 flexi_model.py:50] FlexiViT: resize embedding (8, 8, 3, 768) to (16, 16)
/home/jyang347/CLIPA/clipa_jax/flexi_main.py:351: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/flexi_main.py:394: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/flexi_main.py:403: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/flexi_main.py:417: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/flexi_main.py:428: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(optim.replace_frozen(config.schedule, grads, 0.))
/home/jyang347/CLIPA/clipa_jax/flexi_main.py:430: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  ps = jax.tree_leaves(params)
/home/jyang347/CLIPA/clipa_jax/flexi_main.py:432: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  us = jax.tree_leaves(updates)
I0128 07:00:17.066228 139849920552000 utils.py:844] [35m[2][0m z/secs/update0 = 69.84885644802125
I0128 07:00:17.067022 139849920552000 utils.py:427] TIMING[z/secs/update0]: 69.84885644802125
I0128 07:00:17.104316 139849920552000 utils.py:844] [35m[2][0m global_schedule = 3.0517577442878974e-07
I0128 07:00:17.126976 139849920552000 utils.py:844] [35m[2][0m training_loss = 2.760221004486084
I0128 07:00:17.127653 139849920552000 utils.py:844] [35m[2][0m l2_grad_cls = 83.76158142089844
I0128 07:00:17.128334 139849920552000 utils.py:844] [35m[2][0m l2_grad_embeding = 3.271486759185791
I0128 07:00:17.128898 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_0 = 2.115633964538574
I0128 07:00:17.129454 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_1 = 1.4199726581573486
I0128 07:00:17.129908 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_10 = 0.46362194418907166
I0128 07:00:17.130379 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_11 = 0.43233150243759155
I0128 07:00:17.130798 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_2 = 1.0596885681152344
I0128 07:00:17.131374 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_3 = 0.8927452564239502
I0128 07:00:17.131823 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_4 = 0.7529842257499695
I0128 07:00:17.132290 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_5 = 0.6820544600486755
I0128 07:00:17.132700 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_6 = 0.6045933365821838
I0128 07:00:17.133128 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_7 = 0.569985032081604
I0128 07:00:17.133544 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_8 = 0.5376769304275513
I0128 07:00:17.134010 139849920552000 utils.py:844] [35m[2][0m l2_grad_encoderblock_9 = 0.49640774726867676
I0128 07:00:17.134414 139849920552000 utils.py:844] [35m[2][0m l2_grad_head = 1.9356772899627686
I0128 07:00:17.134810 139849920552000 utils.py:844] [35m[2][0m l2_grads = 86.60411834716797
I0128 07:00:17.135217 139849920552000 utils.py:844] [35m[2][0m l2_params = 371.71875
I0128 07:00:17.135705 139849920552000 utils.py:844] [35m[2][0m l2_updates = 0.0
I0128 07:00:17.136130 139849920552000 utils.py:844] [35m[2][0m ncorrect = 0.0
I0128 07:00:17.136563 139849920552000 utils.py:844] [35m[2][0m nimg = 22.37579345703125
I0128 07:00:17.136987 139849920552000 utils.py:844] [35m[2][0m ntxt = 22.22744369506836
I0128 07:00:17.137520 139849920552000 utils.py:844] [35m[2][0m t = 14.285693168640137
I0128 07:00:17.137968 139849920552000 utils.py:844] [35m[2][0m t/parameter = 2.6592600345611572
I0128 07:00:17.138105 139849920552000 utils.py:844] [35m[2][0m uptime = 164.15986567304935
I0128 07:00:17.138219 139849920552000 utils.py:844] [35m[2][0m examples_seen = 32.0
I0128 07:00:17.138294 139849920552000 utils.py:844] [35m[2][0m progress = 1.7434359635970572e-08
I0128 07:00:17.138363 139849920552000 utils.py:844] [35m[2][0m epoch = 1.22040517917228e-07
I0128 07:00:17.138425 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:1/114716000 [0.0%]
I0128 07:00:17.138658 139849920552000 flexi_main.py:120] [33mNOTE[0m: Init evaluator: disclf…
Steps:1/114716000 [0.0%]
I0128 07:00:17.141858 139849920552000 prompt_engineering.py:92] Using 81 prompts_templates: ['a bad photo of a {}', 'a photo of many {}', 'a sculpture of a {}', 'a photo of the hard to see {}', 'a low resolution photo of the {}', 'a rendering of a {}', 'graffiti of a {}', 'a bad photo of the {}', 'a cropped photo of the {}', 'a tattoo of a {}', 'the embroidered {}', 'a photo of a hard to see {}', 'a bright photo of a {}', 'a photo of a clean {}', 'a photo of a dirty {}', 'a dark photo of the {}', 'a drawing of a {}', 'a photo of my {}', 'the plastic {}', 'a photo of the cool {}', 'a closeup photo of a {}', 'a black and white photo of the {}', 'a painting of the {}', 'a painting of a {}', 'a pixelated photo of the {}', 'a sculpture of the {}', 'a bright photo of the {}', 'a cropped photo of a {}', 'a plastic {}', 'a photo of the dirty {}', 'a jpeg corrupted photo of a {}', 'a blurry photo of the {}', 'a photo of the {}', 'a good photo of the {}', 'a rendering of the {}', 'a {} in a video game', 'a photo of one {}', 'a doodle of a {}', 'a closeup photo of the {}', 'a photo of a {}', 'the origami {}', 'the {} in a video game', 'a sketch of a {}', 'a doodle of the {}', 'a origami {}', 'a low resolution photo of a {}', 'the toy {}', 'a rendition of the {}', 'a photo of the clean {}', 'a photo of a large {}', 'a rendition of a {}', 'a photo of a nice {}', 'a photo of a weird {}', 'a blurry photo of a {}', 'a cartoon {}', 'art of a {}', 'a sketch of the {}', 'a embroidered {}', 'a pixelated photo of a {}', 'itap of the {}', 'a jpeg corrupted photo of the {}', 'a good photo of a {}', 'a plushie {}', 'a photo of the nice {}', 'a photo of the small {}', 'a photo of the weird {}', 'the cartoon {}', 'art of the {}', 'a drawing of the {}', 'a photo of the large {}', 'a black and white photo of a {}', 'the plushie {}', 'a dark photo of a {}', 'itap of a {}', 'graffiti of the {}', 'a toy {}', 'itap of my {}', 'a photo of a cool {}', 'a photo of a small {}', 'a tattoo of the {}', '{}']
I0128 07:00:17.146590 139849920552000 prompt_engineering.py:78] Using 1000 class_names: ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'american robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'american dipper', 'kite bird of prey', 'bald eagle', 'vulture', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'axolotl', 'american bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'green iguana', 'carolina anole', 'desert grassland whiptail lizard', 'agama', 'frillednecked lizard', 'alligator lizard', 'gila monster', 'european green lizard', 'chameleon', 'komodo dragon', 'nile crocodile', 'american alligator', 'triceratops', 'worm snake', 'ringnecked snake', 'eastern hognosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'african rock python', 'indian cobra', 'green mamba', 'sea snake', 'saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'trilobite', 'harvestman', 'scorpion', 'yellow garden spider', 'barn spider', 'european garden spider', 'southern black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie grouse', 'peafowl', 'quail', 'partridge', 'african grey parrot', 'macaw', 'sulphurcrested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'duck', 'redbreasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'american lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'limpkin', 'common gallinule', 'american coot', 'bustard', 'ruddy turnstone', 'dunlin', 'common redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'chihuahua', 'japanese chin', 'maltese', 'pekingese', 'shih tzu', 'king charles spaniel', 'papillon', 'toy terrier', 'rhodesian ridgeback', 'afghan hound', 'basset hound', 'beagle', 'bloodhound', 'bluetick coonhound', 'black and tan coonhound', 'treeing walker coonhound', 'english foxhound', 'redbone coonhound', 'borzoi', 'irish wolfhound', 'italian greyhound', 'whippet', 'ibizan hound', 'norwegian elkhound', 'otterhound', 'saluki', 'scottish deerhound', 'weimaraner', 'staffordshire bull terrier', 'american staffordshire terrier', 'bedlington terrier', 'border terrier', 'kerry blue terrier', 'irish terrier', 'norfolk terrier', 'norwich terrier', 'yorkshire terrier', 'wire fox terrier', 'lakeland terrier', 'sealyham terrier', 'airedale terrier', 'cairn terrier', 'australian terrier', 'dandie dinmont terrier', 'boston terrier', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'scottish terrier', 'tibetan terrier', 'australian silky terrier', 'softcoated wheaten terrier', 'west highland white terrier', 'lhasa apso', 'flatcoated retriever', 'curlycoated retriever', 'golden retriever', 'labrador retriever', 'chesapeake bay retriever', 'german shorthaired pointer', 'vizsla', 'english setter', 'irish setter', 'gordon setter', 'brittany dog', 'clumber spaniel', 'english springer spaniel', 'welsh springer spaniel', 'cocker spaniel', 'sussex spaniel', 'irish water spaniel', 'kuvasz', 'schipperke', 'groenendael dog', 'malinois', 'briard', 'australian kelpie', 'komondor', 'old english sheepdog', 'shetland sheepdog', 'collie', 'border collie', 'bouvier des flandres dog', 'rottweiler', 'german shepherd dog', 'dobermann', 'miniature pinscher', 'greater swiss mountain dog', 'bernese mountain dog', 'appenzeller sennenhund', 'entlebucher sennenhund', 'boxer', 'bullmastiff', 'tibetan mastiff', 'french bulldog', 'great dane', 'st bernard', 'husky', 'alaskan malamute', 'siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'leonberger', 'newfoundland dog', 'great pyrenees dog', 'samoyed', 'pomeranian', 'chow chow', 'keeshond', 'brussels griffon', 'pembroke welsh corgi', 'cardigan welsh corgi', 'toy poodle', 'miniature poodle', 'standard poodle', 'mexican hairless dog xoloitzcuintli', 'grey wolf', 'alaskan tundra wolf', 'red wolf or maned wolf', 'coyote', 'dingo', 'dhole', 'african wild dog', 'hyena', 'red fox', 'kit fox', 'arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'persian cat', 'siamese cat', 'egyptian mau', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'american black bear', 'polar bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket insect', 'stick insect', 'cockroach', 'praying mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamerwinged butterfly', 'starfish', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'hare', 'angora rabbit', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'common sorrel horse', 'zebra', 'pig', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram adult male sheep', 'bighorn sheep', 'alpine ibex', 'hartebeest', 'impala antelope', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'european polecat', 'blackfooted ferret', 'otter', 'skunk', 'badger', 'armadillo', 'threetoed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas monkey', 'baboon', 'macaque', 'langur', 'blackandwhite colobus', 'proboscis monkey', 'marmoset', 'whiteheaded capuchin', 'howler monkey', 'titi monkey', 'geoffroys spider monkey', 'common squirrel monkey', 'ringtailed lemur', 'indri', 'asian elephant', 'african bush elephant', 'red panda', 'giant panda', 'snoek fish', 'eel', 'silver salmon', 'rock beauty fish', 'clownfish', 'sturgeon', 'gar fish', 'lionfish', 'pufferfish', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibious vehicle', 'analog clock', 'apiary', 'apron', 'trash can', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint pen', 'bandaid', 'banjo', 'baluster handrail', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'wheelbarrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'swimming cap', 'bath towel', 'bathtub', 'station wagon', 'lighthouse', 'beaker', 'military hat bearskin or shako', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'bikini', 'ring binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookcase', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'highspeed train', 'butcher shop', 'taxicab', 'cauldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', 'tool kit', 'cardboard box carton', 'car wheel', 'automated teller machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'cd player', 'cello', 'mobile phone', 'chain', 'chainlink fence', 'chain mail', 'chainsaw', 'storage chest', 'chiffonier', 'bell or wind chime', 'china cabinet', 'christmas stocking', 'church', 'movie theater', 'cleaver', 'cliff dwelling', 'cloak', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'construction crane', 'crash helmet', 'crate', 'infant bed', 'crock pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'rotary dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'dishwasher', 'disc brake', 'dock', 'dog sled', 'dome', 'doormat', 'drilling rig', 'drum', 'drumstick', 'dumbbell', 'dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fireboat', 'fire truck', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'fourposter bed', 'freight car', 'french horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'goblet', 'gokart', 'golf ball', 'golf cart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'radiator grille', 'grocery store', 'guillotine', 'hair clip', 'hair spray', 'halftrack', 'hammer', 'hamper', 'hair dryer', 'handheld computer', 'handkerchief', 'hard disk drive', 'harmonica', 'harp', 'combine harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoop skirt', 'gymnastic horizontal bar', 'horsedrawn vehicle', 'hourglass', 'ipod', 'clothes iron', 'carved pumpkin', 'jeans', 'jeep', 'tshirt', 'jigsaw puzzle', 'rickshaw', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'ocean liner', 'lipstick', 'slipon shoe', 'lotion', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'mailbox', 'tights', 'onepiece bathing suit', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine cabinet', 'megalith', 'microphone', 'microwave oven', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'ford model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar and pestle', 'graduation cap', 'mosque', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'mousetrap', 'moving van', 'muzzle', 'metal nail', 'neck brace', 'necklace', 'baby pacifier', 'notebook computer', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'pipe organ', 'oscilloscope', 'overskirt', 'bullock cart', 'oxygen mask', 'product packet packaging', 'paddle', 'paddle wheel', 'padlock', 'paintbrush', 'pajamas', 'palace', 'pan flute', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'patio', 'payphone', 'pedestal', 'pencil case', 'pencil sharpener', 'perfume', 'petri dish', 'photocopier', 'plectrum', 'pickelhaube', 'picket fence', 'pickup truck', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'pingpong ball', 'pinwheel', 'pirate ship', 'drink pitcher', 'block plane', 'planetarium', 'plastic bag', 'plate rack', 'farm plow', 'plunger', 'polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'soda bottle', 'plant pot', 'potters wheel', 'power drill', 'prayer rug', 'printer', 'prison', 'missile', 'projector', 'hockey puck', 'punching bag', 'purse', 'quill', 'quilt', 'race car', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safe', 'safety pin', 'salt shaker', 'sandal', 'sarong', 'saxophone', 'scabbard', 'weighing scale', 'school bus', 'schooner', 'scoreboard', 'crt monitor', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe store', 'shoji screen room divider', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar thermal collector', 'sombrero', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'spatula', 'motorboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'through arch bridge', 'steel drum', 'stethoscope', 'scarf', 'stone wall', 'stopwatch', 'stove', 'strainer', 'tram', 'stretcher', 'couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'suspension bridge', 'mop', 'sweatshirt', 'swim trunks shorts', 'swing', 'electrical switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy bear', 'television', 'tennis ball', 'thatched roof', 'front curtain', 'thimble', 'threshing machine', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toy store', 'tractor', 'semitrailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'hot tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright piano', 'vacuum cleaner', 'vase', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'hair wig', 'window screen', 'window shade', 'windsor tie', 'wine bottle', 'airplane wing', 'wok', 'wooden spoon', 'wool', 'splitrail fence', 'shipwreck', 'sailboat', 'yurt', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'popsicle', 'baguette', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'mashed potatoes', 'cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'granny smith apple', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'cherimoya custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate syrup', 'dough', 'meatloaf', 'pizza', 'pot pie', 'burrito', 'red wine', 'espresso', 'tea cup', 'eggnog', 'mountain', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeshore', 'promontory', 'sandbar', 'beach', 'valley', 'volcano', 'baseball player', 'bridegroom', 'scuba diver', 'rapeseed', 'daisy', 'yellow ladys slipper', 'corn', 'acorn', 'rose hip', 'horse chestnut seed', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'bolete', 'corn cob', 'toilet paper']
I0128 07:00:17.291041 139849920552000 dataset_info.py:566] Load dataset info from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0128 07:00:17.534892 139849920552000 dataset_info.py:642] Field info.description from disk and from code do not match. Keeping the one from code.
I0128 07:00:17.535377 139849920552000 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0128 07:00:17.606834 139849920552000 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split _EvenSplit(split='validation', index=0, count=1, drop_remainder=False), from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0128 07:00:17.610600 139849920552000 api.py:459] Data before pre-processing:
{'file_name': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'image': <tf.Tensor 'args_1:0' shape=(None, None, 3) dtype=uint8>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0128 07:00:17.817712 139849920552000 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'truediv_1:0' shape=(240, 240, 3) dtype=float32>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0128 07:00:18.381073 139849920552000 api.py:459] Data before pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'texts': <tf.Tensor 'args_1:0' shape=() dtype=string>}
I0128 07:00:18.740501 139849920552000 api.py:459] Data after pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'labels': <tf.Tensor 'strided_slice_4:0' shape=(16,) dtype=int32>}
I0128 07:00:18.856193 139849920552000 discriminative_classifier.py:341] Initialized evaluator in 1.7 seconds
I0128 07:01:32.912563 139849920552000 utils.py:844] [35m[3][0m global_schedule = 6.103515488575795e-07
I0128 07:01:33.052411 139849920552000 utils.py:844] [35m[3][0m training_loss = 2.877147674560547
I0128 07:01:33.053653 139849920552000 utils.py:844] [35m[3][0m l2_grad_cls = 80.79561614990234
I0128 07:01:33.054277 139849920552000 utils.py:844] [35m[3][0m l2_grad_embeding = 3.6827123165130615
I0128 07:01:33.054915 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_0 = 2.512354850769043
I0128 07:01:33.055415 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_1 = 1.6807754039764404
I0128 07:01:33.055914 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_10 = 0.5503695607185364
I0128 07:01:33.056405 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_11 = 0.5150572657585144
I0128 07:01:33.056948 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_2 = 1.2671393156051636
I0128 07:01:33.057365 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_3 = 1.0738525390625
I0128 07:01:33.057890 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_4 = 0.8896636366844177
I0128 07:01:33.058340 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_5 = 0.8070108294487
I0128 07:01:33.058834 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_6 = 0.7241427898406982
I0128 07:01:33.059292 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_7 = 0.6776456832885742
I0128 07:01:33.059762 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_8 = 0.6351087093353271
I0128 07:01:33.060166 139849920552000 utils.py:844] [35m[3][0m l2_grad_encoderblock_9 = 0.5944923758506775
I0128 07:01:33.060747 139849920552000 utils.py:844] [35m[3][0m l2_grad_head = 2.3552210330963135
I0128 07:01:33.061211 139849920552000 utils.py:844] [35m[3][0m l2_grads = 84.94816589355469
I0128 07:01:33.061731 139849920552000 utils.py:844] [35m[3][0m l2_params = 371.71875
I0128 07:01:33.062178 139849920552000 utils.py:844] [35m[3][0m l2_updates = 0.0
I0128 07:01:33.062642 139849920552000 utils.py:844] [35m[3][0m ncorrect = 0.0
I0128 07:01:33.063105 139849920552000 utils.py:844] [35m[3][0m nimg = 22.333477020263672
I0128 07:01:33.063590 139849920552000 utils.py:844] [35m[3][0m ntxt = 22.600074768066406
I0128 07:01:33.064088 139849920552000 utils.py:844] [35m[3][0m t = 14.285693168640137
I0128 07:01:33.064660 139849920552000 utils.py:844] [35m[3][0m t/parameter = 2.6592600345611572
I0128 07:01:33.064795 139849920552000 utils.py:844] [35m[3][0m uptime = 240.08655640704092
I0128 07:01:33.064913 139849920552000 utils.py:844] [35m[3][0m examples_seen = 48.0
I0128 07:01:33.064983 139849920552000 utils.py:844] [35m[3][0m progress = 2.6151539453955857e-08
I0128 07:01:33.065042 139849920552000 utils.py:844] [35m[3][0m epoch = 1.83060776875842e-07
I0128 07:01:33.065155 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:1/114716000 [0.0%]
I0128 07:01:34.310224 139849920552000 flexi_model.py:50] FlexiViT: resize embedding (8, 8, 3, 768) to (12, 12)
I0128 07:02:49.141790 139849920552000 flexi_model.py:50] FlexiViT: resize embedding (8, 8, 3, 768) to (48, 48)
I0128 07:04:03.263111 139849920552000 flexi_model.py:50] FlexiViT: resize embedding (8, 8, 3, 768) to (30, 30)
I0128 07:05:16.359405 139849920552000 flexi_model.py:50] FlexiViT: resize embedding (8, 8, 3, 768) to (15, 15)
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=1/0)>
x in flexi_model: Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=1/0)>
flexi_args: [15]
image loss_fn: Traced<ShapedArray(float32[2,240,240,3])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
x in flexi_model: Traced<ShapedArray(float32[2,512])>with<JVPTrace(level=2/1)> with
  primal = Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=0/1)>
  tangent = Traced<ShapedArray(float32[2,512])>with<JaxprTrace(level=1/1)> with
    pval = (ShapedArray(float32[2,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f2e06abafa0>, in_tracers=(Traced<ShapedArray(float32[2,512]):JaxprTrace(level=1/1)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=1/1)>), out_tracer_refs=[<weakref at 0x7f2e069b69a0; to 'JaxprTracer' at 0x7f2e069b64a0>], out_avals=[ShapedArray(float32[2,512])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2,512] b:f32[1,512]. let c:f32[2,512] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'in_positional_semantics': (<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>), 'out_positional_semantics': <_PositionalSemantics.GLOBAL: 1>, 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f2e069b49f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='Model'), Scope(name='img'), Scope(name='head')))))
flexi_args: [30]
image loss_fn: Traced<ShapedArray(float32[2,240,240,3])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
x in flexi_model: Traced<ShapedArray(float32[2,512])>with<JVPTrace(level=2/1)> with
  primal = Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=0/1)>
  tangent = Traced<ShapedArray(float32[2,512])>with<JaxprTrace(level=1/1)> with
    pval = (ShapedArray(float32[2,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f2e05edeb10>, in_tracers=(Traced<ShapedArray(float32[2,512]):JaxprTrace(level=1/1)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=1/1)>), out_tracer_refs=[<weakref at 0x7f2e066004f0; to 'JaxprTracer' at 0x7f2e066004a0>], out_avals=[ShapedArray(float32[2,512])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2,512] b:f32[1,512]. let c:f32[2,512] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'in_positional_semantics': (<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>), 'out_positional_semantics': <_PositionalSemantics.GLOBAL: 1>, 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f2e50d25830>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='Model'), Scope(name='img'), Scope(name='head')))))
flexi_args: [20]
image loss_fn: Traced<ShapedArray(float32[2,240,240,3])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
x in flexi_model: Traced<ShapedArray(float32[2,512])>with<JVPTrace(level=2/1)> with
  primal = Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=0/1)>
  tangent = Traced<ShapedArray(float32[2,512])>with<JaxprTrace(level=1/1)> with
    pval = (ShapedArray(float32[2,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f2e0609b150>, in_tracers=(Traced<ShapedArray(float32[2,512]):JaxprTrace(level=1/1)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=1/1)>), out_tracer_refs=[<weakref at 0x7f2e060aa540; to 'JaxprTracer' at 0x7f2e060aa4f0>], out_avals=[ShapedArray(float32[2,512])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2,512] b:f32[1,512]. let c:f32[2,512] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'in_positional_semantics': (<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>), 'out_positional_semantics': <_PositionalSemantics.GLOBAL: 1>, 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f2e06a657b0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='Model'), Scope(name='img'), Scope(name='head')))))
flexi_args: [5]
image loss_fn: Traced<ShapedArray(float32[2,240,240,3])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
x in flexi_model: Traced<ShapedArray(float32[2,512])>with<JVPTrace(level=2/1)> with
  primal = Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=0/1)>
  tangent = Traced<ShapedArray(float32[2,512])>with<JaxprTrace(level=1/1)> with
    pval = (ShapedArray(float32[2,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f2e05f89630>, in_tracers=(Traced<ShapedArray(float32[2,512]):JaxprTrace(level=1/1)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=1/1)>), out_tracer_refs=[<weakref at 0x7f2e047290e0; to 'JaxprTracer' at 0x7f2e04729090>], out_avals=[ShapedArray(float32[2,512])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2,512] b:f32[1,512]. let c:f32[2,512] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'in_positional_semantics': (<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>), 'out_positional_semantics': <_PositionalSemantics.GLOBAL: 1>, 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f2e2893d070>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='Model'), Scope(name='img'), Scope(name='head')))))
flexi_args: [8]
image loss_fn: Traced<ShapedArray(float32[2,240,240,3])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
x in flexi_model: Traced<ShapedArray(float32[2,512])>with<JVPTrace(level=2/1)> with
  primal = Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=0/1)>
  tangent = Traced<ShapedArray(float32[2,512])>with<JaxprTrace(level=1/1)> with
    pval = (ShapedArray(float32[2,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f2e03f1ab50>, in_tracers=(Traced<ShapedArray(float32[2,512]):JaxprTrace(level=1/1)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=1/1)>), out_tracer_refs=[<weakref at 0x7f2e01ff3c70; to 'JaxprTracer' at 0x7f2e01ff3c20>], out_avals=[ShapedArray(float32[2,512])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2,512] b:f32[1,512]. let c:f32[2,512] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'in_positional_semantics': (<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>), 'out_positional_semantics': <_PositionalSemantics.GLOBAL: 1>, 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f2e03e92430>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='Model'), Scope(name='img'), Scope(name='head')))))
flexi_args: [15]
flexi_args: [20]
flexi_args: [5]
flexi_args: [30]
flexi_args: [15]
flexi_args: [8]
flexi_args: [30]
flexi_args: [16]
image loss_fn: Traced<ShapedArray(float32[2,240,240,3])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
x in flexi_model: I0128 07:06:31.820453 139849920552000 flexi_model.py:50] FlexiViT: resize embedding (8, 8, 3, 768) to (40, 40)
I0128 07:07:45.483379 139849920552000 flexi_model.py:50] FlexiViT: resize embedding (8, 8, 3, 768) to (10, 10)
I0128 07:09:01.268234 139849920552000 flexi_model.py:50] FlexiViT: resize embedding (8, 8, 3, 768) to (20, 20)
I0128 07:10:16.021179 139849920552000 flexi_model.py:50] FlexiViT: resize embedding (8, 8, 3, 768) to (24, 24)
I0128 07:11:32.046602 139849920552000 utils.py:844] [35m[50][0m global_schedule = 1.4953612662793603e-05
I0128 07:11:32.685937 139849920552000 utils.py:844] [35m[50][0m training_loss = 2.977175712585449
I0128 07:11:32.687398 139849920552000 utils.py:844] [35m[50][0m l2_grad_cls = 76.41688537597656
I0128 07:11:32.688058 139849920552000 utils.py:844] [35m[50][0m l2_grad_embeding = 4.381145477294922
I0128 07:11:32.688582 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_0 = 3.028024911880493
I0128 07:11:32.689141 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_1 = 2.1369338035583496
I0128 07:11:32.689586 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_10 = 0.7331666946411133
I0128 07:11:32.690038 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_11 = 0.689694344997406
I0128 07:11:32.690473 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_2 = 1.6564619541168213
I0128 07:11:32.691033 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_3 = 1.4109220504760742
I0128 07:11:32.691499 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_4 = 1.1992398500442505
I0128 07:11:32.692039 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_5 = 1.0824719667434692
I0128 07:11:32.692545 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_6 = 0.9643662571907043
I0128 07:11:32.693108 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_7 = 0.8751175999641418
I0128 07:11:32.693532 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_8 = 0.8243455290794373
I0128 07:11:32.693956 139849920552000 utils.py:844] [35m[50][0m l2_grad_encoderblock_9 = 0.768883466720581
I0128 07:11:32.694397 139849920552000 utils.py:844] [35m[50][0m l2_grad_head = 3.328853130340576
I0128 07:11:32.694968 139849920552000 utils.py:844] [35m[50][0m l2_grads = 83.41990661621094
I0128 07:11:32.695391 139849920552000 utils.py:844] [35m[50][0m l2_params = 371.71875
I0128 07:11:32.695795 139849920552000 utils.py:844] [35m[50][0m l2_updates = 0.0
I0128 07:11:32.696182 139849920552000 utils.py:844] [35m[50][0m ncorrect = 0.0
I0128 07:11:32.696705 139849920552000 utils.py:844] [35m[50][0m nimg = 22.40152359008789
I0128 07:11:32.697120 139849920552000 utils.py:844] [35m[50][0m ntxt = 22.451702117919922
I0128 07:11:32.697574 139849920552000 utils.py:844] [35m[50][0m t = 14.285693168640137
I0128 07:11:32.698022 139849920552000 utils.py:844] [35m[50][0m t/parameter = 2.6592600345611572
I0128 07:11:32.698158 139849920552000 utils.py:844] [35m[50][0m uptime = 839.7199157370487
I0128 07:11:32.698264 139849920552000 utils.py:844] [35m[50][0m examples_seen = 800.0
I0128 07:11:32.698340 139849920552000 utils.py:844] [35m[50][0m progress = 4.3585899089926426e-07
I0128 07:11:32.698404 139849920552000 utils.py:844] [35m[50][0m epoch = 3.0510129479307e-06
I0128 07:11:32.698473 139849920552000 utils.py:844] [35m[50][0m img/sec/core = 0.1567624591550904
I0128 07:11:32.698628 139849920552000 utils.py:844] [35m[50][0m core_hours_TPU v3 = 1.3325185762889062
I0128 07:11:32.698704 139849920552000 utils.py:844] [35m[50][0m core_hours = 1.3325185762889062
I0128 07:11:32.698879 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:50/114716000 [0.0%]
Walltime:13m60s (0s eval)
ETA:406545h34m
Total train time:406545h44m
Traced<ShapedArray(float32[2,512])>with<JVPTrace(level=2/1)> with
  primal = Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=0/1)>
  tangent = Traced<ShapedArray(float32[2,512])>with<JaxprTrace(level=1/1)> with
    pval = (ShapedArray(float32[2,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f2e044ee0c0>, in_tracers=(Traced<ShapedArray(float32[2,512]):JaxprTrace(level=1/1)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=1/1)>), out_tracer_refs=[<weakref at 0x7f2e04510e00; to 'JaxprTracer' at 0x7f2e04510db0>], out_avals=[ShapedArray(float32[2,512])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2,512] b:f32[1,512]. let c:f32[2,512] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'in_positional_semantics': (<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>), 'out_positional_semantics': <_PositionalSemantics.GLOBAL: 1>, 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f2e064beb70>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='Model'), Scope(name='img'), Scope(name='head')))))
flexi_args: [6]
image loss_fn: Traced<ShapedArray(float32[2,240,240,3])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
x in flexi_model: Traced<ShapedArray(float32[2,512])>with<JVPTrace(level=2/1)> with
  primal = Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=0/1)>
  tangent = Traced<ShapedArray(float32[2,512])>with<JaxprTrace(level=1/1)> with
    pval = (ShapedArray(float32[2,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f2e027d6490>, in_tracers=(Traced<ShapedArray(float32[2,512]):JaxprTrace(level=1/1)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=1/1)>), out_tracer_refs=[<weakref at 0x7f2e01c5c950; to 'JaxprTracer' at 0x7f2e01c5c900>], out_avals=[ShapedArray(float32[2,512])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2,512] b:f32[1,512]. let c:f32[2,512] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'in_positional_semantics': (<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>), 'out_positional_semantics': <_PositionalSemantics.GLOBAL: 1>, 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f2e01c8ed70>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='Model'), Scope(name='img'), Scope(name='head')))))
flexi_args: [24]
image loss_fn: Traced<ShapedArray(float32[2,240,240,3])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
x in flexi_model: Traced<ShapedArray(float32[2,512])>with<JVPTrace(level=2/1)> with
  primal = Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=0/1)>
  tangent = Traced<ShapedArray(float32[2,512])>with<JaxprTrace(level=1/1)> with
    pval = (ShapedArray(float32[2,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f2e02b088f0>, in_tracers=(Traced<ShapedArray(float32[2,512]):JaxprTrace(level=1/1)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=1/1)>), out_tracer_refs=[<weakref at 0x7f2e032ee7c0; to 'JaxprTracer' at 0x7f2e032ee770>], out_avals=[ShapedArray(float32[2,512])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2,512] b:f32[1,512]. let c:f32[2,512] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'in_positional_semantics': (<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>), 'out_positional_semantics': <_PositionalSemantics.GLOBAL: 1>, 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f2e043256f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='Model'), Scope(name='img'), Scope(name='head')))))
flexi_args: [12]
image loss_fn: Traced<ShapedArray(float32[2,240,240,3])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
x in flexi_model: Traced<ShapedArray(float32[2,512])>with<JVPTrace(level=2/1)> with
  primal = Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=0/1)>
  tangent = Traced<ShapedArray(float32[2,512])>with<JaxprTrace(level=1/1)> with
    pval = (ShapedArray(float32[2,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f2e0050cd90>, in_tracers=(Traced<ShapedArray(float32[2,512]):JaxprTrace(level=1/1)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=1/1)>), out_tracer_refs=[<weakref at 0x7f2e020d9130; to 'JaxprTracer' at 0x7f2e020d90e0>], out_avals=[ShapedArray(float32[2,512])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2,512] b:f32[1,512]. let c:f32[2,512] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'in_positional_semantics': (<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>), 'out_positional_semantics': <_PositionalSemantics.GLOBAL: 1>, 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f2e02c222f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='Model'), Scope(name='img'), Scope(name='head')))))
flexi_args: [5]
flexi_args: [20]
flexi_args: [15]
flexi_args: [10]
image loss_fn: Traced<ShapedArray(float32[2,240,240,3])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
x in flexi_model: Traced<ShapedArray(float32[2,512])>with<JVPTrace(level=2/1)> with
  primal = Traced<ShapedArray(float32[2,512])>with<DynamicJaxprTrace(level=0/1)>
  tangent = Traced<ShapedArray(float32[2,512])>with<JaxprTrace(level=1/1)> with
    pval = (ShapedArray(float32[2,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f2e020f5300>, in_tracers=(Traced<ShapedArray(float32[2,512]):JaxprTrace(level=1/1)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=1/1)>), out_tracer_refs=[<weakref at 0x7f2e020e9d10; to 'JaxprTracer' at 0x7f2e020e9cc0>], out_avals=[ShapedArray(float32[2,512])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[2,512] b:f32[1,512]. let c:f32[2,512] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'in_positional_semantics': (<_PositionalSemantics.GLOBAL: 1>, <_PositionalSemantics.GLOBAL: 1>), 'out_positional_semantics': <_PositionalSemantics.GLOBAL: 1>, 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f2e005ce130>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='Model'), Scope(name='img'), Scope(name='head')))))
flexi_args: [10]
flexi_args: [6]
flexi_args: [20]
flexi_args: [30]
flexi_args: [15]
flexi_args: [6]
flexi_args: [12]
flexi_args: [12]
flexi_args: [10]
flexi_args: [24]
flexi_args: [8]
flexi_args: [24]
flexi_args: [12]
flexi_args: [5]
flexi_args: [5]
flexi_args: [15]
flexi_args: [24]
flexi_args: [24]
flexi_args: [30]
flexi_args: [12]
flexi_args: [24]
flexi_args: [30]
flexi_args: [20]
flexi_args: [15]
flexi_args: [16]
flexi_args: [8]
flexi_args: [24]
flexi_args: [10]
flexi_args: [12]
flexi_args: [30]
flexi_args: [10]
flexi_args: [30]
flexi_args: [8]
flexi_args: [8]
flexi_args: [12]
flexi_args: [16]
flexi_args: [12]
flexi_args: [24]
flexi_args: [16]
flexi_args: [6]
flexi_args: [20]
flexi_args: [15]
flexi_args: [12]
flexi_args: [8]
flexi_args: [8]
flexi_args: [20]
flexi_args: [12]
flexi_args: [24]
flexi_args: [5]
flexi_args: [8]
I0128 07:11:34.465257 139849920552000 utils.py:844] [35m[100][0m global_schedule = 3.02124008157989e-05
I0128 07:11:35.177845 139849920552000 utils.py:844] [35m[100][0m training_loss = 2.7856857776641846
I0128 07:11:35.178775 139849920552000 utils.py:844] [35m[100][0m l2_grad_cls = 43.72789764404297
I0128 07:11:35.179505 139849920552000 utils.py:844] [35m[100][0m l2_grad_embeding = 3.8444225788116455
I0128 07:11:35.180027 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_0 = 2.5930349826812744
I0128 07:11:35.180490 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_1 = 1.8946068286895752
I0128 07:11:35.180948 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_10 = 0.653182327747345
I0128 07:11:35.181427 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_11 = 0.6270188093185425
I0128 07:11:35.181913 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_2 = 1.4698296785354614
I0128 07:11:35.182405 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_3 = 1.2522550821304321
I0128 07:11:35.182823 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_4 = 1.0645205974578857
I0128 07:11:35.183385 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_5 = 0.958002507686615
I0128 07:11:35.183806 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_6 = 0.8546881079673767
I0128 07:11:35.184245 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_7 = 0.8003447651863098
I0128 07:11:35.184651 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_8 = 0.7431613802909851
I0128 07:11:35.185193 139849920552000 utils.py:844] [35m[100][0m l2_grad_encoderblock_9 = 0.6993329524993896
I0128 07:11:35.185610 139849920552000 utils.py:844] [35m[100][0m l2_grad_head = 3.0473718643188477
I0128 07:11:35.186056 139849920552000 utils.py:844] [35m[100][0m l2_grads = 54.80961608886719
I0128 07:11:35.186434 139849920552000 utils.py:844] [35m[100][0m l2_params = 371.71875
I0128 07:11:35.186952 139849920552000 utils.py:844] [35m[100][0m l2_updates = 0.0
I0128 07:11:35.187374 139849920552000 utils.py:844] [35m[100][0m ncorrect = 0.0625
I0128 07:11:35.187787 139849920552000 utils.py:844] [35m[100][0m nimg = 22.237895965576172
I0128 07:11:35.188203 139849920552000 utils.py:844] [35m[100][0m ntxt = 22.349870681762695
I0128 07:11:35.188791 139849920552000 utils.py:844] [35m[100][0m t = 14.285693168640137
I0128 07:11:35.189239 139849920552000 utils.py:844] [35m[100][0m t/parameter = 2.6592600345611572
I0128 07:11:35.189348 139849920552000 utils.py:844] [35m[100][0m uptime = 842.2111148399999
I0128 07:11:35.189440 139849920552000 utils.py:844] [35m[100][0m examples_seen = 1600.0
I0128 07:11:35.189505 139849920552000 utils.py:844] [35m[100][0m progress = 8.717179817985285e-07
I0128 07:11:35.189568 139849920552000 utils.py:844] [35m[100][0m epoch = 6.1020258958614e-06
I0128 07:11:35.189641 139849920552000 utils.py:844] [35m[100][0m img/sec/core = 40.14131182109628
I0128 07:11:35.189736 139849920552000 utils.py:844] [35m[100][0m core_hours_TPU v3 = 1.3380545742954646
I0128 07:11:35.189793 139849920552000 utils.py:844] [35m[100][0m core_hours = 1.3380545742954646
I0128 07:11:35.189894 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:100/114716000 [0.0%]
Walltime:14m2s (0s eval)
ETA:197804h17m
Total train time:197804h28m
I0128 07:11:36.970730 139849920552000 utils.py:844] [35m[150][0m global_schedule = 4.5471191697288305e-05
I0128 07:11:37.613502 139849920552000 utils.py:844] [35m[150][0m training_loss = 2.823680877685547
I0128 07:11:37.614596 139849920552000 utils.py:844] [35m[150][0m l2_grad_cls = 36.73423767089844
I0128 07:11:37.615293 139849920552000 utils.py:844] [35m[150][0m l2_grad_embeding = 2.742345094680786
I0128 07:11:37.615818 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_0 = 1.837392807006836
I0128 07:11:37.616283 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_1 = 1.2853940725326538
I0128 07:11:37.616778 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_10 = 0.45123007893562317
I0128 07:11:37.617360 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_11 = 0.4246779978275299
I0128 07:11:37.617842 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_2 = 0.9968268275260925
I0128 07:11:37.618289 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_3 = 0.8402271866798401
I0128 07:11:37.618817 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_4 = 0.7141215801239014
I0128 07:11:37.619429 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_5 = 0.6563082933425903
I0128 07:11:37.619827 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_6 = 0.5879940390586853
I0128 07:11:37.620259 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_7 = 0.5476345419883728
I0128 07:11:37.620692 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_8 = 0.5220301747322083
I0128 07:11:37.621217 139849920552000 utils.py:844] [35m[150][0m l2_grad_encoderblock_9 = 0.4844955801963806
I0128 07:11:37.621639 139849920552000 utils.py:844] [35m[150][0m l2_grad_head = 1.9479767084121704
I0128 07:11:37.622083 139849920552000 utils.py:844] [35m[150][0m l2_grads = 42.68534469604492
I0128 07:11:37.622518 139849920552000 utils.py:844] [35m[150][0m l2_params = 371.71875
I0128 07:11:37.622962 139849920552000 utils.py:844] [35m[150][0m l2_updates = 0.0
I0128 07:11:37.623371 139849920552000 utils.py:844] [35m[150][0m ncorrect = 0.1875
I0128 07:11:37.623765 139849920552000 utils.py:844] [35m[150][0m nimg = 22.351091384887695
I0128 07:11:37.624168 139849920552000 utils.py:844] [35m[150][0m ntxt = 22.612375259399414
I0128 07:11:37.624590 139849920552000 utils.py:844] [35m[150][0m t = 14.285693168640137
I0128 07:11:37.624986 139849920552000 utils.py:844] [35m[150][0m t/parameter = 2.6592600345611572
I0128 07:11:37.625084 139849920552000 utils.py:844] [35m[150][0m uptime = 844.6468527530087
I0128 07:11:37.625173 139849920552000 utils.py:844] [35m[150][0m examples_seen = 2400.0
I0128 07:11:37.625234 139849920552000 utils.py:844] [35m[150][0m progress = 1.3075769726977928e-06
I0128 07:11:37.625278 139849920552000 utils.py:844] [35m[150][0m epoch = 9.1530388437921e-06
I0128 07:11:37.625327 139849920552000 utils.py:844] [35m[150][0m img/sec/core = 41.05532022387154
I0128 07:11:37.625423 139849920552000 utils.py:844] [35m[150][0m core_hours_TPU v3 = 1.3434673252132618
I0128 07:11:37.625476 139849920552000 utils.py:844] [35m[150][0m core_hours = 1.3434673252132618
I0128 07:11:37.625557 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:150/114716000 [0.0%]
Walltime:14m5s (0s eval)
ETA:131051h52m
Total train time:131052h2m
I0128 07:11:39.413281 139849920552000 utils.py:844] [35m[200][0m global_schedule = 6.0729980759788305e-05
I0128 07:11:40.323693 139849920552000 utils.py:844] [35m[200][0m training_loss = 2.820991039276123
I0128 07:11:40.324835 139849920552000 utils.py:844] [35m[200][0m l2_grad_cls = 89.66168212890625
I0128 07:11:40.325465 139849920552000 utils.py:844] [35m[200][0m l2_grad_embeding = 3.7852835655212402
I0128 07:11:40.325945 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_0 = 2.6727890968322754
I0128 07:11:40.326397 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_1 = 1.6763880252838135
I0128 07:11:40.326798 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_10 = 0.5332444310188293
I0128 07:11:40.327351 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_11 = 0.49957767128944397
I0128 07:11:40.327757 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_2 = 1.2474944591522217
I0128 07:11:40.328160 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_3 = 1.0631120204925537
I0128 07:11:40.328524 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_4 = 0.8942607641220093
I0128 07:11:40.329039 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_5 = 0.8046367168426514
I0128 07:11:40.329436 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_6 = 0.7066158056259155
I0128 07:11:40.329845 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_7 = 0.6634886264801025
I0128 07:11:40.330253 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_8 = 0.6184630990028381
I0128 07:11:40.330742 139849920552000 utils.py:844] [35m[200][0m l2_grad_encoderblock_9 = 0.5742112398147583
I0128 07:11:40.331209 139849920552000 utils.py:844] [35m[200][0m l2_grad_head = 2.2366943359375
I0128 07:11:40.331681 139849920552000 utils.py:844] [35m[200][0m l2_grads = 93.03656005859375
I0128 07:11:40.332123 139849920552000 utils.py:844] [35m[200][0m l2_params = 371.71875
I0128 07:11:40.332545 139849920552000 utils.py:844] [35m[200][0m l2_updates = 0.0
I0128 07:11:40.332975 139849920552000 utils.py:844] [35m[200][0m ncorrect = 0.0
I0128 07:11:40.333419 139849920552000 utils.py:844] [35m[200][0m nimg = 22.30337142944336
I0128 07:11:40.333808 139849920552000 utils.py:844] [35m[200][0m ntxt = 22.702049255371094
I0128 07:11:40.334238 139849920552000 utils.py:844] [35m[200][0m t = 14.285693168640137
I0128 07:11:40.334661 139849920552000 utils.py:844] [35m[200][0m t/parameter = 2.6592600345611572
I0128 07:11:40.334764 139849920552000 utils.py:844] [35m[200][0m uptime = 847.3565306340461
I0128 07:11:40.334862 139849920552000 utils.py:844] [35m[200][0m examples_seen = 3200.0
I0128 07:11:40.334945 139849920552000 utils.py:844] [35m[200][0m progress = 1.743435963597057e-06
I0128 07:11:40.335011 139849920552000 utils.py:844] [35m[200][0m epoch = 1.22040517917228e-05
I0128 07:11:40.335058 139849920552000 utils.py:844] [35m[200][0m img/sec/core = 36.904755616825135
I0128 07:11:40.335150 139849920552000 utils.py:844] [35m[200][0m core_hours_TPU v3 = 1.3494888316155669
I0128 07:11:40.335202 139849920552000 utils.py:844] [35m[200][0m core_hours = 1.3494888316155669
I0128 07:11:40.335290 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:200/114716000 [0.0%]
Walltime:14m7s (0s eval)
ETA:98228h13m
Total train time:98228h24m
I0128 07:11:42.132533 139849920552000 utils.py:844] [35m[250][0m global_schedule = 7.59887698222883e-05
I0128 07:11:42.938416 139849920552000 utils.py:844] [35m[250][0m training_loss = 2.8919601440429688
I0128 07:11:42.939584 139849920552000 utils.py:844] [35m[250][0m l2_grad_cls = 139.1043243408203
I0128 07:11:42.940202 139849920552000 utils.py:844] [35m[250][0m l2_grad_embeding = 4.389039516448975
I0128 07:11:42.940667 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_0 = 2.8312647342681885
I0128 07:11:42.941208 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_1 = 1.8971484899520874
I0128 07:11:42.941674 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_10 = 0.6098876595497131
I0128 07:11:42.942135 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_11 = 0.5751340985298157
I0128 07:11:42.942560 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_2 = 1.4094244241714478
I0128 07:11:42.943016 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_3 = 1.200069546699524
I0128 07:11:42.943481 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_4 = 1.0292302370071411
I0128 07:11:42.943993 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_5 = 0.9176063537597656
I0128 07:11:42.944355 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_6 = 0.8180113434791565
I0128 07:11:42.944856 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_7 = 0.7423892617225647
I0128 07:11:42.945243 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_8 = 0.6959190964698792
I0128 07:11:42.945679 139849920552000 utils.py:844] [35m[250][0m l2_grad_encoderblock_9 = 0.6491823792457581
I0128 07:11:42.946071 139849920552000 utils.py:844] [35m[250][0m l2_grad_head = 2.825019121170044
I0128 07:11:42.946565 139849920552000 utils.py:844] [35m[250][0m l2_grads = 141.99038696289062
I0128 07:11:42.947027 139849920552000 utils.py:844] [35m[250][0m l2_params = 371.71875
I0128 07:11:42.947588 139849920552000 utils.py:844] [35m[250][0m l2_updates = 0.0
I0128 07:11:42.947976 139849920552000 utils.py:844] [35m[250][0m ncorrect = 0.0
I0128 07:11:42.948464 139849920552000 utils.py:844] [35m[250][0m nimg = 22.172603607177734
I0128 07:11:42.948883 139849920552000 utils.py:844] [35m[250][0m ntxt = 22.334300994873047
I0128 07:11:42.949311 139849920552000 utils.py:844] [35m[250][0m t = 14.285693168640137
I0128 07:11:42.949721 139849920552000 utils.py:844] [35m[250][0m t/parameter = 2.6592600345611572
I0128 07:11:42.949826 139849920552000 utils.py:844] [35m[250][0m uptime = 849.9715940810274
I0128 07:11:42.949916 139849920552000 utils.py:844] [35m[250][0m examples_seen = 4000.0
I0128 07:11:42.949977 139849920552000 utils.py:844] [35m[250][0m progress = 2.1792949544963212e-06
I0128 07:11:42.950026 139849920552000 utils.py:844] [35m[250][0m epoch = 1.5255064739653499e-05
I0128 07:11:42.950077 139849920552000 utils.py:844] [35m[250][0m img/sec/core = 38.23998997631683
I0128 07:11:42.950166 139849920552000 utils.py:844] [35m[250][0m core_hours_TPU v3 = 1.35530008371997
I0128 07:11:42.950217 139849920552000 utils.py:844] [35m[250][0m core_hours = 1.35530008371997
I0128 07:11:42.950300 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:250/114716000 [0.0%]
Walltime:14m10s (0s eval)
ETA:78681h18m
Total train time:78681h28m
I0128 07:11:44.761061 139849920552000 utils.py:844] [35m[300][0m global_schedule = 9.12475588847883e-05
I0128 07:11:45.434647 139849920552000 utils.py:844] [35m[300][0m training_loss = 2.7894091606140137
I0128 07:11:45.436044 139849920552000 utils.py:844] [35m[300][0m l2_grad_cls = 33.986019134521484
I0128 07:11:45.436736 139849920552000 utils.py:844] [35m[300][0m l2_grad_embeding = 2.8923518657684326
I0128 07:11:45.437259 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_0 = 2.0852789878845215
I0128 07:11:45.437734 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_1 = 1.46853506565094
I0128 07:11:45.438160 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_10 = 0.4913690686225891
I0128 07:11:45.438588 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_11 = 0.46227583289146423
I0128 07:11:45.439054 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_2 = 1.125293254852295
I0128 07:11:45.439456 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_3 = 0.960446834564209
I0128 07:11:45.439835 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_4 = 0.7985830903053284
I0128 07:11:45.440344 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_5 = 0.7165953516960144
I0128 07:11:45.440731 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_6 = 0.648157000541687
I0128 07:11:45.441118 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_7 = 0.5944698452949524
I0128 07:11:45.441528 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_8 = 0.5547996163368225
I0128 07:11:45.441964 139849920552000 utils.py:844] [35m[300][0m l2_grad_encoderblock_9 = 0.5323672294616699
I0128 07:11:45.442376 139849920552000 utils.py:844] [35m[300][0m l2_grad_head = 2.105664014816284
I0128 07:11:45.442784 139849920552000 utils.py:844] [35m[300][0m l2_grads = 40.93853759765625
I0128 07:11:45.443195 139849920552000 utils.py:844] [35m[300][0m l2_params = 371.71875
I0128 07:11:45.443599 139849920552000 utils.py:844] [35m[300][0m l2_updates = 0.0
I0128 07:11:45.443978 139849920552000 utils.py:844] [35m[300][0m ncorrect = 0.0625
I0128 07:11:45.444344 139849920552000 utils.py:844] [35m[300][0m nimg = 22.29012680053711
I0128 07:11:45.444752 139849920552000 utils.py:844] [35m[300][0m ntxt = 22.30712890625
I0128 07:11:45.445332 139849920552000 utils.py:844] [35m[300][0m t = 14.285693168640137
I0128 07:11:45.445735 139849920552000 utils.py:844] [35m[300][0m t/parameter = 2.6592600345611572
I0128 07:11:45.445839 139849920552000 utils.py:844] [35m[300][0m uptime = 852.4676061110222
I0128 07:11:45.445935 139849920552000 utils.py:844] [35m[300][0m examples_seen = 4800.0
I0128 07:11:45.446000 139849920552000 utils.py:844] [35m[300][0m progress = 2.6151539453955856e-06
I0128 07:11:45.446052 139849920552000 utils.py:844] [35m[300][0m epoch = 1.83060776875842e-05
I0128 07:11:45.446105 139849920552000 utils.py:844] [35m[300][0m img/sec/core = 40.06390946770018
I0128 07:11:45.446200 139849920552000 utils.py:844] [35m[300][0m core_hours_TPU v3 = 1.3608467771199584
I0128 07:11:45.446272 139849920552000 utils.py:844] [35m[300][0m core_hours = 1.3608467771199584
I0128 07:11:45.446359 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:300/114716000 [0.0%]
Walltime:14m12s (0s eval)
ETA:65703h4m
Total train time:65703h14m
I0128 07:11:47.281643 139849920552000 utils.py:844] [35m[350][0m global_schedule = 0.0001065063479472883
I0128 07:11:48.157818 139849920552000 utils.py:844] [35m[350][0m training_loss = 2.8920063972473145
I0128 07:11:48.159008 139849920552000 utils.py:844] [35m[350][0m l2_grad_cls = 100.77310180664062
I0128 07:11:48.159694 139849920552000 utils.py:844] [35m[350][0m l2_grad_embeding = 3.747096538543701
I0128 07:11:48.160178 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_0 = 2.5084309577941895
I0128 07:11:48.160703 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_1 = 1.6746915578842163
I0128 07:11:48.161127 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_10 = 0.5771352052688599
I0128 07:11:48.161546 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_11 = 0.5452855825424194
I0128 07:11:48.162020 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_2 = 1.3140816688537598
I0128 07:11:48.162461 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_3 = 1.1147122383117676
I0128 07:11:48.162909 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_4 = 0.9508393406867981
I0128 07:11:48.163344 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_5 = 0.8535112142562866
I0128 07:11:48.163770 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_6 = 0.7537612318992615
I0128 07:11:48.164277 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_7 = 0.703118085861206
I0128 07:11:48.164678 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_8 = 0.6471167206764221
I0128 07:11:48.165193 139849920552000 utils.py:844] [35m[350][0m l2_grad_encoderblock_9 = 0.6117864847183228
I0128 07:11:48.165569 139849920552000 utils.py:844] [35m[350][0m l2_grad_head = 2.4592061042785645
I0128 07:11:48.166102 139849920552000 utils.py:844] [35m[350][0m l2_grads = 104.27092742919922
I0128 07:11:48.166507 139849920552000 utils.py:844] [35m[350][0m l2_params = 371.71875
I0128 07:11:48.167006 139849920552000 utils.py:844] [35m[350][0m l2_updates = 0.0
I0128 07:11:48.167385 139849920552000 utils.py:844] [35m[350][0m ncorrect = 0.1875
I0128 07:11:48.167889 139849920552000 utils.py:844] [35m[350][0m nimg = 22.24635887145996
I0128 07:11:48.168311 139849920552000 utils.py:844] [35m[350][0m ntxt = 22.454233169555664
I0128 07:11:48.168747 139849920552000 utils.py:844] [35m[350][0m t = 14.285693168640137
I0128 07:11:48.169124 139849920552000 utils.py:844] [35m[350][0m t/parameter = 2.6592600345611572
I0128 07:11:48.169228 139849920552000 utils.py:844] [35m[350][0m uptime = 855.190993797034
I0128 07:11:48.169318 139849920552000 utils.py:844] [35m[350][0m examples_seen = 5600.0
I0128 07:11:48.169382 139849920552000 utils.py:844] [35m[350][0m progress = 3.05101293629485e-06
I0128 07:11:48.169433 139849920552000 utils.py:844] [35m[350][0m epoch = 2.13570906355149e-05
I0128 07:11:48.169486 139849920552000 utils.py:844] [35m[350][0m img/sec/core = 36.71897339979564
I0128 07:11:48.169586 139849920552000 utils.py:844] [35m[350][0m core_hours_TPU v3 = 1.36689874975554
I0128 07:11:48.169640 139849920552000 utils.py:844] [35m[350][0m core_hours = 1.36689874975554
I0128 07:11:48.169736 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:350/114716000 [0.0%]
Walltime:14m15s (0s eval)
ETA:56485h50m
Total train time:56486h0m
I0128 07:11:50.024390 139849920552000 utils.py:844] [35m[400][0m global_schedule = 0.0001217651370097883
I0128 07:11:50.706838 139849920552000 utils.py:844] [35m[400][0m training_loss = 2.7559075355529785
I0128 07:11:50.707779 139849920552000 utils.py:844] [35m[400][0m l2_grad_cls = 43.7204475402832
I0128 07:11:50.708482 139849920552000 utils.py:844] [35m[400][0m l2_grad_embeding = 3.417769193649292
I0128 07:11:50.709016 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_0 = 2.1586594581604004
I0128 07:11:50.709595 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_1 = 1.5716389417648315
I0128 07:11:50.710044 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_10 = 0.5907543897628784
I0128 07:11:50.710689 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_11 = 0.5643148422241211
I0128 07:11:50.711205 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_2 = 1.2547460794448853
I0128 07:11:50.711654 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_3 = 1.0737130641937256
I0128 07:11:50.712131 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_4 = 0.924704372882843
I0128 07:11:50.712601 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_5 = 0.8466178774833679
I0128 07:11:50.713078 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_6 = 0.7575109004974365
I0128 07:11:50.713519 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_7 = 0.6918375492095947
I0128 07:11:50.713970 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_8 = 0.6743146181106567
I0128 07:11:50.714540 139849920552000 utils.py:844] [35m[400][0m l2_grad_encoderblock_9 = 0.6277515292167664
I0128 07:11:50.714984 139849920552000 utils.py:844] [35m[400][0m l2_grad_head = 2.8001527786254883
I0128 07:11:50.715432 139849920552000 utils.py:844] [35m[400][0m l2_grads = 52.48955535888672
I0128 07:11:50.715845 139849920552000 utils.py:844] [35m[400][0m l2_params = 371.71875
I0128 07:11:50.716389 139849920552000 utils.py:844] [35m[400][0m l2_updates = 0.0
I0128 07:11:50.716797 139849920552000 utils.py:844] [35m[400][0m ncorrect = 0.0
I0128 07:11:50.717195 139849920552000 utils.py:844] [35m[400][0m nimg = 22.107025146484375
I0128 07:11:50.717629 139849920552000 utils.py:844] [35m[400][0m ntxt = 22.3265323638916
I0128 07:11:50.718096 139849920552000 utils.py:844] [35m[400][0m t = 14.285693168640137
I0128 07:11:50.718605 139849920552000 utils.py:844] [35m[400][0m t/parameter = 2.6592600345611572
I0128 07:11:50.718735 139849920552000 utils.py:844] [35m[400][0m uptime = 857.740493105026
I0128 07:11:50.718840 139849920552000 utils.py:844] [35m[400][0m examples_seen = 6400.0
I0128 07:11:50.718900 139849920552000 utils.py:844] [35m[400][0m progress = 3.486871927194114e-06
I0128 07:11:50.718961 139849920552000 utils.py:844] [35m[400][0m epoch = 2.44081035834456e-05
I0128 07:11:50.719013 139849920552000 utils.py:844] [35m[400][0m img/sec/core = 39.223387779133404
I0128 07:11:50.719105 139849920552000 utils.py:844] [35m[400][0m core_hours_TPU v3 = 1.3725643037733
I0128 07:11:50.719158 139849920552000 utils.py:844] [35m[400][0m core_hours = 1.3725643037733
I0128 07:11:50.719240 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:400/114716000 [0.0%]
Walltime:14m18s (0s eval)
ETA:49576h21m
Total train time:49576h32m
I0128 07:11:52.951974 139849920552000 utils.py:844] [35m[450][0m global_schedule = 0.0001370239187963307
I0128 07:11:53.345197 139849920552000 utils.py:844] [35m[450][0m training_loss = 2.9531078338623047
I0128 07:11:53.346553 139849920552000 utils.py:844] [35m[450][0m l2_grad_cls = 107.12299346923828
I0128 07:11:53.347254 139849920552000 utils.py:844] [35m[450][0m l2_grad_embeding = 4.150561332702637
I0128 07:11:53.347772 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_0 = 2.9885308742523193
I0128 07:11:53.348331 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_1 = 1.9922668933868408
I0128 07:11:53.348777 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_10 = 0.6484769582748413
I0128 07:11:53.349227 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_11 = 0.6102973222732544
I0128 07:11:53.349654 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_2 = 1.4806878566741943
I0128 07:11:53.350204 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_3 = 1.2748501300811768
I0128 07:11:53.350659 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_4 = 1.094555139541626
I0128 07:11:53.351205 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_5 = 0.9731783866882324
I0128 07:11:53.351641 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_6 = 0.8569758534431458
I0128 07:11:53.352262 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_7 = 0.7950119376182556
I0128 07:11:53.352729 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_8 = 0.7414471507072449
I0128 07:11:53.353219 139849920552000 utils.py:844] [35m[450][0m l2_grad_encoderblock_9 = 0.7030655741691589
I0128 07:11:53.353665 139849920552000 utils.py:844] [35m[450][0m l2_grad_head = 2.8070666790008545
I0128 07:11:53.354134 139849920552000 utils.py:844] [35m[450][0m l2_grads = 111.46913146972656
I0128 07:11:53.354576 139849920552000 utils.py:844] [35m[450][0m l2_params = 371.71875
I0128 07:11:53.354996 139849920552000 utils.py:844] [35m[450][0m l2_updates = 0.0
I0128 07:11:53.355380 139849920552000 utils.py:844] [35m[450][0m ncorrect = 0.0625
I0128 07:11:53.355916 139849920552000 utils.py:844] [35m[450][0m nimg = 22.436046600341797
I0128 07:11:53.356335 139849920552000 utils.py:844] [35m[450][0m ntxt = 22.33349609375
I0128 07:11:53.356776 139849920552000 utils.py:844] [35m[450][0m t = 14.285693168640137
I0128 07:11:53.357192 139849920552000 utils.py:844] [35m[450][0m t/parameter = 2.6592600345611572
I0128 07:11:53.357306 139849920552000 utils.py:844] [35m[450][0m uptime = 860.3790716990479
I0128 07:11:53.357399 139849920552000 utils.py:844] [35m[450][0m examples_seen = 7200.0
I0128 07:11:53.357479 139849920552000 utils.py:844] [35m[450][0m progress = 3.922730918093378e-06
I0128 07:11:53.357553 139849920552000 utils.py:844] [35m[450][0m epoch = 2.7459116531376297e-05
I0128 07:11:53.357612 139849920552000 utils.py:844] [35m[450][0m img/sec/core = 37.899193234782814
I0128 07:11:53.357715 139849920552000 utils.py:844] [35m[450][0m core_hours_TPU v3 = 1.3784278117600155
I0128 07:11:53.357776 139849920552000 utils.py:844] [35m[450][0m core_hours = 1.3784278117600155
I0128 07:11:53.357868 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:450/114716000 [0.0%]
Walltime:14m20s (0s eval)
ETA:44218h59m
Total train time:44219h9m
I0128 07:11:55.209648 139849920552000 utils.py:844] [35m[500][0m global_schedule = 0.0001522827078588307
I0128 07:11:55.926552 139849920552000 utils.py:844] [35m[500][0m training_loss = 2.890796661376953
I0128 07:11:55.927584 139849920552000 utils.py:844] [35m[500][0m l2_grad_cls = 31.28554344177246
I0128 07:11:55.928230 139849920552000 utils.py:844] [35m[500][0m l2_grad_embeding = 2.808631420135498
I0128 07:11:55.928784 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_0 = 1.8502930402755737
I0128 07:11:55.929260 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_1 = 1.2951641082763672
I0128 07:11:55.929670 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_10 = 0.47355663776397705
I0128 07:11:55.930220 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_11 = 0.4492041766643524
I0128 07:11:55.930642 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_2 = 1.0162529945373535
I0128 07:11:55.931095 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_3 = 0.8646194338798523
I0128 07:11:55.931507 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_4 = 0.7499435544013977
I0128 07:11:55.932036 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_5 = 0.6774545311927795
I0128 07:11:55.932548 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_6 = 0.6029883027076721
I0128 07:11:55.932989 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_7 = 0.5583257079124451
I0128 07:11:55.933427 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_8 = 0.5363632440567017
I0128 07:11:55.933890 139849920552000 utils.py:844] [35m[500][0m l2_grad_encoderblock_9 = 0.501246988773346
I0128 07:11:55.934379 139849920552000 utils.py:844] [35m[500][0m l2_grad_head = 2.1941707134246826
I0128 07:11:55.934795 139849920552000 utils.py:844] [35m[500][0m l2_grads = 39.85414505004883
I0128 07:11:55.935186 139849920552000 utils.py:844] [35m[500][0m l2_params = 371.71875
I0128 07:11:55.935707 139849920552000 utils.py:844] [35m[500][0m l2_updates = 0.0
I0128 07:11:55.936142 139849920552000 utils.py:844] [35m[500][0m ncorrect = 0.0
I0128 07:11:55.936558 139849920552000 utils.py:844] [35m[500][0m nimg = 22.18828010559082
I0128 07:11:55.936965 139849920552000 utils.py:844] [35m[500][0m ntxt = 22.346317291259766
I0128 07:11:55.937417 139849920552000 utils.py:844] [35m[500][0m t = 14.285693168640137
I0128 07:11:55.937927 139849920552000 utils.py:844] [35m[500][0m t/parameter = 2.6592600345611572
I0128 07:11:55.938040 139849920552000 utils.py:844] [35m[500][0m uptime = 862.9598052640213
I0128 07:11:55.938138 139849920552000 utils.py:844] [35m[500][0m examples_seen = 8000.0
I0128 07:11:55.938206 139849920552000 utils.py:844] [35m[500][0m progress = 4.3585899089926425e-06
I0128 07:11:55.938267 139849920552000 utils.py:844] [35m[500][0m epoch = 3.0510129479306997e-05
I0128 07:11:55.938320 139849920552000 utils.py:844] [35m[500][0m img/sec/core = 38.74867260891882
I0128 07:11:55.938417 139849920552000 utils.py:844] [35m[500][0m core_hours_TPU v3 = 1.3841627752377341
I0128 07:11:55.938476 139849920552000 utils.py:844] [35m[500][0m core_hours = 1.3841627752377341
I0128 07:11:55.938564 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:500/114716000 [0.0%]
Walltime:14m23s (0s eval)
ETA:39935h50m
Total train time:39936h1m
I0128 07:11:57.798800 139849920552000 utils.py:844] [35m[550][0m global_schedule = 0.0001675414969213307
I0128 07:11:58.442306 139849920552000 utils.py:844] [35m[550][0m training_loss = 2.735543727874756
I0128 07:11:58.443280 139849920552000 utils.py:844] [35m[550][0m l2_grad_cls = 42.652801513671875
I0128 07:11:58.443942 139849920552000 utils.py:844] [35m[550][0m l2_grad_embeding = 2.9991133213043213
I0128 07:11:58.444483 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_0 = 2.017672538757324
I0128 07:11:58.445030 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_1 = 1.456618070602417
I0128 07:11:58.445453 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_10 = 0.5025801062583923
I0128 07:11:58.445944 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_11 = 0.4693745970726013
I0128 07:11:58.446363 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_2 = 1.1178430318832397
I0128 07:11:58.446889 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_3 = 0.9544892907142639
I0128 07:11:58.447331 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_4 = 0.8052675127983093
I0128 07:11:58.447801 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_5 = 0.7318409085273743
I0128 07:11:58.448189 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_6 = 0.647354781627655
I0128 07:11:58.448724 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_7 = 0.5932137966156006
I0128 07:11:58.449145 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_8 = 0.5621258616447449
I0128 07:11:58.449586 139849920552000 utils.py:844] [35m[550][0m l2_grad_encoderblock_9 = 0.5342047214508057
I0128 07:11:58.449978 139849920552000 utils.py:844] [35m[550][0m l2_grad_head = 2.0830371379852295
I0128 07:11:58.450503 139849920552000 utils.py:844] [35m[550][0m l2_grads = 48.198585510253906
I0128 07:11:58.450909 139849920552000 utils.py:844] [35m[550][0m l2_params = 371.71875
I0128 07:11:58.451334 139849920552000 utils.py:844] [35m[550][0m l2_updates = 0.0
I0128 07:11:58.451705 139849920552000 utils.py:844] [35m[550][0m ncorrect = 0.125
I0128 07:11:58.452105 139849920552000 utils.py:844] [35m[550][0m nimg = 22.134422302246094
I0128 07:11:58.452545 139849920552000 utils.py:844] [35m[550][0m ntxt = 22.39141082763672
I0128 07:11:58.453025 139849920552000 utils.py:844] [35m[550][0m t = 14.285693168640137
I0128 07:11:58.453423 139849920552000 utils.py:844] [35m[550][0m t/parameter = 2.6592600345611572
I0128 07:11:58.453534 139849920552000 utils.py:844] [35m[550][0m uptime = 865.4752991750138
I0128 07:11:58.453630 139849920552000 utils.py:844] [35m[550][0m examples_seen = 8800.0
I0128 07:11:58.453701 139849920552000 utils.py:844] [35m[550][0m progress = 4.794448899891907e-06
I0128 07:11:58.453752 139849920552000 utils.py:844] [35m[550][0m epoch = 3.35611424272377e-05
I0128 07:11:58.453817 139849920552000 utils.py:844] [35m[550][0m img/sec/core = 39.75362435305749
I0128 07:11:58.453920 139849920552000 utils.py:844] [35m[550][0m core_hours_TPU v3 = 1.3897527617066063
I0128 07:11:58.453981 139849920552000 utils.py:844] [35m[550][0m core_hours = 1.3897527617066063
I0128 07:11:58.454073 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:550/114716000 [0.0%]
Walltime:14m25s (0s eval)
ETA:36431h55m
Total train time:36432h6m
flexi_args: [15]
flexi_args: [8]
flexi_args: [15]
flexi_args: [12]
flexi_args: [15]
flexi_args: [30]
flexi_args: [8]
flexi_args: [16]
flexi_args: [24]
flexi_args: [30]
flexi_args: [8]
flexi_args: [10]
flexi_args: [12]
flexi_args: [8]
flexi_args: [24]
flexi_args: [12]
flexi_args: [5]
flexi_args: [12]
flexi_args: [16]
flexi_args: [10]
flexi_args: [6]
flexi_args: [24]
flexi_args: [16]
flexi_args: [10]
flexi_args: [20]
flexi_args: [16]
flexi_args: [6]
flexi_args: [6]
flexi_args: [5]
flexi_args: [16]
flexi_args: [15]
flexi_args: [12]
flexi_args: [20]
flexi_args: [16]
flexi_args: [5]
flexi_args: [5]
flexi_args: [10]
flexi_args: [16]
flexi_args: [8]
flexi_args: [15]
flexi_args: [16]
flexi_args: [6]
flexi_args: [12]
flexi_args: [15]
flexi_args: [24]
flexi_args: [16]
flexi_args: [20]
flexi_args: [15]
flexi_args: [5]
flexi_args: [5]
flexi_args: [12]
flexi_args: [10]
flexi_args: [30]
flexi_args: [16]
flexi_args: [8]
flexi_args: [8]
flexi_args: [15]
flexi_args: [6]
flexi_args: [12]
flexi_args: [24]
flexi_args: [20]
flexi_args: [24]
flexi_args: [16]
flexi_args: [5]
flexi_args: [5]
flexi_args: [15]
flexi_args: [15]
flexi_args: [8]
flexi_args: [6]
flexi_args: [10]
flexi_args: [10]
flexi_args: [12]
flexi_args: [24]
flexi_args: [8]
flexi_args: [12]
flexi_args: [24]
flexi_args: [12]
flexi_args: [30]
flexi_args: [24]
flexi_args: [24]
flexi_args: [5]
flexi_args: [24]
flexi_args: [5]
flexi_args: [12]
flexi_args: [30]
flexi_args: [20]
flexi_args: [20]
flexi_args: [16]
flexi_args: [6]
flexi_args: [6]
flexi_args: [8]
flexi_args: [12]
flexi_args: [30]
flexi_args: [12]
flexi_args: [10]
flexi_args: [30]
flexi_args: [6]
flexi_args: [8]
flexi_args: [24]
flexi_args: [10]
flexi_args: [10]
flexi_args: [16]
flexi_args: [15]
flexi_args: [16]
flexi_args: [15]
flexi_args: [24]
flexi_args: [30]
flexi_args: [5]
flexi_args: [5]
flexi_args: [24]
flexi_args: [20]
flexi_args: [5]
flexi_args: [12]
flexi_args: [30]
flexi_args: [12]
flexi_args: [30]
flexi_args: [20]
flexi_args: [20]
flexi_args: [6]
flexi_args: [24]
flexi_args: [30]
flexi_args: [24]
flexi_args: [6]
flexi_args: [24]
flexi_args: [6]
flexi_args: [12]
flexi_args: [5]
flexi_args: [10]
flexi_args: [20]
flexi_args: [10]
flexi_args: [24]
flexi_args: [30]
flexi_args: [24]
flexi_args: [8]
flexi_args: [10]
flexi_args: [5]
flexi_args: [24]
flexi_args: [10]
flexi_args: [20]
flexi_args: [16]
flexi_args: [20]
flexi_args: [30]
flexi_args: [15]
flexi_args: [12]
flexi_args: [5]
flexi_args: [6]
flexi_args: [12]
flexi_args: [15]
flexi_args: [12]
flexi_args: [6]
flexi_args: [30]
flexi_args: [15]
flexi_args: [12]
flexi_args: [30]
flexi_args: [30]
flexi_args: [30]
flexi_args: [16]
flexi_args: [12]
flexi_args: [10]
flexi_args: [5]
flexi_args: [30]
flexi_args: [15]
flexi_args: [15]
flexi_args: [16]
flexi_args: [15]
flexi_args: [8]
flexi_args: [12]
flexi_args: [15]
flexi_args: [8]
flexi_args: [8]
flexi_args: [12]
flexi_args: [10]
flexi_args: [15]
flexi_args: [5]
flexi_args: [16]
flexi_args: [8]
flexi_args: [12]
flexi_args: [24]
flexi_args: [20]
flexi_args: [6]
flexi_args: [10]
flexi_args: [12]
flexi_args: [6]
flexi_args: [8]
flexi_args: [16]
flexi_args: [5]
flexi_args: [8]
flexi_args: [10]
flexi_args: [20]
flexi_args: [6]
flexi_args: [30]
flexi_args: [24]
flexi_args: [24]
flexi_args: [30]
flexi_args: [16]
flexi_args: [12]
flexi_args: [20]
flexi_args: [12]
flexi_args: [30]
flexi_args: [8]
flexi_args: [15]
flexi_args: [20]
flexi_args: [8]
flexi_args: [10]
flexi_args: [16]
flexi_args: [15]
flexi_args: [5]
flexi_args: [10]
flexi_args: [8]
flexi_args: [10]
flexi_args: [30]
flexi_args: [10]
flexi_args: [8]
flexi_args: [16]
flexi_args: [5]
flexi_args: [20]
flexi_args: [15]
flexi_args: [12]
flexi_args: [10]
flexi_args: [5]
flexi_args: [10]
flexi_args: [6]
flexi_args: [5]
flexi_args: [8]
flexi_args: [24]
flexi_args: [30]
flexi_args: [16]
flexi_args: [10]
flexi_args: [6]
flexi_args: [5]
flexi_args: [6]
flexi_args: [15]
flexi_args: [24]
flexi_args: [6]
flexi_args: [15]
flexi_args: [20]
flexi_args: [10]
flexi_args: [8]
flexi_args: [24]
flexi_args: [15]
flexi_args: [30]
flexi_args: [6]
flexi_args: [30]
flexi_args: [8]
flexi_args: [15]
flexi_args: [6]
flexi_args: [20]
flexi_args: [30]
flexi_args: [24]
flexi_args: [10]
flexi_args: [24]
flexi_args: [8]
flexi_args: [6]
flexi_args: [16]
flexi_args: [6]
flexi_args: [10]
flexi_args: [12]
flexi_args: [30]
flexi_args: [24]
flexi_args: [6]
flexi_args: [24]
flexi_args: [30]
flexi_args: [15]
flexi_args: [8]
flexi_args: [30]
flexi_args: [6]
flexi_args: [5]
flexi_args: [30]
flexi_args: [15]
flexi_args: [24]
flexi_args: [24]
flexi_args: [20]
flexi_args: [12]
flexi_args: [8]
flexi_args: [20]
flexi_args: [30]
flexi_args: [6]
flexi_args: [10]
flexi_args: [10]
flexi_args: [15]
flexi_args: [5]
flexi_args: [15]
flexi_args: [10]
flexi_args: [12]
flexi_args: [8]
flexi_args: [24]
flexi_args: [15]
flexi_args: [20]
flexi_args: [24]
flexi_args: [12]
flexi_args: [5]
flexi_args: [10]
flexi_args: [15]
flexi_args: [16]
flexi_args: [10]
flexi_args: [12]
flexi_args: [15]
flexi_args: [15]
flexi_args: [12]
flexi_args: [20]
flexi_args: [15]
flexi_args: [6]
flexi_args: [30]
flexi_args: [20]
flexi_args: [16]
flexi_args: [15]
flexi_args: [20]
flexi_args: [15]
flexi_args: [20]
flexi_args: [8]
flexi_args: [15]
flexi_args: [30]
flexi_args: [16]
flexi_args: [15]
flexi_args: [16]
flexi_args: [16]
flexi_args: [16]
flexi_args: [5]
flexi_args: [24]
flexi_args: [5]
flexi_args: [6]
flexi_args: [16]
flexi_args: [30]
flexi_args: [12]
flexi_args: [8]
flexi_args: [30]
flexi_args: [6]
flexi_args: [30]
flexi_args: [5]
flexi_args: [24]
flexi_args: [6]
flexi_args: [20]
flexi_args: [20]
flexi_args: [12]
flexi_args: [6]
flexi_args: [5]
flexi_args: [8]
flexi_args: [15]
flexi_args: [24]
flexi_args: [5]
flexi_args: [10]
flexi_args: [24]
flexi_args: [12]
flexi_args: [12]
flexi_args: [24]
flexi_args: [8]
flexi_args: [15]
flexi_args: [30]
flexi_args: [12]
flexi_args: [20]
flexi_args: [12]
flexi_args: [8]
flexi_args: [30]
flexi_args: [30]
flexi_args: [30]
flexi_args: [8]
flexi_args: [20]
flexi_args: [24]
flexi_args: [5]
flexi_args: [6]
flexi_args: [10]
flexi_args: [30]
flexi_args: [15]
flexi_args: [30]
flexi_args: [12]
flexi_args: [24]
flexi_args: [20]
flexi_args: [12]
flexi_args: [16]
flexi_args: [10]
flexi_args: [20]
flexi_args: [10]
flexi_args: [15]
flexi_args: [16]
flexi_args: [16]
flexi_args: [5]
flexi_args: [15]
flexi_args: [15]
flexi_args: [16]
flexi_args: [6]
flexi_args: [24]
flexi_args: [8]
flexi_args: [8]
flexi_args: [5]
flexi_args: [16]
flexi_args: [5]
flexi_args: [30]
flexi_args: [5]
flexi_args: [30]
flexi_args: [10]
flexi_args: [20]
flexi_args: [20]
flexi_args: [16]
flexi_args: [16]
flexi_args: [20]
flexi_args: [12]
flexi_args: [20]
flexi_args: [15]
flexi_args: [6]
flexi_args: [5]
flexi_args: [16]
flexi_args: [20]
flexi_args: [24]
flexi_args: [15]
flexi_args: [12]
flexi_args: [6]
flexi_args: [16]
flexi_args: [24]
flexi_args: [16]
flexi_args: [24]
flexi_args: [16]
flexi_args: [30]
flexi_args: [20]
flexi_args: [6]
flexi_args: [5]
flexi_args: [10]
flexi_args: [16]
flexi_args: [10]
flexi_args: [20]
flexi_args: [8]
flexi_args: [20]
flexi_args: [12]
flexi_args: [6]
flexi_args: [30]
flexi_args: [12]
flexi_args: [6]
flexi_args: [5]
flexi_args: [10]
flexi_args: [30]
flexi_args: [20]
flexi_args: [5]
flexi_args: [16]
flexi_args: [15]
flexi_args: [16]
flexi_args: [24]
flexi_args: [20]
flexi_args: [6]
flexi_args: [15]
flexi_args: [20]
flexi_args: [12]
flexi_args: [20]
flexi_args: [5]
flexi_args: [10]
flexi_args: [15]
flexi_args: [8]
flexi_args: [30]
flexi_args: [5]
flexi_args: [30]
flexi_args: [24]
flexi_args: [16]
flexi_args: [6]
flexi_args: [5]
flexi_args: [12]
flexi_args: [6]
flexi_args: [12]
flexi_args: [12]
flexi_args: [12]
flexi_args: [5]
flexi_args: [30]
flexi_args: [8]
flexi_args: [20]
flexi_args: [8]
flexi_args: [6]
flexi_args: [6]
flexi_args: [6]
flexi_args: [16]
flexi_args: [12]
flexi_args: [30]
flexi_args: [24]
flexi_args: [6]
flexi_args: [10]
flexi_args: [10]
flexi_args: [6]
flexi_args: [16]
flexi_args: [12]
flexi_args: [24]
flexi_args: [24]
flexi_args: [15]
flexi_args: [5]
flexi_args: [6]
flexi_args: [10]
flexi_args: [6]
flexi_args: [12]
flexi_args: [24]
flexi_args: [15]
flexi_args: [8]
flexi_args: [8]
flexi_args: [24]
flexi_args: [20]
flexi_args: [20]
I0128 07:12:00.342802 139849920552000 utils.py:844] [35m[600][0m global_schedule = 0.0001828002859838307
I0128 07:12:00.991178 139849920552000 utils.py:844] [35m[600][0m training_loss = 2.774677276611328
I0128 07:12:00.992521 139849920552000 utils.py:844] [35m[600][0m l2_grad_cls = 76.21371459960938
I0128 07:12:00.993208 139849920552000 utils.py:844] [35m[600][0m l2_grad_embeding = 3.6461689472198486
I0128 07:12:00.993800 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_0 = 2.309011220932007
I0128 07:12:00.994287 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_1 = 1.5459884405136108
I0128 07:12:00.994727 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_10 = 0.5295290350914001
I0128 07:12:00.995221 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_11 = 0.5014140009880066
I0128 07:12:00.995682 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_2 = 1.1793042421340942
I0128 07:12:00.996099 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_3 = 0.9719637036323547
I0128 07:12:00.996471 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_4 = 0.8432905077934265
I0128 07:12:00.997046 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_5 = 0.7608077526092529
I0128 07:12:00.997507 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_6 = 0.6796982288360596
I0128 07:12:00.997973 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_7 = 0.6306204199790955
I0128 07:12:00.998394 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_8 = 0.594018280506134
I0128 07:12:00.998895 139849920552000 utils.py:844] [35m[600][0m l2_grad_encoderblock_9 = 0.5505291223526001
I0128 07:12:00.999322 139849920552000 utils.py:844] [35m[600][0m l2_grad_head = 2.328611135482788
I0128 07:12:00.999835 139849920552000 utils.py:844] [35m[600][0m l2_grads = 80.1750259399414
I0128 07:12:01.000245 139849920552000 utils.py:844] [35m[600][0m l2_params = 371.71875
I0128 07:12:01.000657 139849920552000 utils.py:844] [35m[600][0m l2_updates = 0.0
I0128 07:12:01.001054 139849920552000 utils.py:844] [35m[600][0m ncorrect = 0.0625
I0128 07:12:01.001447 139849920552000 utils.py:844] [35m[600][0m nimg = 22.2895450592041
I0128 07:12:01.001822 139849920552000 utils.py:844] [35m[600][0m ntxt = 22.22056770324707
I0128 07:12:01.002211 139849920552000 utils.py:844] [35m[600][0m t = 14.285693168640137
I0128 07:12:01.002642 139849920552000 utils.py:844] [35m[600][0m t/parameter = 2.6592600345611572
I0128 07:12:01.002754 139849920552000 utils.py:844] [35m[600][0m uptime = 868.0245190220303
I0128 07:12:01.002851 139849920552000 utils.py:844] [35m[600][0m examples_seen = 9600.0
I0128 07:12:01.002950 139849920552000 utils.py:844] [35m[600][0m progress = 5.230307890791171e-06
I0128 07:12:01.003012 139849920552000 utils.py:844] [35m[600][0m epoch = 3.66121553751684e-05
I0128 07:12:01.003069 139849920552000 utils.py:844] [35m[600][0m img/sec/core = 39.227687685326835
I0128 07:12:01.003190 139849920552000 utils.py:844] [35m[600][0m core_hours_TPU v3 = 1.3954176946999763
I0128 07:12:01.003252 139849920552000 utils.py:844] [35m[600][0m core_hours = 1.3954176946999763
I0128 07:12:01.003343 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:600/114716000 [0.0%]
Walltime:14m28s (0s eval)
ETA:33516h43m
Total train time:33516h54m
I0128 07:12:02.884037 139849920552000 utils.py:844] [35m[650][0m global_schedule = 0.0001980590750463307
I0128 07:12:03.540672 139849920552000 utils.py:844] [35m[650][0m training_loss = 2.826028347015381
I0128 07:12:03.541838 139849920552000 utils.py:844] [35m[650][0m l2_grad_cls = 47.739383697509766
I0128 07:12:03.542439 139849920552000 utils.py:844] [35m[650][0m l2_grad_embeding = 2.6940066814422607
I0128 07:12:03.542972 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_0 = 1.731616497039795
I0128 07:12:03.543483 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_1 = 1.237872838973999
I0128 07:12:03.543964 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_10 = 0.4513792097568512
I0128 07:12:03.544425 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_11 = 0.42242133617401123
I0128 07:12:03.544859 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_2 = 0.9611485600471497
I0128 07:12:03.545379 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_3 = 0.825738251209259
I0128 07:12:03.545796 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_4 = 0.7131919860839844
I0128 07:12:03.546292 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_5 = 0.6465979814529419
I0128 07:12:03.546656 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_6 = 0.5590516924858093
I0128 07:12:03.547193 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_7 = 0.5293682813644409
I0128 07:12:03.547744 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_8 = 0.508506178855896
I0128 07:12:03.548317 139849920552000 utils.py:844] [35m[650][0m l2_grad_encoderblock_9 = 0.4747171401977539
I0128 07:12:03.548763 139849920552000 utils.py:844] [35m[650][0m l2_grad_head = 1.960295557975769
I0128 07:12:03.549309 139849920552000 utils.py:844] [35m[650][0m l2_grads = 51.82969284057617
I0128 07:12:03.549843 139849920552000 utils.py:844] [35m[650][0m l2_params = 371.71875
I0128 07:12:03.550258 139849920552000 utils.py:844] [35m[650][0m l2_updates = 0.0
I0128 07:12:03.550642 139849920552000 utils.py:844] [35m[650][0m ncorrect = 0.0625
I0128 07:12:03.551157 139849920552000 utils.py:844] [35m[650][0m nimg = 22.230955123901367
I0128 07:12:03.551693 139849920552000 utils.py:844] [35m[650][0m ntxt = 22.595638275146484
I0128 07:12:03.552122 139849920552000 utils.py:844] [35m[650][0m t = 14.285693168640137
I0128 07:12:03.552527 139849920552000 utils.py:844] [35m[650][0m t/parameter = 2.6592600345611572
I0128 07:12:03.552655 139849920552000 utils.py:844] [35m[650][0m uptime = 870.5744194810395
I0128 07:12:03.552753 139849920552000 utils.py:844] [35m[650][0m examples_seen = 10400.0
I0128 07:12:03.552823 139849920552000 utils.py:844] [35m[650][0m progress = 5.666166881690436e-06
I0128 07:12:03.552886 139849920552000 utils.py:844] [35m[650][0m epoch = 3.96631683230991e-05
I0128 07:12:03.552945 139849920552000 utils.py:844] [35m[650][0m img/sec/core = 39.21721714535301
I0128 07:12:03.553040 139849920552000 utils.py:844] [35m[650][0m core_hours_TPU v3 = 1.4010841401644414
I0128 07:12:03.553098 139849920552000 utils.py:844] [35m[650][0m core_hours = 1.4010841401644414
I0128 07:12:03.553189 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:650/114716000 [0.0%]
Walltime:14m31s (0s eval)
ETA:31052h8m
Total train time:31052h18m
I0128 07:12:05.424984 139849920552000 utils.py:844] [35m[700][0m global_schedule = 0.0002133178641088307
I0128 07:12:06.187207 139849920552000 utils.py:844] [35m[700][0m training_loss = 2.863002061843872
I0128 07:12:06.188249 139849920552000 utils.py:844] [35m[700][0m l2_grad_cls = 133.83262634277344
I0128 07:12:06.188963 139849920552000 utils.py:844] [35m[700][0m l2_grad_embeding = 4.286238193511963
I0128 07:12:06.189491 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_0 = 2.840949058532715
I0128 07:12:06.189943 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_1 = 1.8768121004104614
I0128 07:12:06.190332 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_10 = 0.6055521965026855
I0128 07:12:06.190753 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_11 = 0.5709973573684692
I0128 07:12:06.191265 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_2 = 1.4547665119171143
I0128 07:12:06.191747 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_3 = 1.2174193859100342
I0128 07:12:06.192140 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_4 = 1.0156502723693848
I0128 07:12:06.192568 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_5 = 0.8899592161178589
I0128 07:12:06.192995 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_6 = 0.7890251874923706
I0128 07:12:06.193426 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_7 = 0.728495717048645
I0128 07:12:06.193821 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_8 = 0.6889305710792542
I0128 07:12:06.194249 139849920552000 utils.py:844] [35m[700][0m l2_grad_encoderblock_9 = 0.6530001759529114
I0128 07:12:06.194658 139849920552000 utils.py:844] [35m[700][0m l2_grad_head = 2.5458855628967285
I0128 07:12:06.195120 139849920552000 utils.py:844] [35m[700][0m l2_grads = 136.7632293701172
I0128 07:12:06.195511 139849920552000 utils.py:844] [35m[700][0m l2_params = 371.71875
I0128 07:12:06.195895 139849920552000 utils.py:844] [35m[700][0m l2_updates = 0.0
I0128 07:12:06.196289 139849920552000 utils.py:844] [35m[700][0m ncorrect = 0.0625
I0128 07:12:06.196680 139849920552000 utils.py:844] [35m[700][0m nimg = 22.453144073486328
I0128 07:12:06.197029 139849920552000 utils.py:844] [35m[700][0m ntxt = 22.543346405029297
I0128 07:12:06.197418 139849920552000 utils.py:844] [35m[700][0m t = 14.285693168640137
I0128 07:12:06.197879 139849920552000 utils.py:844] [35m[700][0m t/parameter = 2.6592600345611572
I0128 07:12:06.197992 139849920552000 utils.py:844] [35m[700][0m uptime = 873.2197569910204
I0128 07:12:06.198092 139849920552000 utils.py:844] [35m[700][0m examples_seen = 11200.0
I0128 07:12:06.198160 139849920552000 utils.py:844] [35m[700][0m progress = 6.1020258725897e-06
I0128 07:12:06.198212 139849920552000 utils.py:844] [35m[700][0m epoch = 4.27141812710298e-05
I0128 07:12:06.198269 139849920552000 utils.py:844] [35m[700][0m img/sec/core = 37.80235966968252
I0128 07:12:06.198363 139849920552000 utils.py:844] [35m[700][0m core_hours_TPU v3 = 1.406962667964399
I0128 07:12:06.198421 139849920552000 utils.py:844] [35m[700][0m core_hours = 1.406962667964399
I0128 07:12:06.198513 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:700/114716000 [0.0%]
Walltime:14m33s (0s eval)
ETA:28945h30m
Total train time:28945h40m
I0128 07:12:08.076933 139849920552000 utils.py:844] [35m[750][0m global_schedule = 0.0002285766531713307
I0128 07:12:08.924212 139849920552000 utils.py:844] [35m[750][0m training_loss = 2.6883935928344727
I0128 07:12:08.925233 139849920552000 utils.py:844] [35m[750][0m l2_grad_cls = 142.34457397460938
I0128 07:12:08.925963 139849920552000 utils.py:844] [35m[750][0m l2_grad_embeding = 4.025557518005371
I0128 07:12:08.926469 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_0 = 2.756072521209717
I0128 07:12:08.927057 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_1 = 1.851801872253418
I0128 07:12:08.927599 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_10 = 0.6081729531288147
I0128 07:12:08.928218 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_11 = 0.5749663710594177
I0128 07:12:08.928651 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_2 = 1.4530686140060425
I0128 07:12:08.929342 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_3 = 1.2155086994171143
I0128 07:12:08.929821 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_4 = 1.013922929763794
I0128 07:12:08.930353 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_5 = 0.8961962461471558
I0128 07:12:08.930752 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_6 = 0.8044590353965759
I0128 07:12:08.931293 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_7 = 0.7393836379051208
I0128 07:12:08.931728 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_8 = 0.6986632943153381
I0128 07:12:08.932275 139849920552000 utils.py:844] [35m[750][0m l2_grad_encoderblock_9 = 0.6452474594116211
I0128 07:12:08.932680 139849920552000 utils.py:844] [35m[750][0m l2_grad_head = 2.520270347595215
I0128 07:12:08.933161 139849920552000 utils.py:844] [35m[750][0m l2_grads = 144.72494506835938
I0128 07:12:08.933623 139849920552000 utils.py:844] [35m[750][0m l2_params = 371.71875
I0128 07:12:08.934086 139849920552000 utils.py:844] [35m[750][0m l2_updates = 0.0
I0128 07:12:08.934559 139849920552000 utils.py:844] [35m[750][0m ncorrect = 0.0
I0128 07:12:08.935004 139849920552000 utils.py:844] [35m[750][0m nimg = 22.41002655029297
I0128 07:12:08.935426 139849920552000 utils.py:844] [35m[750][0m ntxt = 22.34270668029785
I0128 07:12:08.935836 139849920552000 utils.py:844] [35m[750][0m t = 14.285693168640137
I0128 07:12:08.936264 139849920552000 utils.py:844] [35m[750][0m t/parameter = 2.6592600345611572
I0128 07:12:08.936367 139849920552000 utils.py:844] [35m[750][0m uptime = 875.9581339890137
I0128 07:12:08.936457 139849920552000 utils.py:844] [35m[750][0m examples_seen = 12000.0
I0128 07:12:08.936522 139849920552000 utils.py:844] [35m[750][0m progress = 6.537884863488964e-06
I0128 07:12:08.936573 139849920552000 utils.py:844] [35m[750][0m epoch = 4.57651942189605e-05
I0128 07:12:08.936626 139849920552000 utils.py:844] [35m[750][0m img/sec/core = 36.517981298148364
I0128 07:12:08.936722 139849920552000 utils.py:844] [35m[750][0m core_hours_TPU v3 = 1.4130479501821618
I0128 07:12:08.936775 139849920552000 utils.py:844] [35m[750][0m core_hours = 1.4130479501821618
I0128 07:12:08.936858 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:750/114716000 [0.0%]
Walltime:14m36s (0s eval)
ETA:27124h51m
Total train time:27125h2m
I0128 07:12:11.202897 139849920552000 utils.py:844] [35m[800][0m global_schedule = 0.0002438354422338307
I0128 07:12:11.326231 139849920552000 utils.py:844] [35m[800][0m training_loss = 2.782468318939209
I0128 07:12:11.327123 139849920552000 utils.py:844] [35m[800][0m l2_grad_cls = 116.24127197265625
I0128 07:12:11.327839 139849920552000 utils.py:844] [35m[800][0m l2_grad_embeding = 3.807621717453003
I0128 07:12:11.328350 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_0 = 2.7171974182128906
I0128 07:12:11.328943 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_1 = 1.9303488731384277
I0128 07:12:11.329348 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_10 = 0.6441450715065002
I0128 07:12:11.329799 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_11 = 0.6017059683799744
I0128 07:12:11.330285 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_2 = 1.4753170013427734
I0128 07:12:11.330718 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_3 = 1.268189549446106
I0128 07:12:11.331131 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_4 = 1.0684020519256592
I0128 07:12:11.331624 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_5 = 0.9455042481422424
I0128 07:12:11.332061 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_6 = 0.8411766886711121
I0128 07:12:11.332615 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_7 = 0.7918844223022461
I0128 07:12:11.333093 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_8 = 0.7325267791748047
I0128 07:12:11.333669 139849920552000 utils.py:844] [35m[800][0m l2_grad_encoderblock_9 = 0.6968494057655334
I0128 07:12:11.334148 139849920552000 utils.py:844] [35m[800][0m l2_grad_head = 2.7416739463806152
I0128 07:12:11.334614 139849920552000 utils.py:844] [35m[800][0m l2_grads = 119.53748321533203
I0128 07:12:11.335045 139849920552000 utils.py:844] [35m[800][0m l2_params = 371.71875
I0128 07:12:11.335497 139849920552000 utils.py:844] [35m[800][0m l2_updates = 0.0
I0128 07:12:11.335916 139849920552000 utils.py:844] [35m[800][0m ncorrect = 0.0625
I0128 07:12:11.336313 139849920552000 utils.py:844] [35m[800][0m nimg = 22.302597045898438
I0128 07:12:11.336688 139849920552000 utils.py:844] [35m[800][0m ntxt = 22.881671905517578
I0128 07:12:11.337084 139849920552000 utils.py:844] [35m[800][0m t = 14.285693168640137
I0128 07:12:11.337505 139849920552000 utils.py:844] [35m[800][0m t/parameter = 2.6592600345611572
I0128 07:12:11.337638 139849920552000 utils.py:844] [35m[800][0m uptime = 878.359404376999
I0128 07:12:11.337744 139849920552000 utils.py:844] [35m[800][0m examples_seen = 12800.0
I0128 07:12:11.337816 139849920552000 utils.py:844] [35m[800][0m progress = 6.973743854388228e-06
I0128 07:12:11.337874 139849920552000 utils.py:844] [35m[800][0m epoch = 4.88162071668912e-05
I0128 07:12:11.337932 139849920552000 utils.py:844] [35m[800][0m img/sec/core = 41.644622988043565
I0128 07:12:11.338035 139849920552000 utils.py:844] [35m[800][0m core_hours_TPU v3 = 1.4183841065999068
I0128 07:12:11.338096 139849920552000 utils.py:844] [35m[800][0m core_hours = 1.4183841065999068
I0128 07:12:11.338191 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:800/114716000 [0.0%]
Walltime:14m38s (0s eval)
ETA:25519h10m
Total train time:25519h20m
I0128 07:12:13.214769 139849920552000 utils.py:844] [35m[850][0m global_schedule = 0.0002590942312963307
I0128 07:12:14.040992 139849920552000 utils.py:844] [35m[850][0m training_loss = 2.8332901000976562
I0128 07:12:14.042235 139849920552000 utils.py:844] [35m[850][0m l2_grad_cls = 78.91609191894531
I0128 07:12:14.042823 139849920552000 utils.py:844] [35m[850][0m l2_grad_embeding = 3.6050572395324707
I0128 07:12:14.043373 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_0 = 2.608224868774414
I0128 07:12:14.043886 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_1 = 1.7907541990280151
I0128 07:12:14.044349 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_10 = 0.6173762083053589
I0128 07:12:14.044829 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_11 = 0.5883368253707886
I0128 07:12:14.045280 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_2 = 1.3989518880844116
I0128 07:12:14.045758 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_3 = 1.1791003942489624
I0128 07:12:14.046168 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_4 = 0.9949535131454468
I0128 07:12:14.046686 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_5 = 0.897769033908844
I0128 07:12:14.047065 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_6 = 0.796485424041748
I0128 07:12:14.047516 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_7 = 0.7434070706367493
I0128 07:12:14.047939 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_8 = 0.6957290768623352
I0128 07:12:14.048466 139849920552000 utils.py:844] [35m[850][0m l2_grad_encoderblock_9 = 0.6577420234680176
I0128 07:12:14.048856 139849920552000 utils.py:844] [35m[850][0m l2_grad_head = 2.7488443851470947
I0128 07:12:14.049305 139849920552000 utils.py:844] [35m[850][0m l2_grads = 84.39563751220703
I0128 07:12:14.049732 139849920552000 utils.py:844] [35m[850][0m l2_params = 371.71875
I0128 07:12:14.050243 139849920552000 utils.py:844] [35m[850][0m l2_updates = 0.0
I0128 07:12:14.050632 139849920552000 utils.py:844] [35m[850][0m ncorrect = 0.0625
I0128 07:12:14.051080 139849920552000 utils.py:844] [35m[850][0m nimg = 22.397682189941406
I0128 07:12:14.051556 139849920552000 utils.py:844] [35m[850][0m ntxt = 22.63030242919922
I0128 07:12:14.052091 139849920552000 utils.py:844] [35m[850][0m t = 14.285693168640137
I0128 07:12:14.052487 139849920552000 utils.py:844] [35m[850][0m t/parameter = 2.6592600345611572
I0128 07:12:14.052589 139849920552000 utils.py:844] [35m[850][0m uptime = 881.074356503028
I0128 07:12:14.052696 139849920552000 utils.py:844] [35m[850][0m examples_seen = 13600.0
I0128 07:12:14.052773 139849920552000 utils.py:844] [35m[850][0m progress = 7.4096028452874925e-06
I0128 07:12:14.052822 139849920552000 utils.py:844] [35m[850][0m epoch = 5.18672201148219e-05
I0128 07:12:14.052871 139849920552000 utils.py:844] [35m[850][0m img/sec/core = 36.83306200550432
I0128 07:12:14.052968 139849920552000 utils.py:844] [35m[850][0m core_hours_TPU v3 = 1.424417333546638
I0128 07:12:14.053023 139849920552000 utils.py:844] [35m[850][0m core_hours = 1.424417333546638
I0128 07:12:14.053107 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:850/114716000 [0.0%]
Walltime:14m41s (0s eval)
ETA:24114h51m
Total train time:24115h1m
I0128 07:12:15.936949 139849920552000 utils.py:844] [35m[900][0m global_schedule = 0.0002743530203588307
I0128 07:12:16.719780 139849920552000 utils.py:844] [35m[900][0m training_loss = 2.8587255477905273
I0128 07:12:16.721060 139849920552000 utils.py:844] [35m[900][0m l2_grad_cls = 36.04519271850586
I0128 07:12:16.721769 139849920552000 utils.py:844] [35m[900][0m l2_grad_embeding = 3.9028677940368652
I0128 07:12:16.722354 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_0 = 2.581247329711914
I0128 07:12:16.722971 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_1 = 1.832256555557251
I0128 07:12:16.723468 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_10 = 0.6230213642120361
I0128 07:12:16.724092 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_11 = 0.5848354697227478
I0128 07:12:16.724635 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_2 = 1.4261330366134644
I0128 07:12:16.725210 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_3 = 1.186915636062622
I0128 07:12:16.725728 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_4 = 1.020284652709961
I0128 07:12:16.726275 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_5 = 0.9205155372619629
I0128 07:12:16.726694 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_6 = 0.811851441860199
I0128 07:12:16.727348 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_7 = 0.7669004797935486
I0128 07:12:16.727838 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_8 = 0.71469646692276
I0128 07:12:16.728319 139849920552000 utils.py:844] [35m[900][0m l2_grad_encoderblock_9 = 0.6539029479026794
I0128 07:12:16.728784 139849920552000 utils.py:844] [35m[900][0m l2_grad_head = 2.729182720184326
I0128 07:12:16.729229 139849920552000 utils.py:844] [35m[900][0m l2_grads = 45.1988525390625
I0128 07:12:16.729661 139849920552000 utils.py:844] [35m[900][0m l2_params = 371.71875
I0128 07:12:16.730205 139849920552000 utils.py:844] [35m[900][0m l2_updates = 0.0
I0128 07:12:16.730637 139849920552000 utils.py:844] [35m[900][0m ncorrect = 0.0
I0128 07:12:16.731039 139849920552000 utils.py:844] [35m[900][0m nimg = 22.229503631591797
I0128 07:12:16.731437 139849920552000 utils.py:844] [35m[900][0m ntxt = 22.440017700195312
I0128 07:12:16.732033 139849920552000 utils.py:844] [35m[900][0m t = 14.285693168640137
I0128 07:12:16.732466 139849920552000 utils.py:844] [35m[900][0m t/parameter = 2.6592600345611572
I0128 07:12:16.732574 139849920552000 utils.py:844] [35m[900][0m uptime = 883.7543397429981
I0128 07:12:16.732664 139849920552000 utils.py:844] [35m[900][0m examples_seen = 14400.0
I0128 07:12:16.732730 139849920552000 utils.py:844] [35m[900][0m progress = 7.845461836186756e-06
I0128 07:12:16.732780 139849920552000 utils.py:844] [35m[900][0m epoch = 5.4918233062752594e-05
I0128 07:12:16.732846 139849920552000 utils.py:844] [35m[900][0m img/sec/core = 37.31366618587998
I0128 07:12:16.732948 139849920552000 utils.py:844] [35m[900][0m core_hours_TPU v3 = 1.4303728518576828
I0128 07:12:16.733006 139849920552000 utils.py:844] [35m[900][0m core_hours = 1.4303728518576828
I0128 07:12:16.733091 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:900/114716000 [0.0%]
Walltime:14m44s (0s eval)
ETA:22865h51m
Total train time:22866h1m
I0128 07:12:18.616146 139849920552000 utils.py:844] [35m[950][0m global_schedule = 0.0002896118094213307
I0128 07:12:19.289618 139849920552000 utils.py:844] [35m[950][0m training_loss = 2.767882823944092
I0128 07:12:19.291324 139849920552000 utils.py:844] [35m[950][0m l2_grad_cls = 44.463077545166016
I0128 07:12:19.292036 139849920552000 utils.py:844] [35m[950][0m l2_grad_embeding = 3.38102650642395
I0128 07:12:19.292535 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_0 = 2.1558480262756348
I0128 07:12:19.292999 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_1 = 1.4792673587799072
I0128 07:12:19.293483 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_10 = 0.5266214609146118
I0128 07:12:19.294008 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_11 = 0.497740238904953
I0128 07:12:19.294464 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_2 = 1.1270700693130493
I0128 07:12:19.294919 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_3 = 0.9565801024436951
I0128 07:12:19.295422 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_4 = 0.8246084451675415
I0128 07:12:19.295890 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_5 = 0.7366271615028381
I0128 07:12:19.296252 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_6 = 0.6704179048538208
I0128 07:12:19.296768 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_7 = 0.6248456835746765
I0128 07:12:19.297214 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_8 = 0.5886318683624268
I0128 07:12:19.297662 139849920552000 utils.py:844] [35m[950][0m l2_grad_encoderblock_9 = 0.5622085332870483
I0128 07:12:19.298073 139849920552000 utils.py:844] [35m[950][0m l2_grad_head = 2.4888253211975098
I0128 07:12:19.298497 139849920552000 utils.py:844] [35m[950][0m l2_grads = 51.70957565307617
I0128 07:12:19.298968 139849920552000 utils.py:844] [35m[950][0m l2_params = 371.71875
I0128 07:12:19.299355 139849920552000 utils.py:844] [35m[950][0m l2_updates = 0.0
I0128 07:12:19.299717 139849920552000 utils.py:844] [35m[950][0m ncorrect = 0.0
I0128 07:12:19.300093 139849920552000 utils.py:844] [35m[950][0m nimg = 22.420621871948242
I0128 07:12:19.300623 139849920552000 utils.py:844] [35m[950][0m ntxt = 22.193408966064453
I0128 07:12:19.301049 139849920552000 utils.py:844] [35m[950][0m t = 14.285693168640137
I0128 07:12:19.301428 139849920552000 utils.py:844] [35m[950][0m t/parameter = 2.6592600345611572
I0128 07:12:19.301541 139849920552000 utils.py:844] [35m[950][0m uptime = 886.3233089550049
I0128 07:12:19.301627 139849920552000 utils.py:844] [35m[950][0m examples_seen = 15200.0
I0128 07:12:19.301689 139849920552000 utils.py:844] [35m[950][0m progress = 8.28132082708602e-06
I0128 07:12:19.301733 139849920552000 utils.py:844] [35m[950][0m epoch = 5.7969246010683294e-05
I0128 07:12:19.301777 139849920552000 utils.py:844] [35m[950][0m img/sec/core = 38.92611851190071
I0128 07:12:19.301874 139849920552000 utils.py:844] [35m[950][0m core_hours_TPU v3 = 1.4360816723288088
I0128 07:12:19.301929 139849920552000 utils.py:844] [35m[950][0m core_hours = 1.4360816723288088
I0128 07:12:19.302010 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:950/114716000 [0.0%]
Walltime:14m46s (0s eval)
ETA:21745h0m
Total train time:21745h11m
I0128 07:12:21.192168 139849920552000 utils.py:844] [35m[1000][0m global_schedule = 0.0003048705984838307
I0128 07:12:21.838559 139849920552000 utils.py:844] [35m[1000][0m training_loss = 2.7804160118103027
I0128 07:12:21.839671 139849920552000 utils.py:844] [35m[1000][0m l2_grad_cls = 41.20121383666992
I0128 07:12:21.840322 139849920552000 utils.py:844] [35m[1000][0m l2_grad_embeding = 2.6944050788879395
I0128 07:12:21.840898 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_0 = 1.69856858253479
I0128 07:12:21.841322 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_1 = 1.1465833187103271
I0128 07:12:21.841721 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_10 = 0.4134193956851959
I0128 07:12:21.842281 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_11 = 0.3892713487148285
I0128 07:12:21.842818 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_2 = 0.8757309913635254
I0128 07:12:21.843286 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_3 = 0.7648152709007263
I0128 07:12:21.843689 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_4 = 0.6525629758834839
I0128 07:12:21.844137 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_5 = 0.5963806509971619
I0128 07:12:21.844557 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_6 = 0.5325294137001038
I0128 07:12:21.844974 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_7 = 0.488779217004776
I0128 07:12:21.845376 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_8 = 0.45490381121635437
I0128 07:12:21.845764 139849920552000 utils.py:844] [35m[1000][0m l2_grad_encoderblock_9 = 0.4350269138813019
I0128 07:12:21.846143 139849920552000 utils.py:844] [35m[1000][0m l2_grad_head = 1.781343698501587
I0128 07:12:21.846515 139849920552000 utils.py:844] [35m[1000][0m l2_grads = 45.48244857788086
I0128 07:12:21.846880 139849920552000 utils.py:844] [35m[1000][0m l2_params = 371.71875
I0128 07:12:21.847425 139849920552000 utils.py:844] [35m[1000][0m l2_updates = 0.0
I0128 07:12:21.847824 139849920552000 utils.py:844] [35m[1000][0m ncorrect = 0.0
I0128 07:12:21.848213 139849920552000 utils.py:844] [35m[1000][0m nimg = 22.243595123291016
I0128 07:12:21.848589 139849920552000 utils.py:844] [35m[1000][0m ntxt = 22.407007217407227
I0128 07:12:21.849101 139849920552000 utils.py:844] [35m[1000][0m t = 14.285693168640137
I0128 07:12:21.849620 139849920552000 utils.py:844] [35m[1000][0m t/parameter = 2.6592600345611572
I0128 07:12:21.849723 139849920552000 utils.py:844] [35m[1000][0m uptime = 888.8714903450455
I0128 07:12:21.849817 139849920552000 utils.py:844] [35m[1000][0m examples_seen = 16000.0
I0128 07:12:21.849882 139849920552000 utils.py:844] [35m[1000][0m progress = 8.717179817985285e-06
I0128 07:12:21.849930 139849920552000 utils.py:844] [35m[1000][0m epoch = 6.1020258958613994e-05
I0128 07:12:21.849978 139849920552000 utils.py:844] [35m[1000][0m img/sec/core = 39.24367409276484
I0128 07:12:21.850070 139849920552000 utils.py:844] [35m[1000][0m core_hours_TPU v3 = 1.44174429764001
I0128 07:12:21.850124 139849920552000 utils.py:844] [35m[1000][0m core_hours = 1.44174429764001
I0128 07:12:21.850208 139849920552000 flexi_main.py:120] [33mNOTE[0m: Steps:1000/114716000 [0.0%]
Walltime:14m49s (0s eval)
ETA:20735h55m
Total train time:20736h6m
I0128 07:12:23.373503 139849920552000 flexi_main.py:120] [33mNOTE[0m: disclf evaluation...
Steps:1000/114716000 [0.0%]
Walltime:14m49s (0s eval)
ETA:20735h55m
Total train time:20736h6m
I0128 07:12:23.373709 139849920552000 discriminative_classifier.py:348] Starting text embedding...
I0128 07:12:26.814446 139849920552000 discriminative_classifier.py:365] Compiled text embeddings in 3.4s
tcmalloc: large alloc 1642618880 bytes == 0xf86936000 @  0x7f3159382680 0x7f31593a2da2 0x5d6aec 0x63908c 0x4fe616 0x4daf8a 0x547447 0x5d5846 0x547447 0x54552a 0x5d5a23 0x5483b6 0x54552a 0x5d5a23 0x547265 0x54552a 0x5d5a23 0x5d4c12 0x7f315136ccf3 0x5d553a 0x5d6066 0x54ca58 0x54552a 0x5d5a23 0x5d4c12 0x548a66 0x54552a 0x5d5a23 0x5d4c12 0x548a66 0x54552a
I0128 07:13:11.333433 139849920552000 discriminative_classifier.py:383] Embedded imagenet2012 text in 5064 steps - ...[16 16 16 16 16 16 16 16  8  0]
I0128 07:13:11.334235 139849920552000 discriminative_classifier.py:385] Totalling 81000 text in 44.5s
I0128 07:13:11.334320 139849920552000 discriminative_classifier.py:386] Total texts embeddings size 165.9M
I0128 07:13:11.441235 139849920552000 discriminative_classifier.py:400] Starting image embedding...
Traceback (most recent call last):
  File "/home/jyang347/CLIPA/clipa_jax/flexi_main.py", line 649, in <module>
    app.run(main)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/jyang347/CLIPA/clipa_jax/flexi_main.py", line 610, in main
    for key, value in evaluator.run(params_repl):
  File "/home/jyang347/CLIPA/clipa_jax/evaluators/proj/image_text/discriminative_classifier.py", line 470, in run
    return [(f"{dataset_name}_accuracy",
  File "/home/jyang347/CLIPA/clipa_jax/evaluators/proj/image_text/discriminative_classifier.py", line 471, in <listcomp>
    self.evaluate(params, dataset_name)["accuracy"])
  File "/home/jyang347/CLIPA/clipa_jax/evaluators/proj/image_text/discriminative_classifier.py", line 423, in evaluate
    correct_p, embs_p = self._count_correct_p(
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/api.py", line 2395, in cache_miss
    execute = pxla.xla_pmap_impl_lazy(fun_, *tracers, **params)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py", line 1021, in xla_pmap_impl_lazy
    compiled_fun, fingerprint = parallel_callable(
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/linear_util.py", line 301, in memoized_fun
    ans = call(fun, *args)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py", line 1297, in parallel_callable
    pmap_computation = lower_parallel_callable(
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/profiler.py", line 314, in wrapper
    return func(*args, **kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py", line 1461, in lower_parallel_callable
    jaxpr, consts, replicas, parts, shards = stage_parallel_callable(
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py", line 1374, in stage_parallel_callable
    jaxpr, out_sharded_avals, consts = pe.trace_to_jaxpr_final(
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/profiler.py", line 314, in wrapper
    return func(*args, **kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/interpreters/partial_eval.py", line 2099, in trace_to_jaxpr_final
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/interpreters/partial_eval.py", line 2046, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/linear_util.py", line 165, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/home/jyang347/CLIPA/clipa_jax/evaluators/proj/image_text/discriminative_classifier.py", line 302, in count_correct
    zimg, _, _ = predict_fn(params, image, None)
  File "/home/jyang347/CLIPA/clipa_jax/flexi_main.py", line 445, in predict_fn
    zimg, ztxt, out = model.apply({"params": params}, image, text)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/flax/linen/module.py", line 1511, in apply
    return apply(
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/flax/core/scope.py", line 934, in wrapper
    y = fn(root, *args, **kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/flax/linen/module.py", line 2082, in scope_fn
    return fn(module.clone(parent=scope, _deep_clone=True), *args, **kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/flax/linen/module.py", line 418, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/flax/linen/module.py", line 854, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/models/two_towers.py", line 98, in __call__
    zimg, out_img = image_model(
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/flax/linen/module.py", line 418, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/flax/linen/module.py", line 854, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/models/flexi_model.py", line 132, in __call__
    x = out["stem"] = Patchify(
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/flax/linen/module.py", line 418, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/flax/linen/module.py", line 854, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/home/jyang347/CLIPA/clipa_jax/models/flexi_model.py", line 99, in __call__
    patch_size = tuple(np.array((h, w)) // np.array((seqhw, seqhw)))
jax._src.traceback_util.UnfilteredStackTrace: TypeError: unsupported operand type(s) for //: 'int' and 'NoneType'

The stack trace below excludes JAX-internal frames.
The preceding is the original exception that occurred, unmodified.

--------------------

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/jyang347/CLIPA/clipa_jax/flexi_main.py", line 649, in <module>
    app.run(main)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/jyang347/CLIPA/clipa_jax/flexi_main.py", line 610, in main
    for key, value in evaluator.run(params_repl):
  File "/home/jyang347/CLIPA/clipa_jax/evaluators/proj/image_text/discriminative_classifier.py", line 470, in run
    return [(f"{dataset_name}_accuracy",
  File "/home/jyang347/CLIPA/clipa_jax/evaluators/proj/image_text/discriminative_classifier.py", line 471, in <listcomp>
    self.evaluate(params, dataset_name)["accuracy"])
  File "/home/jyang347/CLIPA/clipa_jax/evaluators/proj/image_text/discriminative_classifier.py", line 423, in evaluate
    correct_p, embs_p = self._count_correct_p(
  File "/home/jyang347/CLIPA/clipa_jax/evaluators/proj/image_text/discriminative_classifier.py", line 302, in count_correct
    zimg, _, _ = predict_fn(params, image, None)
  File "/home/jyang347/CLIPA/clipa_jax/flexi_main.py", line 445, in predict_fn
    zimg, ztxt, out = model.apply({"params": params}, image, text)
  File "/home/jyang347/CLIPA/clipa_jax/models/two_towers.py", line 98, in __call__
    zimg, out_img = image_model(
  File "/home/jyang347/CLIPA/clipa_jax/models/flexi_model.py", line 132, in __call__
    x = out["stem"] = Patchify(
  File "/home/jyang347/CLIPA/clipa_jax/models/flexi_model.py", line 99, in __call__
    patch_size = tuple(np.array((h, w)) // np.array((seqhw, seqhw)))
TypeError: unsupported operand type(s) for //: 'int' and 'NoneType'
flexi_args: [15]
flexi_args: [16]
flexi_args: [5]
flexi_args: [8]
flexi_args: [12]
flexi_args: [30]
flexi_args: [20]
flexi_args: [8]
flexi_args: [5]
flexi_args: [16]
flexi_args: [12]
flexi_args: [16]
flexi_args: [8]
flexi_args: [20]
flexi_args: [30]
flexi_args: [24]
flexi_args: [30]
flexi_args: [24]
flexi_args: [30]
flexi_args: [20]
flexi_args: [10]
flexi_args: [5]
flexi_args: [10]
flexi_args: [15]
flexi_args: [16]
flexi_args: [15]
flexi_args: [6]
flexi_args: [15]
flexi_args: [8]
flexi_args: [16]
flexi_args: [20]
flexi_args: [5]
flexi_args: [12]
flexi_args: [6]
flexi_args: [8]
flexi_args: [10]
flexi_args: [8]
flexi_args: [12]
flexi_args: [30]
flexi_args: [24]
flexi_args: [12]
flexi_args: [20]
flexi_args: [10]
flexi_args: [10]
flexi_args: [16]
flexi_args: [8]
flexi_args: [10]
flexi_args: [16]
flexi_args: [8]
flexi_args: [8]
flexi_args: [15]
flexi_args: [24]
flexi_args: [8]
flexi_args: [10]
flexi_args: [6]
flexi_args: [8]
flexi_args: [20]
flexi_args: [5]
flexi_args: [8]
flexi_args: [15]
flexi_args: [30]
flexi_args: [6]
flexi_args: [20]
flexi_args: [8]
flexi_args: [8]
flexi_args: [12]
flexi_args: [16]
flexi_args: [6]
flexi_args: [15]
flexi_args: [6]
flexi_args: [16]
flexi_args: [30]
flexi_args: [12]
flexi_args: [5]
flexi_args: [16]
flexi_args: [30]
flexi_args: [12]
flexi_args: [30]
flexi_args: [30]
flexi_args: [12]
flexi_args: [15]
flexi_args: [30]
flexi_args: [20]
flexi_args: [16]
flexi_args: [6]
flexi_args: [5]
flexi_args: [20]
flexi_args: [15]
flexi_args: [15]
flexi_args: [6]
flexi_args: [6]
flexi_args: [12]
flexi_args: [20]
flexi_args: [30]
flexi_args: [30]
flexi_args: [24]
flexi_args: [15]
flexi_args: [24]
flexi_args: [12]
flexi_args: [12]
flexi_args: [12]
flexi_args: [6]
flexi_args: [15]
flexi_args: [10]
flexi_args: [20]
flexi_args: [24]
flexi_args: [8]
flexi_args: [12]
flexi_args: [15]
flexi_args: [6]
flexi_args: [6]
flexi_args: [8]
flexi_args: [10]
flexi_args: [30]
flexi_args: [30]
flexi_args: [24]
flexi_args: [15]
flexi_args: [12]
flexi_args: [24]
flexi_args: [24]
flexi_args: [5]
flexi_args: [6]
flexi_args: [6]
flexi_args: [8]
flexi_args: [30]
flexi_args: [30]
flexi_args: [24]
flexi_args: [16]
flexi_args: [6]
flexi_args: [10]
flexi_args: [15]
flexi_args: [24]
flexi_args: [15]
flexi_args: [15]
flexi_args: [24]
flexi_args: [16]
flexi_args: [12]
flexi_args: [6]
flexi_args: [15]
flexi_args: [5]
flexi_args: [15]
flexi_args: [6]
flexi_args: [10]
flexi_args: [15]
flexi_args: [12]
flexi_args: [16]
flexi_args: [24]
flexi_args: [10]
flexi_args: [10]
flexi_args: [8]
flexi_args: [30]
flexi_args: [8]
flexi_args: [15]
flexi_args: [24]
flexi_args: [12]
flexi_args: [12]
flexi_args: [24]
flexi_args: [30]
flexi_args: [5]
flexi_args: [16]
flexi_args: [30]
flexi_args: [16]
flexi_args: [24]
flexi_args: [5]
flexi_args: [20]
flexi_args: [12]
flexi_args: [6]
flexi_args: [30]
flexi_args: [30]
flexi_args: [24]
flexi_args: [30]
flexi_args: [8]
flexi_args: [20]
flexi_args: [24]
flexi_args: [12]
flexi_args: [6]
flexi_args: [8]
flexi_args: [30]
flexi_args: [24]
flexi_args: [5]
flexi_args: [15]
flexi_args: [30]
flexi_args: [8]
flexi_args: [15]
flexi_args: [16]
flexi_args: [20]
flexi_args: [10]
flexi_args: [24]
flexi_args: [16]
flexi_args: [8]
flexi_args: [12]
flexi_args: [10]
flexi_args: [24]
flexi_args: [6]
flexi_args: [20]
flexi_args: [24]
flexi_args: [15]
flexi_args: [12]
flexi_args: [16]
flexi_args: [6]
flexi_args: [16]
flexi_args: [16]
flexi_args: [8]
flexi_args: [5]
flexi_args: [16]
flexi_args: [12]
flexi_args: [20]
flexi_args: [10]
flexi_args: [5]
flexi_args: [8]
flexi_args: [15]
flexi_args: [5]
flexi_args: [15]
flexi_args: [30]
flexi_args: [10]
flexi_args: [20]
flexi_args: [16]
flexi_args: [20]
flexi_args: [24]
flexi_args: [6]
flexi_args: [6]
flexi_args: [5]
flexi_args: [16]
flexi_args: [20]
flexi_args: [15]
flexi_args: [12]
flexi_args: [10]
flexi_args: [16]
flexi_args: [5]
flexi_args: [15]
flexi_args: [12]
flexi_args: [30]
flexi_args: [6]
flexi_args: [6]
flexi_args: [16]
flexi_args: [8]
flexi_args: [12]
flexi_args: [15]
flexi_args: [6]
flexi_args: [30]
flexi_args: [10]
flexi_args: [24]
flexi_args: [6]
flexi_args: [24]
flexi_args: [20]
flexi_args: [30]
flexi_args: [12]
flexi_args: [6]
flexi_args: [8]
flexi_args: [15]
flexi_args: [10]
flexi_args: [12]
flexi_args: [5]
flexi_args: [5]
flexi_args: [30]
flexi_args: [24]
flexi_args: [15]
flexi_args: [30]
flexi_args: [30]
flexi_args: [20]
flexi_args: [6]
flexi_args: [10]
flexi_args: [10]
flexi_args: [5]
flexi_args: [16]
flexi_args: [24]
flexi_args: [10]
flexi_args: [8]
flexi_args: [30]
flexi_args: [10]
flexi_args: [8]
flexi_args: [24]
flexi_args: [20]
flexi_args: [10]
flexi_args: [8]
flexi_args: [30]
flexi_args: [5]
flexi_args: [10]
flexi_args: [30]
flexi_args: [20]
flexi_args: [15]
flexi_args: [6]
flexi_args: [20]
flexi_args: [30]
flexi_args: [12]
flexi_args: [16]
flexi_args: [6]
flexi_args: [6]
flexi_args: [6]
flexi_args: [6]
flexi_args: [20]
flexi_args: [20]
flexi_args: [6]
flexi_args: [24]
flexi_args: [8]
flexi_args: [16]
flexi_args: [24]
flexi_args: [10]
flexi_args: [20]
flexi_args: [10]
flexi_args: [8]
flexi_args: [20]
flexi_args: [10]
flexi_args: [8]
flexi_args: [16]
flexi_args: [16]
flexi_args: [12]
flexi_args: [12]
flexi_args: [12]
flexi_args: [30]
flexi_args: [30]
flexi_args: [24]
flexi_args: [16]
flexi_args: [10]
flexi_args: [20]
flexi_args: [12]
flexi_args: [10]
flexi_args: [5]
flexi_args: [12]
flexi_args: [12]
flexi_args: [5]
flexi_args: [8]
flexi_args: [20]
flexi_args: [6]
flexi_args: [24]
flexi_args: [30]
flexi_args: [15]
flexi_args: [8]
flexi_args: [20]
flexi_args: [24]
flexi_args: [24]
flexi_args: [30]
flexi_args: [8]
flexi_args: [24]
flexi_args: [8]
flexi_args: [30]
flexi_args: [20]
flexi_args: [30]
flexi_args: [20]
flexi_args: [30]
flexi_args: [10]
flexi_args: [10]
flexi_args: [15]
flexi_args: [5]
flexi_args: [24]
flexi_args: [24]
flexi_args: [10]
flexi_args: [24]
flexi_args: [16]
flexi_args: [12]
flexi_args: [8]
flexi_args: [20]
flexi_args: [20]
flexi_args: [20]
flexi_args: [10]
flexi_args: [16]
flexi_args: [24]
flexi_args: [15]
flexi_args: [16]
flexi_args: [24]
flexi_args: [20]
flexi_args: [10]
flexi_args: [24]
flexi_args: [15]
flexi_args: [16]
flexi_args: [10]
flexi_args: [15]
flexi_args: [24]
flexi_args: [20]
flexi_args: [20]
flexi_args: [24]
flexi_args: [20]
flexi_args: [8]
flexi_args: [6]
flexi_args: [15]
flexi_args: [15]
flexi_args: [20]
flexi_args: [24]
flexi_args: [15]
flexi_args: [5]
flexi_args: [5]
flexi_args: [8]
flexi_args: [30]
flexi_args: [20]
flexi_args: [6]
flexi_args: [16]
flexi_args: [10]
flexi_args: [20]
flexi_args: [16]
flexi_args: [5]
flexi_args: [15]
flexi_args: [10]
flexi_args: [8]
flexi_args: [5]
flexi_args: [10]
flexi_args: [15]
flexi_args: [5]
flexi_args: [15]
flexi_args: [30]
flexi_args: [8]
flexi_args: [30]
flexi_args: [6]
flexi_args: [6]
flexi_args: [5]
flexi_args: [10]
flexi_args: [6]
flexi_args: [24]
flexi_args: [30]
flexi_args: [12]
flexi_args: [8]
flexi_args: [16]
flexi_args: [24]
flexi_args: [24]
flexi_args: [8]
flexi_args: [6]
flexi_args: [5]
flexi_args: [15]
flexi_args: [15]
flexi_args: [5]
flexi_args: [24]
flexi_args: [5]
flexi_args: [30]
flexi_args: [20]
flexi_args: [24]
flexi_args: [6]
flexi_args: [6]
flexi_args: [30]
flexi_args: [20]
flexi_args: [5]
flexi_args: [10]
flexi_args: [6]
flexi_args: [24]
flexi_args: [20]
flexi_args: [10]
flexi_args: [20]
flexi_args: [5]
flexi_args: [16]
flexi_args: [5]
flexi_args: [10]
text in two towers: Traced<ShapedArray(int32[2,16])>with<DynamicJaxprTrace(level=0/1)>
text in two towers: None
