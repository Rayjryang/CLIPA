nohup: ignoring input
focus-album-323718
europe-west4-a
tpu-v3-64-pod-vm
SSH key found in project metadata; not updating instance.
Using ssh batch size of 8. Attempting to SSH into 1 nodes with a total of 8 workers.
SSH: Attempting to connect to worker 0...
SSH: Attempting to connect to worker 1...
SSH: Attempting to connect to worker 2...
SSH: Attempting to connect to worker 3...
SSH: Attempting to connect to worker 4...
SSH: Attempting to connect to worker 5...
SSH: Attempting to connect to worker 6...
SSH: Attempting to connect to worker 7...
rm: cannot remove '/tmp/tpu_logs/': No such file or directory
##### Command execution on worker 1 failed with exit status 1. Continuing.
rm: cannot remove '/tmp/tpu_logs/': No such file or directory
##### Command execution on worker 0 failed with exit status 1. Continuing.
rm: cannot remove '/tmp/tpu_logs/': No such file or directory
##### Command execution on worker 2 failed with exit status 1. Continuing.
rm: cannot remove '/tmp/tpu_logs/': No such file or directory
##### Command execution on worker 3 failed with exit status 1. Continuing.
rm: cannot remove '/tmp/tpu_logs/': No such file or directory
##### Command execution on worker 4 failed with exit status 1. Continuing.
rm: cannot remove '/tmp/tpu_logs/': No such file or directory
##### Command execution on worker 7 failed with exit status 1. Continuing.
rm: cannot remove '/tmp/tpu_logs/': No such file or directory
##### Command execution on worker 6 failed with exit status 1. Continuing.
rm: cannot remove '/tmp/tpu_logs/': No such file or directory
##### Command execution on worker 5 failed with exit status 1. Continuing.
SSH key found in project metadata; not updating instance.
Using ssh batch size of 8. Attempting to SSH into 1 nodes with a total of 8 workers.
SSH: Attempting to connect to worker 0...
SSH: Attempting to connect to worker 1...
SSH: Attempting to connect to worker 2...
SSH: Attempting to connect to worker 3...
SSH: Attempting to connect to worker 4...
SSH: Attempting to connect to worker 5...
SSH: Attempting to connect to worker 6...
SSH: Attempting to connect to worker 7...
Terminated
SSH key found in project metadata; not updating instance.
Using ssh batch size of 8. Attempting to SSH into 1 nodes with a total of 8 workers.
SSH: Attempting to connect to worker 0...
SSH: Attempting to connect to worker 1...
SSH: Attempting to connect to worker 2...
SSH: Attempting to connect to worker 3...
SSH: Attempting to connect to worker 4...
SSH: Attempting to connect to worker 5...
SSH: Attempting to connect to worker 6...
SSH: Attempting to connect to worker 7...
pkill: killing pid 1057 failed: Operation not permitted
pkill: killing pid 1132 failed: Operation not permitted
##### Command execution on worker 2 failed with exit status 1. Continuing.
pkill: killing pid 1068 failed: Operation not permitted
pkill: killing pid 1132 failed: Operation not permitted
##### Command execution on worker 1 failed with exit status 1. Continuing.
pkill: killing pid 1063 failed: Operation not permitted
pkill: killing pid 1132 failed: Operation not permitted
##### Command execution on worker 3 failed with exit status 1. Continuing.
pkill: killing pid 1052 failed: Operation not permitted
pkill: killing pid 1138 failed: Operation not permitted
##### Command execution on worker 4 failed with exit status 1. Continuing.
Terminated
SSH key found in project metadata; not updating instance.
Using ssh batch size of 8. Attempting to SSH into 1 nodes with a total of 8 workers.
SSH: Attempting to connect to worker 0...
SSH: Attempting to connect to worker 1...
SSH: Attempting to connect to worker 2...
SSH: Attempting to connect to worker 3...
SSH: Attempting to connect to worker 4...
SSH: Attempting to connect to worker 5...
SSH: Attempting to connect to worker 6...
SSH: Attempting to connect to worker 7...
Terminated
SSH key found in project metadata; not updating instance.
Using ssh batch size of 8. Attempting to SSH into 1 nodes with a total of 8 workers.
SSH: Attempting to connect to worker 0...
SSH: Attempting to connect to worker 1...
SSH: Attempting to connect to worker 2...
SSH: Attempting to connect to worker 3...
SSH: Attempting to connect to worker 4...
SSH: Attempting to connect to worker 5...
SSH: Attempting to connect to worker 6...
SSH: Attempting to connect to worker 7...
pkill: killing pid 1057 failed: Operation not permitted
pkill: killing pid 1132 failed: Operation not permitted
pkill: killing pid 1063 failed: Operation not permitted
pkill: killing pid 1132 failed: Operation not permitted
##### Command execution on worker 2 failed with exit status 1. Continuing.
Terminated
SSH key found in project metadata; not updating instance.
Using ssh batch size of 8. Attempting to SSH into 1 nodes with a total of 8 workers.
SSH: Attempting to connect to worker 0...
SSH: Attempting to connect to worker 1...
SSH: Attempting to connect to worker 2...
SSH: Attempting to connect to worker 3...
SSH: Attempting to connect to worker 4...
SSH: Attempting to connect to worker 5...
SSH: Attempting to connect to worker 6...
SSH: Attempting to connect to worker 7...
wandb: Appending key for api.wandb.ai to your netrc file: /home/jyang347/.netrc
wandb: Appending key for api.wandb.ai to your netrc file: /home/jyang347/.netrc
wandb: Appending key for api.wandb.ai to your netrc file: /home/jyang347/.netrc
wandb: Appending key for api.wandb.ai to your netrc file: /home/jyang347/.netrc
wandb: Appending key for api.wandb.ai to your netrc file: /home/jyang347/.netrc
wandb: Appending key for api.wandb.ai to your netrc file: /home/jyang347/.netrc
wandb: Appending key for api.wandb.ai to your netrc file: /home/jyang347/.netrc
wandb: Appending key for api.wandb.ai to your netrc file: /home/jyang347/.netrc
SSH key found in project metadata; not updating instance.
Using ssh batch size of 8. Attempting to SSH into 1 nodes with a total of 8 workers.
SSH: Attempting to connect to worker 0...
SSH: Attempting to connect to worker 1...
SSH: Attempting to connect to worker 2...
SSH: Attempting to connect to worker 3...
SSH: Attempting to connect to worker 4...
SSH: Attempting to connect to worker 5...
SSH: Attempting to connect to worker 6...
SSH: Attempting to connect to worker 7...
2024-01-25 01:13:26.607948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:26.630306: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:26.632757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:26.636070: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:26.639158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:26.652242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:26.664973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:26.667985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.256714: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.256814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.256823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-01-25 01:13:27.271720: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.271814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.271823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-01-25 01:13:27.276519: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.276635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.276645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-01-25 01:13:27.280051: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.280153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.280161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-01-25 01:13:27.289849: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.289948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.289957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-01-25 01:13:27.302756: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.302880: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.302889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-01-25 01:13:27.314577: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.314694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.314706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-01-25 01:13:27.329558: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.329661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:27.329670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-01-25 01:13:29.547106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:29.547152: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2024-01-25 01:13:29.554511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:29.554555: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2024-01-25 01:13:29.561234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:29.561279: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2024-01-25 01:13:29.564958: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:29.565007: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2024-01-25 01:13:29.575140: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:29.575186: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2024-01-25 01:13:29.630594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:29.630634: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2024-01-25 01:13:29.644683: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:29.644726: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2024-01-25 01:13:29.674432: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib
2024-01-25 01:13:29.674475: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
I0125 01:13:33.076349 139866951023680 main.py:89] [33mHello from process 5 holding 8/64 devices and writing to workdir gs://lxh_jaxtpu_eu_ckpt/jinruiyang_ckpt/clipa/tpu-v3-64-pod-vm-So150m-14-res56t16.[0m
I0125 01:13:33.116286 140592021429312 main.py:89] [33mHello from process 1 holding 8/64 devices and writing to workdir gs://lxh_jaxtpu_eu_ckpt/jinruiyang_ckpt/clipa/tpu-v3-64-pod-vm-So150m-14-res56t16.[0m
I0125 01:13:33.116628 139959958596672 main.py:89] [33mHello from process 6 holding 8/64 devices and writing to workdir gs://lxh_jaxtpu_eu_ckpt/jinruiyang_ckpt/clipa/tpu-v3-64-pod-vm-So150m-14-res56t16.[0m
I0125 01:13:33.119529 140493899304000 main.py:89] [33mHello from process 2 holding 8/64 devices and writing to workdir gs://lxh_jaxtpu_eu_ckpt/jinruiyang_ckpt/clipa/tpu-v3-64-pod-vm-So150m-14-res56t16.[0m
I0125 01:13:33.121164 140307309722688 main.py:89] [33mHello from process 0 holding 8/64 devices and writing to workdir gs://lxh_jaxtpu_eu_ckpt/jinruiyang_ckpt/clipa/tpu-v3-64-pod-vm-So150m-14-res56t16.[0m
I0125 01:13:33.171527 139956134382656 main.py:89] [33mHello from process 3 holding 8/64 devices and writing to workdir gs://lxh_jaxtpu_eu_ckpt/jinruiyang_ckpt/clipa/tpu-v3-64-pod-vm-So150m-14-res56t16.[0m
I0125 01:13:33.249762 140212821134400 main.py:89] [33mHello from process 4 holding 8/64 devices and writing to workdir gs://lxh_jaxtpu_eu_ckpt/jinruiyang_ckpt/clipa/tpu-v3-64-pod-vm-So150m-14-res56t16.[0m
I0125 01:13:33.320425 140581069126720 main.py:89] [33mHello from process 7 holding 8/64 devices and writing to workdir gs://lxh_jaxtpu_eu_ckpt/jinruiyang_ckpt/clipa/tpu-v3-64-pod-vm-So150m-14-res56t16.[0m
[nltk_data] Downloading package punkt to /home/jyang347/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/jyang347/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
I0125 01:13:33.606637 139866951023680 main.py:119] [33mNOTE[0m: Global batch size 32768 on 8 hosts results in 4096 local batch size. With 8 dev per host (64 dev total), that's a 512 per-device batch size.
[nltk_data] Downloading package punkt to /home/jyang347/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/jyang347/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
I0125 01:13:33.615874 139959958596672 main.py:119] [33mNOTE[0m: Global batch size 32768 on 8 hosts results in 4096 local batch size. With 8 dev per host (64 dev total), that's a 512 per-device batch size.
[nltk_data] Downloading package punkt to /home/jyang347/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/jyang347/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
I0125 01:13:33.631725 140212821134400 main.py:119] [33mNOTE[0m: Global batch size 32768 on 8 hosts results in 4096 local batch size. With 8 dev per host (64 dev total), that's a 512 per-device batch size.
[nltk_data] Downloading package punkt to /home/jyang347/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/jyang347/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
I0125 01:13:33.632373 139956134382656 main.py:119] [33mNOTE[0m: Global batch size 32768 on 8 hosts results in 4096 local batch size. With 8 dev per host (64 dev total), that's a 512 per-device batch size.
[nltk_data] Downloading package punkt to /home/jyang347/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/jyang347/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
I0125 01:13:33.644137 140307309722688 main.py:119] [33mNOTE[0m: Initializing...
I0125 01:13:33.644855 140307309722688 main.py:119] [33mNOTE[0m: Global batch size 32768 on 8 hosts results in 4096 local batch size. With 8 dev per host (64 dev total), that's a 512 per-device batch size.
[nltk_data] Downloading package punkt to /home/jyang347/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/jyang347/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
I0125 01:13:33.652205 140592021429312 main.py:119] [33mNOTE[0m: Global batch size 32768 on 8 hosts results in 4096 local batch size. With 8 dev per host (64 dev total), that's a 512 per-device batch size.
[nltk_data] Downloading package punkt to /home/jyang347/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/jyang347/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
I0125 01:13:33.664214 140493899304000 main.py:119] [33mNOTE[0m: Global batch size 32768 on 8 hosts results in 4096 local batch size. With 8 dev per host (64 dev total), that's a 512 per-device batch size.
[nltk_data] Downloading package punkt to /home/jyang347/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/jyang347/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
I0125 01:13:33.696370 140581069126720 main.py:119] [33mNOTE[0m: Global batch size 32768 on 8 hosts results in 4096 local batch size. With 8 dev per host (64 dev total), that's a 512 per-device batch size.
I0125 01:13:33.738425 140307309722688 main.py:119] [33mNOTE[0m: Initializing train dataset...
I0125 01:13:34.095580 140212821134400 dataset_info.py:566] Load dataset info from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:34.096877 139866951023680 dataset_info.py:566] Load dataset info from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:34.100041 140493899304000 dataset_info.py:566] Load dataset info from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:34.116009 139959958596672 dataset_info.py:566] Load dataset info from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:34.116063 140592021429312 dataset_info.py:566] Load dataset info from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:34.120601 140581069126720 dataset_info.py:566] Load dataset info from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:34.127946 139956134382656 dataset_info.py:566] Load dataset info from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:34.163330 140307309722688 dataset_info.py:566] Load dataset info from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:36.567081 140493899304000 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:13:36.594223 139956134382656 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:13:36.596457 140212821134400 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:13:36.599843 139866951023680 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:13:36.608531 140307309722688 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:13:36.636495 139959958596672 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:13:36.637857 140592021429312 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:13:36.640505 140581069126720 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0125 01:13:37.294074 140493899304000 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0125 01:13:37.316429 140212821134400 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0125 01:13:37.330490 139866951023680 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0125 01:13:37.334011 140307309722688 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0125 01:13:37.340118 139956134382656 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
I0125 01:13:37.367907 140493899304000 logging_logger.py:49] Constructing tf.data.Dataset laion400m for split _EvenSplit(split='full-filter', index=2, count=8, drop_remainder=False), from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0125 01:13:37.373103 139959958596672 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
I0125 01:13:37.389970 140212821134400 logging_logger.py:49] Constructing tf.data.Dataset laion400m for split _EvenSplit(split='full-filter', index=4, count=8, drop_remainder=False), from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0125 01:13:37.392037 140592021429312 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0125 01:13:37.394124 140581069126720 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow_datasets/core/reader.py:100: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
I0125 01:13:37.407535 140307309722688 logging_logger.py:49] Constructing tf.data.Dataset laion400m for split _EvenSplit(split='full-filter', index=0, count=8, drop_remainder=False), from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:37.407394 139866951023680 logging_logger.py:49] Constructing tf.data.Dataset laion400m for split _EvenSplit(split='full-filter', index=5, count=8, drop_remainder=False), from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:37.412024 139956134382656 logging_logger.py:49] Constructing tf.data.Dataset laion400m for split _EvenSplit(split='full-filter', index=3, count=8, drop_remainder=False), from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:37.444413 139959958596672 logging_logger.py:49] Constructing tf.data.Dataset laion400m for split _EvenSplit(split='full-filter', index=6, count=8, drop_remainder=False), from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:37.466261 140581069126720 logging_logger.py:49] Constructing tf.data.Dataset laion400m for split _EvenSplit(split='full-filter', index=7, count=8, drop_remainder=False), from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:37.468364 140592021429312 logging_logger.py:49] Constructing tf.data.Dataset laion400m for split _EvenSplit(split='full-filter', index=1, count=8, drop_remainder=False), from gs://jaxtpu-data-eu-west4/laion400m_blip_filtered
I0125 01:13:43.245952 140493899304000 api.py:459] Data before pre-processing:
{'LICENSE': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'NSFW': <tf.Tensor 'args_1:0' shape=() dtype=string>, 'caption': <tf.Tensor 'args_2:0' shape=() dtype=string>, 'error_message': <tf.Tensor 'args_3:0' shape=() dtype=string>, 'exif': <tf.Tensor 'args_4:0' shape=() dtype=string>, 'height': <tf.Tensor 'args_5:0' shape=() dtype=int64>, 'jpg': <tf.Tensor 'args_6:0' shape=(None, None, 3) dtype=uint8>, 'key': <tf.Tensor 'args_7:0' shape=() dtype=string>, 'original_height': <tf.Tensor 'args_8:0' shape=() dtype=int64>, 'original_width': <tf.Tensor 'args_9:0' shape=() dtype=int64>, 'sha256': <tf.Tensor 'args_10:0' shape=() dtype=string>, 'status': <tf.Tensor 'args_11:0' shape=() dtype=string>, 'txt': <tf.Tensor 'args_13:0' shape=() dtype=string>, 'url': <tf.Tensor 'args_14:0' shape=() dtype=string>, 'width': <tf.Tensor 'args_15:0' shape=() dtype=int64>, 'tfds_id': <tf.Tensor 'args_12:0' shape=() dtype=string>}
I0125 01:13:43.254842 140212821134400 api.py:459] Data before pre-processing:
{'LICENSE': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'NSFW': <tf.Tensor 'args_1:0' shape=() dtype=string>, 'caption': <tf.Tensor 'args_2:0' shape=() dtype=string>, 'error_message': <tf.Tensor 'args_3:0' shape=() dtype=string>, 'exif': <tf.Tensor 'args_4:0' shape=() dtype=string>, 'height': <tf.Tensor 'args_5:0' shape=() dtype=int64>, 'jpg': <tf.Tensor 'args_6:0' shape=(None, None, 3) dtype=uint8>, 'key': <tf.Tensor 'args_7:0' shape=() dtype=string>, 'original_height': <tf.Tensor 'args_8:0' shape=() dtype=int64>, 'original_width': <tf.Tensor 'args_9:0' shape=() dtype=int64>, 'sha256': <tf.Tensor 'args_10:0' shape=() dtype=string>, 'status': <tf.Tensor 'args_11:0' shape=() dtype=string>, 'txt': <tf.Tensor 'args_13:0' shape=() dtype=string>, 'url': <tf.Tensor 'args_14:0' shape=() dtype=string>, 'width': <tf.Tensor 'args_15:0' shape=() dtype=int64>, 'tfds_id': <tf.Tensor 'args_12:0' shape=() dtype=string>}
I0125 01:13:43.338546 139959958596672 api.py:459] Data before pre-processing:
{'LICENSE': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'NSFW': <tf.Tensor 'args_1:0' shape=() dtype=string>, 'caption': <tf.Tensor 'args_2:0' shape=() dtype=string>, 'error_message': <tf.Tensor 'args_3:0' shape=() dtype=string>, 'exif': <tf.Tensor 'args_4:0' shape=() dtype=string>, 'height': <tf.Tensor 'args_5:0' shape=() dtype=int64>, 'jpg': <tf.Tensor 'args_6:0' shape=(None, None, 3) dtype=uint8>, 'key': <tf.Tensor 'args_7:0' shape=() dtype=string>, 'original_height': <tf.Tensor 'args_8:0' shape=() dtype=int64>, 'original_width': <tf.Tensor 'args_9:0' shape=() dtype=int64>, 'sha256': <tf.Tensor 'args_10:0' shape=() dtype=string>, 'status': <tf.Tensor 'args_11:0' shape=() dtype=string>, 'txt': <tf.Tensor 'args_13:0' shape=() dtype=string>, 'url': <tf.Tensor 'args_14:0' shape=() dtype=string>, 'width': <tf.Tensor 'args_15:0' shape=() dtype=int64>, 'tfds_id': <tf.Tensor 'args_12:0' shape=() dtype=string>}
I0125 01:13:43.357823 140307309722688 api.py:459] Data before pre-processing:
{'LICENSE': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'NSFW': <tf.Tensor 'args_1:0' shape=() dtype=string>, 'caption': <tf.Tensor 'args_2:0' shape=() dtype=string>, 'error_message': <tf.Tensor 'args_3:0' shape=() dtype=string>, 'exif': <tf.Tensor 'args_4:0' shape=() dtype=string>, 'height': <tf.Tensor 'args_5:0' shape=() dtype=int64>, 'jpg': <tf.Tensor 'args_6:0' shape=(None, None, 3) dtype=uint8>, 'key': <tf.Tensor 'args_7:0' shape=() dtype=string>, 'original_height': <tf.Tensor 'args_8:0' shape=() dtype=int64>, 'original_width': <tf.Tensor 'args_9:0' shape=() dtype=int64>, 'sha256': <tf.Tensor 'args_10:0' shape=() dtype=string>, 'status': <tf.Tensor 'args_11:0' shape=() dtype=string>, 'txt': <tf.Tensor 'args_13:0' shape=() dtype=string>, 'url': <tf.Tensor 'args_14:0' shape=() dtype=string>, 'width': <tf.Tensor 'args_15:0' shape=() dtype=int64>, 'tfds_id': <tf.Tensor 'args_12:0' shape=() dtype=string>}
I0125 01:13:43.369256 139866951023680 api.py:459] Data before pre-processing:
{'LICENSE': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'NSFW': <tf.Tensor 'args_1:0' shape=() dtype=string>, 'caption': <tf.Tensor 'args_2:0' shape=() dtype=string>, 'error_message': <tf.Tensor 'args_3:0' shape=() dtype=string>, 'exif': <tf.Tensor 'args_4:0' shape=() dtype=string>, 'height': <tf.Tensor 'args_5:0' shape=() dtype=int64>, 'jpg': <tf.Tensor 'args_6:0' shape=(None, None, 3) dtype=uint8>, 'key': <tf.Tensor 'args_7:0' shape=() dtype=string>, 'original_height': <tf.Tensor 'args_8:0' shape=() dtype=int64>, 'original_width': <tf.Tensor 'args_9:0' shape=() dtype=int64>, 'sha256': <tf.Tensor 'args_10:0' shape=() dtype=string>, 'status': <tf.Tensor 'args_11:0' shape=() dtype=string>, 'txt': <tf.Tensor 'args_13:0' shape=() dtype=string>, 'url': <tf.Tensor 'args_14:0' shape=() dtype=string>, 'width': <tf.Tensor 'args_15:0' shape=() dtype=int64>, 'tfds_id': <tf.Tensor 'args_12:0' shape=() dtype=string>}
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0125 01:13:43.381745 140493899304000 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
I0125 01:13:43.387935 140581069126720 api.py:459] Data before pre-processing:
{'LICENSE': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'NSFW': <tf.Tensor 'args_1:0' shape=() dtype=string>, 'caption': <tf.Tensor 'args_2:0' shape=() dtype=string>, 'error_message': <tf.Tensor 'args_3:0' shape=() dtype=string>, 'exif': <tf.Tensor 'args_4:0' shape=() dtype=string>, 'height': <tf.Tensor 'args_5:0' shape=() dtype=int64>, 'jpg': <tf.Tensor 'args_6:0' shape=(None, None, 3) dtype=uint8>, 'key': <tf.Tensor 'args_7:0' shape=() dtype=string>, 'original_height': <tf.Tensor 'args_8:0' shape=() dtype=int64>, 'original_width': <tf.Tensor 'args_9:0' shape=() dtype=int64>, 'sha256': <tf.Tensor 'args_10:0' shape=() dtype=string>, 'status': <tf.Tensor 'args_11:0' shape=() dtype=string>, 'txt': <tf.Tensor 'args_13:0' shape=() dtype=string>, 'url': <tf.Tensor 'args_14:0' shape=() dtype=string>, 'width': <tf.Tensor 'args_15:0' shape=() dtype=int64>, 'tfds_id': <tf.Tensor 'args_12:0' shape=() dtype=string>}
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0125 01:13:43.389550 140212821134400 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
I0125 01:13:43.412964 140592021429312 api.py:459] Data before pre-processing:
{'LICENSE': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'NSFW': <tf.Tensor 'args_1:0' shape=() dtype=string>, 'caption': <tf.Tensor 'args_2:0' shape=() dtype=string>, 'error_message': <tf.Tensor 'args_3:0' shape=() dtype=string>, 'exif': <tf.Tensor 'args_4:0' shape=() dtype=string>, 'height': <tf.Tensor 'args_5:0' shape=() dtype=int64>, 'jpg': <tf.Tensor 'args_6:0' shape=(None, None, 3) dtype=uint8>, 'key': <tf.Tensor 'args_7:0' shape=() dtype=string>, 'original_height': <tf.Tensor 'args_8:0' shape=() dtype=int64>, 'original_width': <tf.Tensor 'args_9:0' shape=() dtype=int64>, 'sha256': <tf.Tensor 'args_10:0' shape=() dtype=string>, 'status': <tf.Tensor 'args_11:0' shape=() dtype=string>, 'txt': <tf.Tensor 'args_13:0' shape=() dtype=string>, 'url': <tf.Tensor 'args_14:0' shape=() dtype=string>, 'width': <tf.Tensor 'args_15:0' shape=() dtype=int64>, 'tfds_id': <tf.Tensor 'args_12:0' shape=() dtype=string>}
I0125 01:13:43.413458 139956134382656 api.py:459] Data before pre-processing:
{'LICENSE': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'NSFW': <tf.Tensor 'args_1:0' shape=() dtype=string>, 'caption': <tf.Tensor 'args_2:0' shape=() dtype=string>, 'error_message': <tf.Tensor 'args_3:0' shape=() dtype=string>, 'exif': <tf.Tensor 'args_4:0' shape=() dtype=string>, 'height': <tf.Tensor 'args_5:0' shape=() dtype=int64>, 'jpg': <tf.Tensor 'args_6:0' shape=(None, None, 3) dtype=uint8>, 'key': <tf.Tensor 'args_7:0' shape=() dtype=string>, 'original_height': <tf.Tensor 'args_8:0' shape=() dtype=int64>, 'original_width': <tf.Tensor 'args_9:0' shape=() dtype=int64>, 'sha256': <tf.Tensor 'args_10:0' shape=() dtype=string>, 'status': <tf.Tensor 'args_11:0' shape=() dtype=string>, 'txt': <tf.Tensor 'args_13:0' shape=() dtype=string>, 'url': <tf.Tensor 'args_14:0' shape=() dtype=string>, 'width': <tf.Tensor 'args_15:0' shape=() dtype=int64>, 'tfds_id': <tf.Tensor 'args_12:0' shape=() dtype=string>}
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0125 01:13:43.475957 139959958596672 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0125 01:13:43.493952 140307309722688 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0125 01:13:43.509079 139866951023680 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0125 01:13:43.529890 140581069126720 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0125 01:13:43.553553 139956134382656 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
WARNING:tensorflow:From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W0125 01:13:43.556468 140592021429312 deprecation.py:350] From /home/jyang347/CLIPA/clipa_jax/bv_venv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
/tmp/__autograph_generated_fileyu41xv_3.py:11: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  ag__.converted_call(ag__.ld(warnings).warn, (f'jax.{ag__.ld(f).__name__} is deprecated, and will be removed in a future release. Use jax.tree_util.{ag__.ld(f).__name__} instead.',), dict(category=ag__.ld(FutureWarning), stacklevel=2), fscope)
I0125 01:13:45.107965 140493899304000 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'Cast:0' shape=(56, 56, 3) dtype=uint8>, 'labels': <tf.Tensor 'cond/Identity:0' shape=(16,) dtype=int32>}
/tmp/__autograph_generated_fileuv3sfxl9.py:11: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  ag__.converted_call(ag__.ld(warnings).warn, (f'jax.{ag__.ld(f).__name__} is deprecated, and will be removed in a future release. Use jax.tree_util.{ag__.ld(f).__name__} instead.',), dict(category=ag__.ld(FutureWarning), stacklevel=2), fscope)
I0125 01:13:45.114082 140212821134400 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'Cast:0' shape=(56, 56, 3) dtype=uint8>, 'labels': <tf.Tensor 'cond/Identity:0' shape=(16,) dtype=int32>}
/tmp/__autograph_generated_file2grdzbg6.py:11: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  ag__.converted_call(ag__.ld(warnings).warn, (f'jax.{ag__.ld(f).__name__} is deprecated, and will be removed in a future release. Use jax.tree_util.{ag__.ld(f).__name__} instead.',), dict(category=ag__.ld(FutureWarning), stacklevel=2), fscope)
I0125 01:13:45.187839 140307309722688 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'Cast:0' shape=(56, 56, 3) dtype=uint8>, 'labels': <tf.Tensor 'cond/Identity:0' shape=(16,) dtype=int32>}
/tmp/__autograph_generated_filepnh6eagt.py:11: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  ag__.converted_call(ag__.ld(warnings).warn, (f'jax.{ag__.ld(f).__name__} is deprecated, and will be removed in a future release. Use jax.tree_util.{ag__.ld(f).__name__} instead.',), dict(category=ag__.ld(FutureWarning), stacklevel=2), fscope)
I0125 01:13:45.221581 139959958596672 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'Cast:0' shape=(56, 56, 3) dtype=uint8>, 'labels': <tf.Tensor 'cond/Identity:0' shape=(16,) dtype=int32>}
/tmp/__autograph_generated_file7gs9q_83.py:11: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  ag__.converted_call(ag__.ld(warnings).warn, (f'jax.{ag__.ld(f).__name__} is deprecated, and will be removed in a future release. Use jax.tree_util.{ag__.ld(f).__name__} instead.',), dict(category=ag__.ld(FutureWarning), stacklevel=2), fscope)
I0125 01:13:45.267550 139866951023680 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'Cast:0' shape=(56, 56, 3) dtype=uint8>, 'labels': <tf.Tensor 'cond/Identity:0' shape=(16,) dtype=int32>}
/tmp/__autograph_generated_fileplum3lox.py:11: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  ag__.converted_call(ag__.ld(warnings).warn, (f'jax.{ag__.ld(f).__name__} is deprecated, and will be removed in a future release. Use jax.tree_util.{ag__.ld(f).__name__} instead.',), dict(category=ag__.ld(FutureWarning), stacklevel=2), fscope)
I0125 01:13:45.308615 140581069126720 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'Cast:0' shape=(56, 56, 3) dtype=uint8>, 'labels': <tf.Tensor 'cond/Identity:0' shape=(16,) dtype=int32>}
/tmp/__autograph_generated_fileu7iuxe4b.py:11: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  ag__.converted_call(ag__.ld(warnings).warn, (f'jax.{ag__.ld(f).__name__} is deprecated, and will be removed in a future release. Use jax.tree_util.{ag__.ld(f).__name__} instead.',), dict(category=ag__.ld(FutureWarning), stacklevel=2), fscope)
I0125 01:13:45.339929 140592021429312 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'Cast:0' shape=(56, 56, 3) dtype=uint8>, 'labels': <tf.Tensor 'cond/Identity:0' shape=(16,) dtype=int32>}
/tmp/__autograph_generated_filesubibd3w.py:11: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  ag__.converted_call(ag__.ld(warnings).warn, (f'jax.{ag__.ld(f).__name__} is deprecated, and will be removed in a future release. Use jax.tree_util.{ag__.ld(f).__name__} instead.',), dict(category=ag__.ld(FutureWarning), stacklevel=2), fscope)
I0125 01:13:45.343723 139956134382656 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'Cast:0' shape=(56, 56, 3) dtype=uint8>, 'labels': <tf.Tensor 'cond/Identity:0' shape=(16,) dtype=int32>}
I0125 01:13:45.417339 140212821134400 main.py:119] [33mNOTE[0m: Running for 56014 steps, that means 7.000041 epochs
I0125 01:13:45.417838 140493899304000 main.py:119] [33mNOTE[0m: Running for 56014 steps, that means 7.000041 epochs
I0125 01:13:45.490073 140307309722688 main.py:119] [33mNOTE[0m: Running for 56014 steps, that means 7.000041 epochs
I0125 01:13:45.490267 140307309722688 main.py:119] [33mNOTE[0m: Initializing two_towers model...
I0125 01:13:45.533090 139959958596672 main.py:119] [33mNOTE[0m: Running for 56014 steps, that means 7.000041 epochs
I0125 01:13:45.575039 139866951023680 main.py:119] [33mNOTE[0m: Running for 56014 steps, that means 7.000041 epochs
W0125 01:13:45.580560 140212821134400 checkpoints.py:55] GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.
W0125 01:13:45.588034 140493899304000 checkpoints.py:55] GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.
I0125 01:13:45.619940 140581069126720 main.py:119] [33mNOTE[0m: Running for 56014 steps, that means 7.000041 epochs
W0125 01:13:45.654900 140307309722688 checkpoints.py:55] GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.
I0125 01:13:45.657989 139956134382656 main.py:119] [33mNOTE[0m: Running for 56014 steps, that means 7.000041 epochs
I0125 01:13:45.660282 140592021429312 main.py:119] [33mNOTE[0m: Running for 56014 steps, that means 7.000041 epochs
W0125 01:13:45.697242 139959958596672 checkpoints.py:55] GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.
W0125 01:13:45.742885 139866951023680 checkpoints.py:55] GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.
W0125 01:13:45.788129 140581069126720 checkpoints.py:55] GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.
W0125 01:13:45.827559 139956134382656 checkpoints.py:55] GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.
W0125 01:13:45.832037 140592021429312 checkpoints.py:55] GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.
I0125 01:13:46.296094 140212821134400 vit.py:166] remat policy: actcp
I0125 01:13:46.296229 140212821134400 vit.py:171] activation checkpointing actcp
I0125 01:13:46.322943 140493899304000 vit.py:166] remat policy: actcp
I0125 01:13:46.323103 140493899304000 vit.py:171] activation checkpointing actcp
I0125 01:13:46.371069 140307309722688 vit.py:166] remat policy: actcp
I0125 01:13:46.371208 140307309722688 vit.py:171] activation checkpointing actcp
I0125 01:13:46.417316 139959958596672 vit.py:166] remat policy: actcp
I0125 01:13:46.417456 139959958596672 vit.py:171] activation checkpointing actcp
I0125 01:13:46.478212 139866951023680 vit.py:166] remat policy: actcp
I0125 01:13:46.478375 139866951023680 vit.py:171] activation checkpointing actcp
I0125 01:13:46.517722 140581069126720 vit.py:166] remat policy: actcp
I0125 01:13:46.517865 140581069126720 vit.py:171] activation checkpointing actcp
I0125 01:13:46.559186 139956134382656 vit.py:166] remat policy: actcp
I0125 01:13:46.559336 139956134382656 vit.py:171] activation checkpointing actcp
I0125 01:13:46.570116 140592021429312 vit.py:166] remat policy: actcp
I0125 01:13:46.570281 140592021429312 vit.py:171] activation checkpointing actcp
I0125 01:14:31.447264 140212821134400 utils.py:427] TIMING[z/secs/init]: 45.887792627792805
I0125 01:14:31.493031 140307309722688 utils.py:844] [35m[0][0m z/secs/init = 45.85918369400315
I0125 01:14:31.493226 140307309722688 utils.py:427] TIMING[z/secs/init]: 45.85918369400315
I0125 01:14:31.649307 139959958596672 utils.py:427] TIMING[z/secs/init]: 45.97302590101026
/home/jyang347/CLIPA/clipa_jax/main.py:227: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  num_params = sum(p.size for p in jax.tree_leaves(params_cpu))
I0125 01:14:31.862233 140307309722688 parameter_overview.py:264] 
init params
+-----------------------------------------------------------------------------+------------------+------------+-----------+---------+
| Name                                                                        | Shape            | Size       | Mean      | Std     |
+-----------------------------------------------------------------------------+------------------+------------+-----------+---------+
| img/Transformer/encoderblock_0/LayerNorm_0/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_0/LayerNorm_0/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_0/LayerNorm_1/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_0/LayerNorm_1/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias                      | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel                    | (880, 2320)      | 2,041,600  | 1.76e-05  | 0.025   |
| img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias                      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel                    | (2320, 880)      | 2,041,600  | -3.33e-06 | 0.025   |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias      | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel    | (880, 16, 55)    | 774,400    | -8.66e-06 | 0.0337  |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel    | (16, 55, 880)    | 774,400    | -1.88e-05 | 0.0337  |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel  | (880, 16, 55)    | 774,400    | 2.65e-05  | 0.0337  |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel  | (880, 16, 55)    | 774,400    | -2.24e-05 | 0.0337  |
| img/Transformer/encoderblock_1/LayerNorm_0/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_1/LayerNorm_0/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_1/LayerNorm_1/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_1/LayerNorm_1/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias                      | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel                    | (880, 2320)      | 2,041,600  | -8.34e-07 | 0.025   |
| img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias                      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel                    | (2320, 880)      | 2,041,600  | 1.23e-05  | 0.025   |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias      | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel    | (880, 16, 55)    | 774,400    | -1.02e-05 | 0.0337  |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel    | (16, 55, 880)    | 774,400    | -7.1e-06  | 0.0337  |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel  | (880, 16, 55)    | 774,400    | 7.97e-05  | 0.0337  |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel  | (880, 16, 55)    | 774,400    | 3.05e-05  | 0.0337  |
| img/Transformer/encoderblock_10/LayerNorm_0/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_10/LayerNorm_0/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_10/LayerNorm_1/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_10/LayerNorm_1/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias                     | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel                   | (880, 2320)      | 2,041,600  | -1.1e-05  | 0.025   |
| img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias                     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel                   | (2320, 880)      | 2,041,600  | -6.81e-06 | 0.025   |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias     | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel   | (880, 16, 55)    | 774,400    | -5.31e-06 | 0.0337  |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel   | (16, 55, 880)    | 774,400    | -2.94e-05 | 0.0337  |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel | (880, 16, 55)    | 774,400    | -3.01e-05 | 0.0337  |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel | (880, 16, 55)    | 774,400    | -9.73e-06 | 0.0337  |
| img/Transformer/encoderblock_11/LayerNorm_0/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_11/LayerNorm_0/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_11/LayerNorm_1/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_11/LayerNorm_1/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias                     | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel                   | (880, 2320)      | 2,041,600  | -1.51e-05 | 0.025   |
| img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias                     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel                   | (2320, 880)      | 2,041,600  | 4.05e-05  | 0.025   |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias     | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel   | (880, 16, 55)    | 774,400    | -3.03e-05 | 0.0337  |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel   | (16, 55, 880)    | 774,400    | 1.45e-05  | 0.0337  |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel | (880, 16, 55)    | 774,400    | 4.25e-05  | 0.0337  |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel | (880, 16, 55)    | 774,400    | 2.4e-05   | 0.0337  |
| img/Transformer/encoderblock_12/LayerNorm_0/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_12/LayerNorm_0/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_12/LayerNorm_1/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_12/LayerNorm_1/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_12/MlpBlock_0/Dense_0/bias                     | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_12/MlpBlock_0/Dense_0/kernel                   | (880, 2320)      | 2,041,600  | 1.38e-05  | 0.025   |
| img/Transformer/encoderblock_12/MlpBlock_0/Dense_1/bias                     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_12/MlpBlock_0/Dense_1/kernel                   | (2320, 880)      | 2,041,600  | -1.06e-05 | 0.025   |
| img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/key/bias     | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/key/kernel   | (880, 16, 55)    | 774,400    | -3.73e-05 | 0.0337  |
| img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/out/bias     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/out/kernel   | (16, 55, 880)    | 774,400    | 4.37e-07  | 0.0337  |
I0125 01:14:31.862433 140307309722688 parameter_overview.py:264] 
| img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/query/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/query/kernel | (880, 16, 55)    | 774,400    | 1.21e-05  | 0.0337  |
| img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/value/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/value/kernel | (880, 16, 55)    | 774,400    | 7.24e-05  | 0.0337  |
| img/Transformer/encoderblock_13/LayerNorm_0/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_13/LayerNorm_0/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_13/LayerNorm_1/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_13/LayerNorm_1/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_13/MlpBlock_0/Dense_0/bias                     | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_13/MlpBlock_0/Dense_0/kernel                   | (880, 2320)      | 2,041,600  | -1.51e-05 | 0.025   |
| img/Transformer/encoderblock_13/MlpBlock_0/Dense_1/bias                     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_13/MlpBlock_0/Dense_1/kernel                   | (2320, 880)      | 2,041,600  | -1.51e-05 | 0.025   |
| img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/key/bias     | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/key/kernel   | (880, 16, 55)    | 774,400    | -1.23e-05 | 0.0337  |
| img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/out/bias     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/out/kernel   | (16, 55, 880)    | 774,400    | -0.00012  | 0.0337  |
| img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/query/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/query/kernel | (880, 16, 55)    | 774,400    | 3.89e-07  | 0.0337  |
| img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/value/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/value/kernel | (880, 16, 55)    | 774,400    | -5.5e-06  | 0.0337  |
| img/Transformer/encoderblock_14/LayerNorm_0/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_14/LayerNorm_0/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_14/LayerNorm_1/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_14/LayerNorm_1/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_14/MlpBlock_0/Dense_0/bias                     | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_14/MlpBlock_0/Dense_0/kernel                   | (880, 2320)      | 2,041,600  | -1.56e-05 | 0.025   |
| img/Transformer/encoderblock_14/MlpBlock_0/Dense_1/bias                     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_14/MlpBlock_0/Dense_1/kernel                   | (2320, 880)      | 2,041,600  | -9.04e-06 | 0.025   |
| img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/key/bias     | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/key/kernel   | (880, 16, 55)    | 774,400    | -2.32e-05 | 0.0337  |
| img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/out/bias     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/out/kernel   | (16, 55, 880)    | 774,400    | 5.59e-05  | 0.0337  |
| img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/query/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/query/kernel | (880, 16, 55)    | 774,400    | 1.76e-05  | 0.0337  |
| img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/value/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/value/kernel | (880, 16, 55)    | 774,400    | 3.66e-05  | 0.0337  |
| img/Transformer/encoderblock_15/LayerNorm_0/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_15/LayerNorm_0/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_15/LayerNorm_1/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_15/LayerNorm_1/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_15/MlpBlock_0/Dense_0/bias                     | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_15/MlpBlock_0/Dense_0/kernel                   | (880, 2320)      | 2,041,600  | -1.73e-05 | 0.025   |
| img/Transformer/encoderblock_15/MlpBlock_0/Dense_1/bias                     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_15/MlpBlock_0/Dense_1/kernel                   | (2320, 880)      | 2,041,600  | -1.03e-06 | 0.025   |
| img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/key/bias     | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/key/kernel   | (880, 16, 55)    | 774,400    | 2.26e-06  | 0.0337  |
| img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/out/bias     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/out/kernel   | (16, 55, 880)    | 774,400    | -5.67e-06 | 0.0337  |
| img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/query/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/query/kernel | (880, 16, 55)    | 774,400    | 4.44e-05  | 0.0337  |
| img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/value/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/value/kernel | (880, 16, 55)    | 774,400    | 6.08e-06  | 0.0337  |
| img/Transformer/encoderblock_16/LayerNorm_0/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_16/LayerNorm_0/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_16/LayerNorm_1/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_16/LayerNorm_1/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_16/MlpBlock_0/Dense_0/bias                     | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_16/MlpBlock_0/Dense_0/kernel                   | (880, 2320)      | 2,041,600  | 2.78e-06  | 0.025   |
| img/Transformer/encoderblock_16/MlpBlock_0/Dense_1/bias                     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_16/MlpBlock_0/Dense_1/kernel                   | (2320, 880)      | 2,041,600  | -3.04e-05 | 0.025   |
| img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/key/bias     | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/key/kernel   | (880, 16, 55)    | 774,400    | 2.32e-06  | 0.0337  |
| img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/out/bias     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/out/kernel   | (16, 55, 880)    | 774,400    | -1.49e-06 | 0.0337  |
| img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/query/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/query/kernel | (880, 16, 55)    | 774,400    | 1.22e-05  | 0.0337  |
| img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/value/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/value/kernel | (880, 16, 55)    | 774,400    | -4.37e-05 | 0.0337  |
| img/Transformer/encoderblock_17/LayerNorm_0/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_17/LayerNorm_0/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_17/LayerNorm_1/bias                            | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_17/LayerNorm_1/scale                           | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_17/MlpBlock_0/Dense_0/bias                     | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_17/MlpBlock_0/Dense_0/kernel                   | (880, 2320)      | 2,041,600  | -1.81e-05 | 0.025   |
| img/Transformer/encoderblock_17/MlpBlock_0/Dense_1/bias                     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_17/MlpBlock_0/Dense_1/kernel                   | (2320, 880)      | 2,041,600  | 9.98e-07  | 0.025   |
| img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/key/bias     | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/key/kernel   | (880, 16, 55)    | 774,400    | 3.5e-05   | 0.0337  |
| img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/out/bias     | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/out/kernel   | (16, 55, 880)    | 774,400    | -5.65e-06 | 0.0337  |
I0125 01:14:31.862494 140307309722688 parameter_overview.py:264] 
| img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/query/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/query/kernel | (880, 16, 55)    | 774,400    | 1.58e-05  | 0.0337  |
| img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/value/bias   | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/value/kernel | (880, 16, 55)    | 774,400    | -2.55e-05 | 0.0337  |
| img/Transformer/encoderblock_2/LayerNorm_0/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_2/LayerNorm_0/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_2/LayerNorm_1/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_2/LayerNorm_1/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias                      | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel                    | (880, 2320)      | 2,041,600  | -1.08e-05 | 0.025   |
| img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias                      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel                    | (2320, 880)      | 2,041,600  | 8.5e-06   | 0.025   |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias      | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel    | (880, 16, 55)    | 774,400    | 4.96e-05  | 0.0337  |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel    | (16, 55, 880)    | 774,400    | -1.18e-05 | 0.0337  |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel  | (880, 16, 55)    | 774,400    | -5.27e-05 | 0.0337  |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel  | (880, 16, 55)    | 774,400    | -4.83e-05 | 0.0337  |
| img/Transformer/encoderblock_3/LayerNorm_0/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_3/LayerNorm_0/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_3/LayerNorm_1/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_3/LayerNorm_1/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias                      | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel                    | (880, 2320)      | 2,041,600  | 4.08e-06  | 0.025   |
| img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias                      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel                    | (2320, 880)      | 2,041,600  | 2.53e-05  | 0.025   |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias      | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel    | (880, 16, 55)    | 774,400    | 2.78e-08  | 0.0337  |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel    | (16, 55, 880)    | 774,400    | -8.5e-05  | 0.0337  |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel  | (880, 16, 55)    | 774,400    | 2.16e-05  | 0.0337  |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel  | (880, 16, 55)    | 774,400    | 9.82e-06  | 0.0337  |
| img/Transformer/encoderblock_4/LayerNorm_0/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_4/LayerNorm_0/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_4/LayerNorm_1/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_4/LayerNorm_1/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias                      | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel                    | (880, 2320)      | 2,041,600  | -1.29e-05 | 0.025   |
| img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias                      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel                    | (2320, 880)      | 2,041,600  | -2.48e-05 | 0.025   |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias      | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel    | (880, 16, 55)    | 774,400    | 5.81e-05  | 0.0337  |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel    | (16, 55, 880)    | 774,400    | 5.11e-06  | 0.0337  |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel  | (880, 16, 55)    | 774,400    | -2.87e-05 | 0.0337  |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel  | (880, 16, 55)    | 774,400    | 9.15e-06  | 0.0337  |
| img/Transformer/encoderblock_5/LayerNorm_0/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_5/LayerNorm_0/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_5/LayerNorm_1/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_5/LayerNorm_1/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias                      | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel                    | (880, 2320)      | 2,041,600  | -2.61e-05 | 0.025   |
| img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias                      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel                    | (2320, 880)      | 2,041,600  | -1.99e-05 | 0.025   |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias      | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel    | (880, 16, 55)    | 774,400    | 9.66e-05  | 0.0337  |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel    | (16, 55, 880)    | 774,400    | 4.92e-05  | 0.0337  |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel  | (880, 16, 55)    | 774,400    | -6.44e-05 | 0.0337  |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel  | (880, 16, 55)    | 774,400    | -2.86e-05 | 0.0337  |
| img/Transformer/encoderblock_6/LayerNorm_0/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_6/LayerNorm_0/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_6/LayerNorm_1/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_6/LayerNorm_1/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias                      | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel                    | (880, 2320)      | 2,041,600  | -5.45e-06 | 0.025   |
| img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias                      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel                    | (2320, 880)      | 2,041,600  | -3.12e-05 | 0.025   |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias      | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel    | (880, 16, 55)    | 774,400    | 3.93e-05  | 0.0337  |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel    | (16, 55, 880)    | 774,400    | 7.13e-05  | 0.0337  |
I0125 01:14:31.862540 140307309722688 parameter_overview.py:264] 
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel  | (880, 16, 55)    | 774,400    | 3.61e-05  | 0.0337  |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel  | (880, 16, 55)    | 774,400    | -1.77e-05 | 0.0337  |
| img/Transformer/encoderblock_7/LayerNorm_0/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_7/LayerNorm_0/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_7/LayerNorm_1/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_7/LayerNorm_1/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias                      | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel                    | (880, 2320)      | 2,041,600  | 1.39e-05  | 0.025   |
| img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias                      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel                    | (2320, 880)      | 2,041,600  | 8.36e-06  | 0.025   |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias      | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel    | (880, 16, 55)    | 774,400    | 1.13e-05  | 0.0337  |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel    | (16, 55, 880)    | 774,400    | -5.1e-05  | 0.0337  |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel  | (880, 16, 55)    | 774,400    | -3.58e-05 | 0.0337  |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel  | (880, 16, 55)    | 774,400    | 7.55e-06  | 0.0337  |
| img/Transformer/encoderblock_8/LayerNorm_0/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_8/LayerNorm_0/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_8/LayerNorm_1/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_8/LayerNorm_1/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias                      | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel                    | (880, 2320)      | 2,041,600  | -7.8e-06  | 0.025   |
| img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias                      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel                    | (2320, 880)      | 2,041,600  | 1.32e-05  | 0.025   |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias      | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel    | (880, 16, 55)    | 774,400    | -2.6e-05  | 0.0337  |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel    | (16, 55, 880)    | 774,400    | 4.86e-05  | 0.0337  |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel  | (880, 16, 55)    | 774,400    | 6.19e-05  | 0.0337  |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel  | (880, 16, 55)    | 774,400    | -1.99e-05 | 0.0337  |
| img/Transformer/encoderblock_9/LayerNorm_0/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_9/LayerNorm_0/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_9/LayerNorm_1/bias                             | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_9/LayerNorm_1/scale                            | (880,)           | 880        | 1.0       | 0.0     |
| img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias                      | (2320,)          | 2,320      | 0.0       | 0.0     |
| img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel                    | (880, 2320)      | 2,041,600  | 9.29e-06  | 0.025   |
| img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias                      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel                    | (2320, 880)      | 2,041,600  | -4.11e-06 | 0.025   |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias      | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel    | (880, 16, 55)    | 774,400    | -1.96e-05 | 0.0337  |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias      | (880,)           | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel    | (16, 55, 880)    | 774,400    | 6.18e-05  | 0.0337  |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel  | (880, 16, 55)    | 774,400    | -2.76e-05 | 0.0337  |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias    | (16, 55)         | 880        | 0.0       | 0.0     |
| img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel  | (880, 16, 55)    | 774,400    | 4.06e-05  | 0.0337  |
| img/cls                                                                     | (1, 1, 880)      | 880        | 0.0       | 0.0     |
| img/embedding/kernel                                                        | (14, 14, 3, 880) | 517,440    | -0.000147 | 0.0413  |
| img/encoder_norm/bias                                                       | (880,)           | 880        | 0.0       | 0.0     |
| img/encoder_norm/scale                                                      | (880,)           | 880        | 1.0       | 0.0     |
| img/head/kernel                                                             | (880, 512)       | 450,560    | -1.52e-05 | 0.0337  |
| t                                                                           | (1,)             | 1          | 2.66      | 0.0     |
| txt/Embed_0/embedding                                                       | (32000, 512)     | 16,384,000 | 4e-06     | 0.02    |
| txt/Transformer/encoderblock_0/LayerNorm_0/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_0/LayerNorm_0/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_0/LayerNorm_1/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_0/LayerNorm_1/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias                      | (2048,)          | 2,048      | 0.0       | 0.0     |
| txt/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel                    | (512, 2048)      | 1,048,576  | 2.28e-05  | 0.0313  |
| txt/Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias                      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel                    | (2048, 512)      | 1,048,576  | -6.61e-06 | 0.00902 |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias      | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)     | 262,144    | -5.43e-05 | 0.0442  |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)     | 262,144    | 4.5e-06   | 0.00903 |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)     | 262,144    | 2.26e-05  | 0.0442  |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)     | 262,144    | 3.43e-05  | 0.0442  |
| txt/Transformer/encoderblock_1/LayerNorm_0/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_1/LayerNorm_0/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_1/LayerNorm_1/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_1/LayerNorm_1/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias                      | (2048,)          | 2,048      | 0.0       | 0.0     |
I0125 01:14:31.862582 140307309722688 parameter_overview.py:264] 
| txt/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel                    | (512, 2048)      | 1,048,576  | 2.36e-06  | 0.0313  |
| txt/Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias                      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel                    | (2048, 512)      | 1,048,576  | 2.28e-06  | 0.00902 |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias      | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)     | 262,144    | 7.03e-05  | 0.0442  |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)     | 262,144    | -1.81e-05 | 0.00902 |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)     | 262,144    | 4.3e-06   | 0.0441  |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)     | 262,144    | 5.16e-05  | 0.0441  |
| txt/Transformer/encoderblock_10/LayerNorm_0/bias                            | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_10/LayerNorm_0/scale                           | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_10/LayerNorm_1/bias                            | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_10/LayerNorm_1/scale                           | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias                     | (2048,)          | 2,048      | 0.0       | 0.0     |
| txt/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel                   | (512, 2048)      | 1,048,576  | -9.68e-06 | 0.0312  |
| txt/Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias                     | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel                   | (2048, 512)      | 1,048,576  | -7.3e-06  | 0.00901 |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias     | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel   | (512, 8, 64)     | 262,144    | 2.7e-05   | 0.0442  |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias     | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel   | (8, 64, 512)     | 262,144    | -7.14e-06 | 0.00903 |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias   | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel | (512, 8, 64)     | 262,144    | 3.06e-05  | 0.0441  |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias   | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel | (512, 8, 64)     | 262,144    | -0.000111 | 0.0442  |
| txt/Transformer/encoderblock_11/LayerNorm_0/bias                            | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_11/LayerNorm_0/scale                           | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_11/LayerNorm_1/bias                            | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_11/LayerNorm_1/scale                           | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias                     | (2048,)          | 2,048      | 0.0       | 0.0     |
| txt/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel                   | (512, 2048)      | 1,048,576  | -2.45e-05 | 0.0313  |
| txt/Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias                     | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel                   | (2048, 512)      | 1,048,576  | 5.18e-06  | 0.00901 |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias     | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel   | (512, 8, 64)     | 262,144    | 2.29e-05  | 0.0441  |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias     | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel   | (8, 64, 512)     | 262,144    | 8.92e-06  | 0.00904 |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias   | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel | (512, 8, 64)     | 262,144    | -0.000123 | 0.0442  |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias   | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel | (512, 8, 64)     | 262,144    | 0.000117  | 0.0442  |
| txt/Transformer/encoderblock_2/LayerNorm_0/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_2/LayerNorm_0/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_2/LayerNorm_1/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_2/LayerNorm_1/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias                      | (2048,)          | 2,048      | 0.0       | 0.0     |
| txt/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel                    | (512, 2048)      | 1,048,576  | 1.85e-05  | 0.0312  |
| txt/Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias                      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel                    | (2048, 512)      | 1,048,576  | 1.13e-05  | 0.00902 |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias      | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)     | 262,144    | 2.76e-05  | 0.0441  |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)     | 262,144    | 1.78e-05  | 0.00902 |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)     | 262,144    | 8.18e-05  | 0.0442  |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)     | 262,144    | -1.15e-05 | 0.0443  |
| txt/Transformer/encoderblock_3/LayerNorm_0/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_3/LayerNorm_0/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_3/LayerNorm_1/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_3/LayerNorm_1/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias                      | (2048,)          | 2,048      | 0.0       | 0.0     |
| txt/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel                    | (512, 2048)      | 1,048,576  | 2.61e-05  | 0.0312  |
| txt/Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias                      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel                    | (2048, 512)      | 1,048,576  | -1.15e-05 | 0.00903 |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias      | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)     | 262,144    | -3.85e-05 | 0.0443  |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)     | 262,144    | 1.74e-05  | 0.00902 |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)     | 262,144    | -8.37e-05 | 0.0441  |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)     | 262,144    | -0.000173 | 0.0444  |
| txt/Transformer/encoderblock_4/LayerNorm_0/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_4/LayerNorm_0/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_4/LayerNorm_1/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_4/LayerNorm_1/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias                      | (2048,)          | 2,048      | 0.0       | 0.0     |
I0125 01:14:31.862623 140307309722688 parameter_overview.py:264] 
| txt/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel                    | (512, 2048)      | 1,048,576  | 7.67e-05  | 0.0313  |
| txt/Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias                      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel                    | (2048, 512)      | 1,048,576  | 9.1e-06   | 0.00901 |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias      | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)     | 262,144    | 4.27e-05  | 0.0444  |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)     | 262,144    | 1.37e-05  | 0.00902 |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)     | 262,144    | 0.000109  | 0.0441  |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)     | 262,144    | -0.000132 | 0.0441  |
| txt/Transformer/encoderblock_5/LayerNorm_0/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_5/LayerNorm_0/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_5/LayerNorm_1/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_5/LayerNorm_1/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias                      | (2048,)          | 2,048      | 0.0       | 0.0     |
| txt/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel                    | (512, 2048)      | 1,048,576  | 4.78e-05  | 0.0312  |
| txt/Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias                      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel                    | (2048, 512)      | 1,048,576  | -5.45e-06 | 0.00903 |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias      | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)     | 262,144    | -0.000206 | 0.0442  |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)     | 262,144    | -3.86e-06 | 0.00901 |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)     | 262,144    | 2.11e-05  | 0.0442  |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)     | 262,144    | 2.62e-05  | 0.0442  |
| txt/Transformer/encoderblock_6/LayerNorm_0/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_6/LayerNorm_0/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_6/LayerNorm_1/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_6/LayerNorm_1/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias                      | (2048,)          | 2,048      | 0.0       | 0.0     |
| txt/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel                    | (512, 2048)      | 1,048,576  | -6.34e-05 | 0.0313  |
| txt/Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias                      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel                    | (2048, 512)      | 1,048,576  | -6.81e-06 | 0.00903 |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias      | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)     | 262,144    | 7.69e-05  | 0.0442  |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)     | 262,144    | -8.59e-06 | 0.00902 |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)     | 262,144    | -2.12e-05 | 0.0443  |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)     | 262,144    | -7.48e-05 | 0.0442  |
| txt/Transformer/encoderblock_7/LayerNorm_0/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_7/LayerNorm_0/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_7/LayerNorm_1/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_7/LayerNorm_1/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias                      | (2048,)          | 2,048      | 0.0       | 0.0     |
| txt/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel                    | (512, 2048)      | 1,048,576  | -2.7e-05  | 0.0312  |
| txt/Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias                      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel                    | (2048, 512)      | 1,048,576  | 9.78e-06  | 0.00902 |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias      | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)     | 262,144    | 4.24e-05  | 0.0442  |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)     | 262,144    | -7.1e-06  | 0.00903 |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)     | 262,144    | -7.34e-05 | 0.0443  |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)     | 262,144    | -4.52e-05 | 0.0442  |
| txt/Transformer/encoderblock_8/LayerNorm_0/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_8/LayerNorm_0/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_8/LayerNorm_1/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_8/LayerNorm_1/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias                      | (2048,)          | 2,048      | 0.0       | 0.0     |
| txt/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel                    | (512, 2048)      | 1,048,576  | 2.52e-05  | 0.0313  |
| txt/Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias                      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel                    | (2048, 512)      | 1,048,576  | -6.68e-06 | 0.00902 |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias      | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)     | 262,144    | -2.64e-05 | 0.0442  |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)     | 262,144    | 1.66e-05  | 0.00902 |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)     | 262,144    | 6.85e-05  | 0.0442  |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)     | 262,144    | 4.4e-05   | 0.0442  |
| txt/Transformer/encoderblock_9/LayerNorm_0/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_9/LayerNorm_0/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_9/LayerNorm_1/bias                             | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_9/LayerNorm_1/scale                            | (512,)           | 512        | 1.0       | 0.0     |
| txt/Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias                      | (2048,)          | 2,048      | 0.0       | 0.0     |
I0125 01:14:31.862663 140307309722688 parameter_overview.py:264] 
| txt/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel                    | (512, 2048)      | 1,048,576  | 3.33e-05  | 0.0313  |
| txt/Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias                      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel                    | (2048, 512)      | 1,048,576  | 1.11e-06  | 0.00902 |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias      | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel    | (512, 8, 64)     | 262,144    | -2.11e-05 | 0.0442  |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias      | (512,)           | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel    | (8, 64, 512)     | 262,144    | 1.05e-05  | 0.00904 |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel  | (512, 8, 64)     | 262,144    | 1.34e-06  | 0.0442  |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias    | (8, 64)          | 512        | 0.0       | 0.0     |
| txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel  | (512, 8, 64)     | 262,144    | 4.68e-05  | 0.0442  |
| txt/encoder_norm/bias                                                       | (512,)           | 512        | 0.0       | 0.0     |
| txt/encoder_norm/scale                                                      | (512,)           | 512        | 1.0       | 0.0     |
| txt/head/kernel                                                             | (512, 512)       | 262,144    | 6.96e-05  | 0.0441  |
| txt/pos_embedding                                                           | (1, 16, 512)     | 8,192      | -3.76e-05 | 0.0101  |
+-----------------------------------------------------------------------------+------------------+------------+-----------+---------+
Total: 184,893,329
I0125 01:14:31.862788 140307309722688 utils.py:844] [35m[0][0m num_params = 184893329.0
I0125 01:14:31.862866 140307309722688 main.py:119] [33mNOTE[0m: Initializing scale_by_adam optimizer...
/home/jyang347/CLIPA/clipa_jax/helpers/utils.py:492: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  vals, tree_def = jax.tree_flatten(tree)
I0125 01:14:31.865746 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/LayerNorm_0/bias - matched by .*
I0125 01:14:31.865898 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/LayerNorm_0/scale - matched by .*
I0125 01:14:31.865958 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/LayerNorm_1/bias - matched by .*
I0125 01:14:31.866011 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/LayerNorm_1/scale - matched by .*
I0125 01:14:31.866056 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.866101 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.866150 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.866193 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.866235 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.866278 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.866320 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.866362 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.866404 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.866447 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.866489 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.866531 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.866577 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/LayerNorm_0/bias - matched by .*
I0125 01:14:31.866620 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/LayerNorm_0/scale - matched by .*
I0125 01:14:31.866662 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/LayerNorm_1/bias - matched by .*
I0125 01:14:31.866704 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/LayerNorm_1/scale - matched by .*
I0125 01:14:31.866751 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.866793 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.866835 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.866878 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.866920 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.866961 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.867003 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.867044 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.867086 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.867128 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.867170 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.867222 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.867266 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/LayerNorm_0/bias - matched by .*
I0125 01:14:31.867308 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/LayerNorm_0/scale - matched by .*
I0125 01:14:31.867350 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/LayerNorm_1/bias - matched by .*
I0125 01:14:31.867392 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/LayerNorm_1/scale - matched by .*
I0125 01:14:31.867434 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.867475 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.867517 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.867559 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.867600 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.867642 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.867683 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.867740 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.867776 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.867830 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.867867 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.867906 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.867943 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/LayerNorm_0/bias - matched by .*
I0125 01:14:31.867980 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/LayerNorm_0/scale - matched by .*
I0125 01:14:31.868018 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/LayerNorm_1/bias - matched by .*
I0125 01:14:31.868056 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/LayerNorm_1/scale - matched by .*
I0125 01:14:31.868093 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.868131 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.868168 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.868205 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.868242 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.868278 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.868316 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.868353 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.868390 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.868427 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.868464 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.868501 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.868538 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/LayerNorm_0/bias - matched by .*
I0125 01:14:31.868575 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/LayerNorm_0/scale - matched by .*
I0125 01:14:31.868612 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/LayerNorm_1/bias - matched by .*
I0125 01:14:31.868649 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/LayerNorm_1/scale - matched by .*
I0125 01:14:31.868686 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.868726 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.868764 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.868811 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.868846 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.868882 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.868918 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.868953 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.868987 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.869022 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.869058 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.869093 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.869127 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/LayerNorm_0/bias - matched by .*
I0125 01:14:31.869162 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/LayerNorm_0/scale - matched by .*
I0125 01:14:31.869197 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/LayerNorm_1/bias - matched by .*
I0125 01:14:31.869232 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/LayerNorm_1/scale - matched by .*
I0125 01:14:31.869267 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.869302 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.869337 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.869372 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.869407 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.869442 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.869477 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.869512 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.869546 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.869581 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.869616 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.869650 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.869685 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/LayerNorm_0/bias - matched by .*
I0125 01:14:31.869720 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/LayerNorm_0/scale - matched by .*
I0125 01:14:31.869760 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/LayerNorm_1/bias - matched by .*
I0125 01:14:31.869795 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/LayerNorm_1/scale - matched by .*
I0125 01:14:31.869830 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.869865 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.869900 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.869936 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.869971 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.870006 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.870041 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.870077 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.870112 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.870146 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.870181 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.870216 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.870251 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/LayerNorm_0/bias - matched by .*
I0125 01:14:31.870286 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/LayerNorm_0/scale - matched by .*
I0125 01:14:31.870321 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/LayerNorm_1/bias - matched by .*
I0125 01:14:31.870356 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/LayerNorm_1/scale - matched by .*
I0125 01:14:31.870391 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.870425 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.870460 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.870495 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.870529 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.870564 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.870600 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.870635 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.870670 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.870704 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.870743 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.870778 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.870813 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/LayerNorm_0/bias - matched by .*
I0125 01:14:31.870849 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/LayerNorm_0/scale - matched by .*
I0125 01:14:31.870884 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/LayerNorm_1/bias - matched by .*
I0125 01:14:31.870919 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/LayerNorm_1/scale - matched by .*
I0125 01:14:31.870954 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.870989 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.871024 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.871058 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.871094 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.871129 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.871164 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.871198 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.871246 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.871282 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.871317 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.871352 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.871387 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/LayerNorm_0/bias - matched by .*
I0125 01:14:31.871422 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/LayerNorm_0/scale - matched by .*
I0125 01:14:31.871457 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/LayerNorm_1/bias - matched by .*
I0125 01:14:31.871492 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/LayerNorm_1/scale - matched by .*
I0125 01:14:31.871526 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.871562 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.871597 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.871632 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.871667 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.871704 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.871743 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.871778 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.871813 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.871848 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.871883 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.871918 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.871953 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/LayerNorm_0/bias - matched by .*
I0125 01:14:31.871988 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/LayerNorm_0/scale - matched by .*
I0125 01:14:31.872023 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/LayerNorm_1/bias - matched by .*
I0125 01:14:31.872057 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/LayerNorm_1/scale - matched by .*
I0125 01:14:31.872092 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.872128 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.872163 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.872198 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.872232 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.872267 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.872301 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.872336 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.872371 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.872406 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.872441 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.872476 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.872511 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/LayerNorm_0/bias - matched by .*
I0125 01:14:31.872545 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/LayerNorm_0/scale - matched by .*
I0125 01:14:31.872580 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/LayerNorm_1/bias - matched by .*
I0125 01:14:31.872615 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/LayerNorm_1/scale - matched by .*
I0125 01:14:31.872650 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.872684 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.872719 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.872757 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.872793 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.872846 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.872884 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.872920 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.872957 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.872994 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.873030 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.873068 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.873105 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/LayerNorm_0/bias - matched by .*
I0125 01:14:31.873142 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/LayerNorm_0/scale - matched by .*
I0125 01:14:31.873179 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/LayerNorm_1/bias - matched by .*
I0125 01:14:31.873215 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/LayerNorm_1/scale - matched by .*
I0125 01:14:31.873252 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.873289 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.873326 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.873363 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.873400 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.873437 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.873475 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.873512 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.873549 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.873586 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.873623 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.873680 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.873742 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/LayerNorm_0/bias - matched by .*
I0125 01:14:31.873784 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/LayerNorm_0/scale - matched by .*
I0125 01:14:31.873825 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/LayerNorm_1/bias - matched by .*
I0125 01:14:31.873867 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/LayerNorm_1/scale - matched by .*
I0125 01:14:31.873908 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.873949 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.873991 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.874032 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.874073 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.874114 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.874156 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.874197 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.874238 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.874279 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.874320 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.874362 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.874403 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/LayerNorm_0/bias - matched by .*
I0125 01:14:31.874445 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/LayerNorm_0/scale - matched by .*
I0125 01:14:31.874487 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/LayerNorm_1/bias - matched by .*
I0125 01:14:31.874529 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/LayerNorm_1/scale - matched by .*
I0125 01:14:31.874570 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.874611 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.874652 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.874694 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.874739 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.874781 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.874833 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.874873 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.874923 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.874976 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.875013 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.875051 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.875088 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/LayerNorm_0/bias - matched by .*
I0125 01:14:31.875124 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/LayerNorm_0/scale - matched by .*
I0125 01:14:31.875161 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/LayerNorm_1/bias - matched by .*
I0125 01:14:31.875198 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/LayerNorm_1/scale - matched by .*
I0125 01:14:31.875248 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.875286 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.875324 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.875361 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.875399 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.875436 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.875473 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.875511 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.875551 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.875589 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.875654 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.875696 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.875741 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/LayerNorm_0/bias - matched by .*
I0125 01:14:31.875782 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/LayerNorm_0/scale - matched by .*
I0125 01:14:31.875823 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/LayerNorm_1/bias - matched by .*
I0125 01:14:31.875864 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/LayerNorm_1/scale - matched by .*
I0125 01:14:31.875906 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.875948 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.875989 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.876030 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.876073 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.876115 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.876157 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.876198 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.876239 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.876281 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.876322 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.876363 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.876405 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/LayerNorm_0/bias - matched by .*
I0125 01:14:31.876446 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/LayerNorm_0/scale - matched by .*
I0125 01:14:31.876488 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/LayerNorm_1/bias - matched by .*
I0125 01:14:31.876529 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/LayerNorm_1/scale - matched by .*
I0125 01:14:31.876574 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.876616 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.876658 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.876699 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.876745 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.876788 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.876830 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.876872 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.876914 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.876955 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.876997 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.877039 140307309722688 utils.py:769] config.schedule: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.877081 140307309722688 utils.py:769] config.schedule: img/cls - matched by .*
I0125 01:14:31.877123 140307309722688 utils.py:769] config.schedule: img/embedding/kernel - matched by .*
I0125 01:14:31.877165 140307309722688 utils.py:769] config.schedule: img/encoder_norm/bias - matched by .*
I0125 01:14:31.877207 140307309722688 utils.py:769] config.schedule: img/encoder_norm/scale - matched by .*
I0125 01:14:31.877249 140307309722688 utils.py:769] config.schedule: img/head/kernel - matched by .*
I0125 01:14:31.877289 140307309722688 utils.py:769] config.schedule: t - matched by .*
I0125 01:14:31.877331 140307309722688 utils.py:769] config.schedule: txt/Embed_0/embedding - matched by .*
I0125 01:14:31.877372 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/LayerNorm_0/bias - matched by .*
I0125 01:14:31.877413 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/LayerNorm_0/scale - matched by .*
I0125 01:14:31.877454 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/LayerNorm_1/bias - matched by .*
I0125 01:14:31.877496 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/LayerNorm_1/scale - matched by .*
I0125 01:14:31.877537 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.877578 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.877620 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.877661 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.877703 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.877759 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.877794 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.877830 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.877865 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.877901 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.877937 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.877972 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.878008 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/LayerNorm_0/bias - matched by .*
I0125 01:14:31.878044 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/LayerNorm_0/scale - matched by .*
I0125 01:14:31.878079 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/LayerNorm_1/bias - matched by .*
I0125 01:14:31.878115 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/LayerNorm_1/scale - matched by .*
I0125 01:14:31.878150 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.878185 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.878220 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.878254 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.878289 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.878324 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.878359 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.878394 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.878429 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.878464 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.878499 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.878534 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.878570 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/LayerNorm_0/bias - matched by .*
I0125 01:14:31.878605 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/LayerNorm_0/scale - matched by .*
I0125 01:14:31.878640 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/LayerNorm_1/bias - matched by .*
I0125 01:14:31.878675 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/LayerNorm_1/scale - matched by .*
I0125 01:14:31.878710 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.878749 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.878785 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.878821 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.878856 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.878892 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.878927 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.878964 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.879000 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.879036 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.879071 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.879106 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.879142 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/LayerNorm_0/bias - matched by .*
I0125 01:14:31.879177 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/LayerNorm_0/scale - matched by .*
I0125 01:14:31.879220 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/LayerNorm_1/bias - matched by .*
I0125 01:14:31.879257 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/LayerNorm_1/scale - matched by .*
I0125 01:14:31.879292 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.879328 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.879362 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.879398 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.879432 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.879467 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.879502 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.879537 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.879572 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.879607 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.879641 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.879676 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.879710 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/LayerNorm_0/bias - matched by .*
I0125 01:14:31.879749 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/LayerNorm_0/scale - matched by .*
I0125 01:14:31.879784 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/LayerNorm_1/bias - matched by .*
I0125 01:14:31.879818 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/LayerNorm_1/scale - matched by .*
I0125 01:14:31.879853 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.879888 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.879923 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.879957 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.879992 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.880028 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.880064 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.880098 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.880133 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.880169 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.880203 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.880238 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.880273 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/LayerNorm_0/bias - matched by .*
I0125 01:14:31.880308 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/LayerNorm_0/scale - matched by .*
I0125 01:14:31.880342 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/LayerNorm_1/bias - matched by .*
I0125 01:14:31.880377 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/LayerNorm_1/scale - matched by .*
I0125 01:14:31.880412 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.880446 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.880481 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.880516 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.880551 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.880585 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.880620 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.880655 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.880690 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.880730 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.880766 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.880800 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.880835 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/LayerNorm_0/bias - matched by .*
I0125 01:14:31.880870 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/LayerNorm_0/scale - matched by .*
I0125 01:14:31.880908 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/LayerNorm_1/bias - matched by .*
I0125 01:14:31.880943 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/LayerNorm_1/scale - matched by .*
I0125 01:14:31.880978 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.881013 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.881049 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.881084 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.881119 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.881154 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.881189 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.881224 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.881259 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.881294 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.881330 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.881365 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.881400 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/LayerNorm_0/bias - matched by .*
I0125 01:14:31.881435 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/LayerNorm_0/scale - matched by .*
I0125 01:14:31.881469 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/LayerNorm_1/bias - matched by .*
I0125 01:14:31.881505 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/LayerNorm_1/scale - matched by .*
I0125 01:14:31.881540 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.881575 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.881610 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.881645 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.881680 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.881715 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.881753 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.881788 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.881824 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.881859 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.881894 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.881928 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.881963 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/LayerNorm_0/bias - matched by .*
I0125 01:14:31.881998 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/LayerNorm_0/scale - matched by .*
I0125 01:14:31.882032 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/LayerNorm_1/bias - matched by .*
I0125 01:14:31.882067 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/LayerNorm_1/scale - matched by .*
I0125 01:14:31.882102 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.882137 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.882172 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.882207 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.882242 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.882277 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.882312 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.882348 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.882383 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.882418 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.882453 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.882488 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.882522 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/LayerNorm_0/bias - matched by .*
I0125 01:14:31.882557 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/LayerNorm_0/scale - matched by .*
I0125 01:14:31.882592 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/LayerNorm_1/bias - matched by .*
I0125 01:14:31.882627 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/LayerNorm_1/scale - matched by .*
I0125 01:14:31.882661 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.882697 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.882736 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.882772 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.882807 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.882843 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.882878 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.882914 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.882949 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.882984 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.883019 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.883054 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.883089 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/LayerNorm_0/bias - matched by .*
I0125 01:14:31.883124 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/LayerNorm_0/scale - matched by .*
I0125 01:14:31.883160 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/LayerNorm_1/bias - matched by .*
I0125 01:14:31.883195 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/LayerNorm_1/scale - matched by .*
I0125 01:14:31.883244 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.883280 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.883316 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.883351 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.883389 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.883424 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.883459 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.883494 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.883529 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.883564 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.883600 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.883635 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.883671 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/LayerNorm_0/bias - matched by .*
I0125 01:14:31.883705 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/LayerNorm_0/scale - matched by .*
I0125 01:14:31.883750 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/LayerNorm_1/bias - matched by .*
I0125 01:14:31.883788 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/LayerNorm_1/scale - matched by .*
I0125 01:14:31.883823 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias - matched by .*
I0125 01:14:31.883859 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel - matched by .*
I0125 01:14:31.883894 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias - matched by .*
I0125 01:14:31.883929 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel - matched by .*
I0125 01:14:31.883964 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias - matched by .*
I0125 01:14:31.883999 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel - matched by .*
I0125 01:14:31.884034 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias - matched by .*
I0125 01:14:31.884070 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel - matched by .*
I0125 01:14:31.884105 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias - matched by .*
I0125 01:14:31.884140 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel - matched by .*
I0125 01:14:31.884176 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias - matched by .*
I0125 01:14:31.884212 140307309722688 utils.py:769] config.schedule: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel - matched by .*
I0125 01:14:31.884248 140307309722688 utils.py:769] config.schedule: txt/encoder_norm/bias - matched by .*
I0125 01:14:31.884283 140307309722688 utils.py:769] config.schedule: txt/encoder_norm/scale - matched by .*
I0125 01:14:31.884318 140307309722688 utils.py:769] config.schedule: txt/head/kernel - matched by .*
I0125 01:14:31.884353 140307309722688 utils.py:769] config.schedule: txt/pos_embedding - matched by .*
/home/jyang347/CLIPA/clipa_jax/optim/build_optax.py:292: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  assert not any(jax.tree_flatten(all_false)[0]), (
I0125 01:14:31.889556 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.889656 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.889708 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.889760 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.889801 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.889839 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.889882 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.889920 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.889957 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.889994 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.890031 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.890068 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.890110 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.890146 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.890184 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.890221 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.890257 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.890294 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.890335 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.890372 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.890408 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.890444 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.890481 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.890517 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.890559 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_12/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.890595 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_12/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.890632 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.890668 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.890704 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.890747 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_12/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.890788 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_13/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.890824 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_13/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.890861 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.890897 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.890933 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.890970 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_13/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.891010 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_14/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.891047 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_14/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.891083 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.891120 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.891156 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.891193 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_14/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.891246 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_15/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.891284 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_15/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.891320 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.891357 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.891393 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.891431 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_15/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.891472 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_16/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.891509 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_16/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.891545 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.891582 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.891618 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.891654 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_16/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.891696 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_17/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.891737 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_17/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.891774 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.891811 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.891848 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.891884 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_17/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.891925 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.891962 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.891998 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.892034 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.892069 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.892106 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.892146 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.892183 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.892219 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.892255 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.892291 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.892328 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.892368 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.892405 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.892441 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.892477 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.892513 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.892550 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.892590 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.892627 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.892663 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.892698 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.892739 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.892776 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.892816 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.892853 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.892890 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.892927 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.892964 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.892999 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.893040 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.893076 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.893113 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.893148 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.893184 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.893220 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.893260 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.893296 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.893332 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.893368 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.893404 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.893441 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.893481 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.893517 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.893554 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.893590 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.893626 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.893680 140307309722688 utils.py:769] config.wd_mults: img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.893739 140307309722688 utils.py:769] config.wd_mults: img/embedding/kernel - matched by .*/kernel$
I0125 01:14:31.893780 140307309722688 utils.py:769] config.wd_mults: img/head/kernel - matched by .*/kernel$
I0125 01:14:31.893826 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.893866 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.893905 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.893944 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.893983 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.894022 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.894066 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.894104 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.894143 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.894181 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.894220 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.894259 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.894302 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.894341 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.894379 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.894417 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.894455 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.894494 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.894537 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.894576 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.894615 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.894654 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.894693 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.894735 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.894779 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.894818 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.894867 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.894904 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.894940 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.894976 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.895016 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.895052 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.895088 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.895124 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.895160 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.895196 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.895246 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.895283 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.895320 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.895356 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.895393 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.895430 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.895471 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.895507 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.895543 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.895582 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.895640 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.895683 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.895735 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.895779 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.895823 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.895866 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.895909 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.895952 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.896000 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.896043 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.896085 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.896129 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.896172 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.896214 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.896262 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.896306 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.896349 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.896393 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.896436 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.896480 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.896528 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel - matched by .*/kernel$
I0125 01:14:31.896574 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel - matched by .*/kernel$
I0125 01:14:31.896617 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel - matched by .*/kernel$
I0125 01:14:31.896660 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel - matched by .*/kernel$
I0125 01:14:31.896703 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel - matched by .*/kernel$
I0125 01:14:31.896750 140307309722688 utils.py:769] config.wd_mults: txt/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel - matched by .*/kernel$
I0125 01:14:31.896795 140307309722688 utils.py:769] config.wd_mults: txt/head/kernel - matched by .*/kernel$
I0125 01:14:32.414062 140581069126720 utils.py:427] TIMING[z/secs/init]: 46.64734803396277
I0125 01:14:32.496194 139866951023680 utils.py:427] TIMING[z/secs/init]: 46.774670652113855
I0125 01:14:32.747318 139956134382656 utils.py:427] TIMING[z/secs/init]: 46.94130051485263
I0125 01:14:32.759927 140493899304000 utils.py:427] TIMING[z/secs/init]: 47.19345671799965
I0125 01:14:33.040846 140592021429312 utils.py:427] TIMING[z/secs/init]: 47.230970497010276
I0125 01:14:36.674380 140307309722688 main.py:119] [33mNOTE[0m: Kicking off misc stuff...
I0125 01:14:36.675542 140307309722688 main.py:119] [33mNOTE[0m: Replicating...
Steps:0/56014 [0.0%]
I0125 01:14:40.231596 140307309722688 main.py:119] [33mNOTE[0m: First step compilations...
Steps:0/56014 [0.0%]
I0125 01:14:54.696202 140307309722688 vit.py:166] remat policy: actcp
I0125 01:14:54.696367 140307309722688 vit.py:171] activation checkpointing actcp
/home/jyang347/CLIPA/clipa_jax/helpers/utils.py:492: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  vals, tree_def = jax.tree_flatten(tree)
/home/jyang347/CLIPA/clipa_jax/optim/build_optax.py:292: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  assert not any(jax.tree_flatten(all_false)[0]), (
I0125 01:14:55.650651 140212821134400 vit.py:166] remat policy: actcp
I0125 01:14:55.650818 140212821134400 vit.py:171] activation checkpointing actcp
/home/jyang347/CLIPA/clipa_jax/helpers/utils.py:492: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  vals, tree_def = jax.tree_flatten(tree)
/home/jyang347/CLIPA/clipa_jax/optim/build_optax.py:292: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  assert not any(jax.tree_flatten(all_false)[0]), (
I0125 01:14:55.854585 139959958596672 vit.py:166] remat policy: actcp
I0125 01:14:55.854755 139959958596672 vit.py:171] activation checkpointing actcp
/home/jyang347/CLIPA/clipa_jax/helpers/utils.py:492: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  vals, tree_def = jax.tree_flatten(tree)
/home/jyang347/CLIPA/clipa_jax/optim/build_optax.py:292: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  assert not any(jax.tree_flatten(all_false)[0]), (
I0125 01:14:55.856773 139866951023680 vit.py:166] remat policy: actcp
I0125 01:14:55.856950 139866951023680 vit.py:171] activation checkpointing actcp
/home/jyang347/CLIPA/clipa_jax/helpers/utils.py:492: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  vals, tree_def = jax.tree_flatten(tree)
/home/jyang347/CLIPA/clipa_jax/optim/build_optax.py:292: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  assert not any(jax.tree_flatten(all_false)[0]), (
I0125 01:14:56.121013 140581069126720 vit.py:166] remat policy: actcp
I0125 01:14:56.121195 140581069126720 vit.py:171] activation checkpointing actcp
/home/jyang347/CLIPA/clipa_jax/helpers/utils.py:492: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  vals, tree_def = jax.tree_flatten(tree)
/home/jyang347/CLIPA/clipa_jax/optim/build_optax.py:292: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  assert not any(jax.tree_flatten(all_false)[0]), (
I0125 01:14:56.290167 140592021429312 vit.py:166] remat policy: actcp
I0125 01:14:56.290326 140592021429312 vit.py:171] activation checkpointing actcp
/home/jyang347/CLIPA/clipa_jax/helpers/utils.py:492: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  vals, tree_def = jax.tree_flatten(tree)
/home/jyang347/CLIPA/clipa_jax/optim/build_optax.py:292: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  assert not any(jax.tree_flatten(all_false)[0]), (
I0125 01:14:56.973851 139956134382656 vit.py:166] remat policy: actcp
I0125 01:14:56.974006 139956134382656 vit.py:171] activation checkpointing actcp
/home/jyang347/CLIPA/clipa_jax/helpers/utils.py:492: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  vals, tree_def = jax.tree_flatten(tree)
/home/jyang347/CLIPA/clipa_jax/optim/build_optax.py:292: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.
  assert not any(jax.tree_flatten(all_false)[0]), (
I0125 01:14:58.438489 140493899304000 vit.py:166] remat policy: actcp
I0125 01:14:58.438657 140493899304000 vit.py:171] activation checkpointing actcp
/home/jyang347/CLIPA/clipa_jax/main.py:301: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:344: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:353: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:365: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:376: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(optim.replace_frozen(config.schedule, grads, 0.))
/home/jyang347/CLIPA/clipa_jax/main.py:378: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  ps = jax.tree_leaves(params)
/home/jyang347/CLIPA/clipa_jax/main.py:380: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  us = jax.tree_leaves(updates)
I0125 01:16:57.053287 140307309722688 utils.py:844] [35m[1][0m z/secs/update0 = 124.07220428902656
I0125 01:16:57.053694 140307309722688 utils.py:427] TIMING[z/secs/update0]: 124.07220428902656
I0125 01:16:57.085405 140307309722688 utils.py:844] [35m[1][0m global_schedule = 0.0
/home/jyang347/CLIPA/clipa_jax/main.py:301: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:344: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:353: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:365: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:376: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(optim.replace_frozen(config.schedule, grads, 0.))
/home/jyang347/CLIPA/clipa_jax/main.py:378: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  ps = jax.tree_leaves(params)
/home/jyang347/CLIPA/clipa_jax/main.py:380: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  us = jax.tree_leaves(updates)
I0125 01:16:57.838718 140212821134400 utils.py:427] TIMING[z/secs/update0]: 123.98939965595491
I0125 01:16:57.841311 140212821134400 prompt_engineering.py:92] Using 81 prompts_templates: ['a bad photo of a {}', 'a photo of many {}', 'a sculpture of a {}', 'a photo of the hard to see {}', 'a low resolution photo of the {}', 'a rendering of a {}', 'graffiti of a {}', 'a bad photo of the {}', 'a cropped photo of the {}', 'a tattoo of a {}', 'the embroidered {}', 'a photo of a hard to see {}', 'a bright photo of a {}', 'a photo of a clean {}', 'a photo of a dirty {}', 'a dark photo of the {}', 'a drawing of a {}', 'a photo of my {}', 'the plastic {}', 'a photo of the cool {}', 'a closeup photo of a {}', 'a black and white photo of the {}', 'a painting of the {}', 'a painting of a {}', 'a pixelated photo of the {}', 'a sculpture of the {}', 'a bright photo of the {}', 'a cropped photo of a {}', 'a plastic {}', 'a photo of the dirty {}', 'a jpeg corrupted photo of a {}', 'a blurry photo of the {}', 'a photo of the {}', 'a good photo of the {}', 'a rendering of the {}', 'a {} in a video game', 'a photo of one {}', 'a doodle of a {}', 'a closeup photo of the {}', 'a photo of a {}', 'the origami {}', 'the {} in a video game', 'a sketch of a {}', 'a doodle of the {}', 'a origami {}', 'a low resolution photo of a {}', 'the toy {}', 'a rendition of the {}', 'a photo of the clean {}', 'a photo of a large {}', 'a rendition of a {}', 'a photo of a nice {}', 'a photo of a weird {}', 'a blurry photo of a {}', 'a cartoon {}', 'art of a {}', 'a sketch of the {}', 'a embroidered {}', 'a pixelated photo of a {}', 'itap of the {}', 'a jpeg corrupted photo of the {}', 'a good photo of a {}', 'a plushie {}', 'a photo of the nice {}', 'a photo of the small {}', 'a photo of the weird {}', 'the cartoon {}', 'art of the {}', 'a drawing of the {}', 'a photo of the large {}', 'a black and white photo of a {}', 'the plushie {}', 'a dark photo of a {}', 'itap of a {}', 'graffiti of the {}', 'a toy {}', 'itap of my {}', 'a photo of a cool {}', 'a photo of a small {}', 'a tattoo of the {}', '{}']
I0125 01:16:57.845587 140212821134400 prompt_engineering.py:78] Using 1000 class_names: ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'american robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'american dipper', 'kite bird of prey', 'bald eagle', 'vulture', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'axolotl', 'american bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'green iguana', 'carolina anole', 'desert grassland whiptail lizard', 'agama', 'frillednecked lizard', 'alligator lizard', 'gila monster', 'european green lizard', 'chameleon', 'komodo dragon', 'nile crocodile', 'american alligator', 'triceratops', 'worm snake', 'ringnecked snake', 'eastern hognosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'african rock python', 'indian cobra', 'green mamba', 'sea snake', 'saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'trilobite', 'harvestman', 'scorpion', 'yellow garden spider', 'barn spider', 'european garden spider', 'southern black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie grouse', 'peafowl', 'quail', 'partridge', 'african grey parrot', 'macaw', 'sulphurcrested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'duck', 'redbreasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'american lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'limpkin', 'common gallinule', 'american coot', 'bustard', 'ruddy turnstone', 'dunlin', 'common redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'chihuahua', 'japanese chin', 'maltese', 'pekingese', 'shih tzu', 'king charles spaniel', 'papillon', 'toy terrier', 'rhodesian ridgeback', 'afghan hound', 'basset hound', 'beagle', 'bloodhound', 'bluetick coonhound', 'black and tan coonhound', 'treeing walker coonhound', 'english foxhound', 'redbone coonhound', 'borzoi', 'irish wolfhound', 'italian greyhound', 'whippet', 'ibizan hound', 'norwegian elkhound', 'otterhound', 'saluki', 'scottish deerhound', 'weimaraner', 'staffordshire bull terrier', 'american staffordshire terrier', 'bedlington terrier', 'border terrier', 'kerry blue terrier', 'irish terrier', 'norfolk terrier', 'norwich terrier', 'yorkshire terrier', 'wire fox terrier', 'lakeland terrier', 'sealyham terrier', 'airedale terrier', 'cairn terrier', 'australian terrier', 'dandie dinmont terrier', 'boston terrier', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'scottish terrier', 'tibetan terrier', 'australian silky terrier', 'softcoated wheaten terrier', 'west highland white terrier', 'lhasa apso', 'flatcoated retriever', 'curlycoated retriever', 'golden retriever', 'labrador retriever', 'chesapeake bay retriever', 'german shorthaired pointer', 'vizsla', 'english setter', 'irish setter', 'gordon setter', 'brittany dog', 'clumber spaniel', 'english springer spaniel', 'welsh springer spaniel', 'cocker spaniel', 'sussex spaniel', 'irish water spaniel', 'kuvasz', 'schipperke', 'groenendael dog', 'malinois', 'briard', 'australian kelpie', 'komondor', 'old english sheepdog', 'shetland sheepdog', 'collie', 'border collie', 'bouvier des flandres dog', 'rottweiler', 'german shepherd dog', 'dobermann', 'miniature pinscher', 'greater swiss mountain dog', 'bernese mountain dog', 'appenzeller sennenhund', 'entlebucher sennenhund', 'boxer', 'bullmastiff', 'tibetan mastiff', 'french bulldog', 'great dane', 'st bernard', 'husky', 'alaskan malamute', 'siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'leonberger', 'newfoundland dog', 'great pyrenees dog', 'samoyed', 'pomeranian', 'chow chow', 'keeshond', 'brussels griffon', 'pembroke welsh corgi', 'cardigan welsh corgi', 'toy poodle', 'miniature poodle', 'standard poodle', 'mexican hairless dog xoloitzcuintli', 'grey wolf', 'alaskan tundra wolf', 'red wolf or maned wolf', 'coyote', 'dingo', 'dhole', 'african wild dog', 'hyena', 'red fox', 'kit fox', 'arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'persian cat', 'siamese cat', 'egyptian mau', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'american black bear', 'polar bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket insect', 'stick insect', 'cockroach', 'praying mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamerwinged butterfly', 'starfish', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'hare', 'angora rabbit', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'common sorrel horse', 'zebra', 'pig', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram adult male sheep', 'bighorn sheep', 'alpine ibex', 'hartebeest', 'impala antelope', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'european polecat', 'blackfooted ferret', 'otter', 'skunk', 'badger', 'armadillo', 'threetoed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas monkey', 'baboon', 'macaque', 'langur', 'blackandwhite colobus', 'proboscis monkey', 'marmoset', 'whiteheaded capuchin', 'howler monkey', 'titi monkey', 'geoffroys spider monkey', 'common squirrel monkey', 'ringtailed lemur', 'indri', 'asian elephant', 'african bush elephant', 'red panda', 'giant panda', 'snoek fish', 'eel', 'silver salmon', 'rock beauty fish', 'clownfish', 'sturgeon', 'gar fish', 'lionfish', 'pufferfish', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibious vehicle', 'analog clock', 'apiary', 'apron', 'trash can', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint pen', 'bandaid', 'banjo', 'baluster handrail', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'wheelbarrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'swimming cap', 'bath towel', 'bathtub', 'station wagon', 'lighthouse', 'beaker', 'military hat bearskin or shako', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'bikini', 'ring binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookcase', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'highspeed train', 'butcher shop', 'taxicab', 'cauldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', 'tool kit', 'cardboard box carton', 'car wheel', 'automated teller machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'cd player', 'cello', 'mobile phone', 'chain', 'chainlink fence', 'chain mail', 'chainsaw', 'storage chest', 'chiffonier', 'bell or wind chime', 'china cabinet', 'christmas stocking', 'church', 'movie theater', 'cleaver', 'cliff dwelling', 'cloak', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'construction crane', 'crash helmet', 'crate', 'infant bed', 'crock pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'rotary dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'dishwasher', 'disc brake', 'dock', 'dog sled', 'dome', 'doormat', 'drilling rig', 'drum', 'drumstick', 'dumbbell', 'dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fireboat', 'fire truck', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'fourposter bed', 'freight car', 'french horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'goblet', 'gokart', 'golf ball', 'golf cart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'radiator grille', 'grocery store', 'guillotine', 'hair clip', 'hair spray', 'halftrack', 'hammer', 'hamper', 'hair dryer', 'handheld computer', 'handkerchief', 'hard disk drive', 'harmonica', 'harp', 'combine harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoop skirt', 'gymnastic horizontal bar', 'horsedrawn vehicle', 'hourglass', 'ipod', 'clothes iron', 'carved pumpkin', 'jeans', 'jeep', 'tshirt', 'jigsaw puzzle', 'rickshaw', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'ocean liner', 'lipstick', 'slipon shoe', 'lotion', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'mailbox', 'tights', 'onepiece bathing suit', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine cabinet', 'megalith', 'microphone', 'microwave oven', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'ford model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar and pestle', 'graduation cap', 'mosque', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'mousetrap', 'moving van', 'muzzle', 'metal nail', 'neck brace', 'necklace', 'baby pacifier', 'notebook computer', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'pipe organ', 'oscilloscope', 'overskirt', 'bullock cart', 'oxygen mask', 'product packet packaging', 'paddle', 'paddle wheel', 'padlock', 'paintbrush', 'pajamas', 'palace', 'pan flute', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'patio', 'payphone', 'pedestal', 'pencil case', 'pencil sharpener', 'perfume', 'petri dish', 'photocopier', 'plectrum', 'pickelhaube', 'picket fence', 'pickup truck', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'pingpong ball', 'pinwheel', 'pirate ship', 'drink pitcher', 'block plane', 'planetarium', 'plastic bag', 'plate rack', 'farm plow', 'plunger', 'polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'soda bottle', 'plant pot', 'potters wheel', 'power drill', 'prayer rug', 'printer', 'prison', 'missile', 'projector', 'hockey puck', 'punching bag', 'purse', 'quill', 'quilt', 'race car', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safe', 'safety pin', 'salt shaker', 'sandal', 'sarong', 'saxophone', 'scabbard', 'weighing scale', 'school bus', 'schooner', 'scoreboard', 'crt monitor', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe store', 'shoji screen room divider', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar thermal collector', 'sombrero', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'spatula', 'motorboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'through arch bridge', 'steel drum', 'stethoscope', 'scarf', 'stone wall', 'stopwatch', 'stove', 'strainer', 'tram', 'stretcher', 'couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'suspension bridge', 'mop', 'sweatshirt', 'swim trunks shorts', 'swing', 'electrical switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy bear', 'television', 'tennis ball', 'thatched roof', 'front curtain', 'thimble', 'threshing machine', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toy store', 'tractor', 'semitrailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'hot tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright piano', 'vacuum cleaner', 'vase', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'hair wig', 'window screen', 'window shade', 'windsor tie', 'wine bottle', 'airplane wing', 'wok', 'wooden spoon', 'wool', 'splitrail fence', 'shipwreck', 'sailboat', 'yurt', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'popsicle', 'baguette', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'mashed potatoes', 'cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'granny smith apple', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'cherimoya custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate syrup', 'dough', 'meatloaf', 'pizza', 'pot pie', 'burrito', 'red wine', 'espresso', 'tea cup', 'eggnog', 'mountain', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeshore', 'promontory', 'sandbar', 'beach', 'valley', 'volcano', 'baseball player', 'bridegroom', 'scuba diver', 'rapeseed', 'daisy', 'yellow ladys slipper', 'corn', 'acorn', 'rose hip', 'horse chestnut seed', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'bolete', 'corn cob', 'toilet paper']
I0125 01:16:57.995818 140212821134400 dataset_info.py:566] Load dataset info from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:16:58.278853 140212821134400 dataset_info.py:642] Field info.description from disk and from code do not match. Keeping the one from code.
I0125 01:16:58.279216 140212821134400 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:16:58.345057 140212821134400 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split _EvenSplit(split='validation', index=4, count=8, drop_remainder=False), from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:16:58.348303 140212821134400 api.py:459] Data before pre-processing:
{'file_name': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'image': <tf.Tensor 'args_1:0' shape=(None, None, 3) dtype=uint8>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:16:58.542641 140212821134400 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'truediv_1:0' shape=(56, 56, 3) dtype=float32>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:16:59.071565 140212821134400 api.py:459] Data before pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'texts': <tf.Tensor 'args_1:0' shape=() dtype=string>}
/home/jyang347/CLIPA/clipa_jax/main.py:301: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:344: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:353: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:365: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:376: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(optim.replace_frozen(config.schedule, grads, 0.))
/home/jyang347/CLIPA/clipa_jax/main.py:378: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  ps = jax.tree_leaves(params)
/home/jyang347/CLIPA/clipa_jax/main.py:380: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  us = jax.tree_leaves(updates)
I0125 01:16:59.088191 139959958596672 utils.py:427] TIMING[z/secs/update0]: 125.01542029692791
I0125 01:16:59.090892 139959958596672 prompt_engineering.py:92] Using 81 prompts_templates: ['a bad photo of a {}', 'a photo of many {}', 'a sculpture of a {}', 'a photo of the hard to see {}', 'a low resolution photo of the {}', 'a rendering of a {}', 'graffiti of a {}', 'a bad photo of the {}', 'a cropped photo of the {}', 'a tattoo of a {}', 'the embroidered {}', 'a photo of a hard to see {}', 'a bright photo of a {}', 'a photo of a clean {}', 'a photo of a dirty {}', 'a dark photo of the {}', 'a drawing of a {}', 'a photo of my {}', 'the plastic {}', 'a photo of the cool {}', 'a closeup photo of a {}', 'a black and white photo of the {}', 'a painting of the {}', 'a painting of a {}', 'a pixelated photo of the {}', 'a sculpture of the {}', 'a bright photo of the {}', 'a cropped photo of a {}', 'a plastic {}', 'a photo of the dirty {}', 'a jpeg corrupted photo of a {}', 'a blurry photo of the {}', 'a photo of the {}', 'a good photo of the {}', 'a rendering of the {}', 'a {} in a video game', 'a photo of one {}', 'a doodle of a {}', 'a closeup photo of the {}', 'a photo of a {}', 'the origami {}', 'the {} in a video game', 'a sketch of a {}', 'a doodle of the {}', 'a origami {}', 'a low resolution photo of a {}', 'the toy {}', 'a rendition of the {}', 'a photo of the clean {}', 'a photo of a large {}', 'a rendition of a {}', 'a photo of a nice {}', 'a photo of a weird {}', 'a blurry photo of a {}', 'a cartoon {}', 'art of a {}', 'a sketch of the {}', 'a embroidered {}', 'a pixelated photo of a {}', 'itap of the {}', 'a jpeg corrupted photo of the {}', 'a good photo of a {}', 'a plushie {}', 'a photo of the nice {}', 'a photo of the small {}', 'a photo of the weird {}', 'the cartoon {}', 'art of the {}', 'a drawing of the {}', 'a photo of the large {}', 'a black and white photo of a {}', 'the plushie {}', 'a dark photo of a {}', 'itap of a {}', 'graffiti of the {}', 'a toy {}', 'itap of my {}', 'a photo of a cool {}', 'a photo of a small {}', 'a tattoo of the {}', '{}']
I0125 01:16:59.095130 139959958596672 prompt_engineering.py:78] Using 1000 class_names: ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'american robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'american dipper', 'kite bird of prey', 'bald eagle', 'vulture', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'axolotl', 'american bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'green iguana', 'carolina anole', 'desert grassland whiptail lizard', 'agama', 'frillednecked lizard', 'alligator lizard', 'gila monster', 'european green lizard', 'chameleon', 'komodo dragon', 'nile crocodile', 'american alligator', 'triceratops', 'worm snake', 'ringnecked snake', 'eastern hognosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'african rock python', 'indian cobra', 'green mamba', 'sea snake', 'saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'trilobite', 'harvestman', 'scorpion', 'yellow garden spider', 'barn spider', 'european garden spider', 'southern black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie grouse', 'peafowl', 'quail', 'partridge', 'african grey parrot', 'macaw', 'sulphurcrested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'duck', 'redbreasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'american lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'limpkin', 'common gallinule', 'american coot', 'bustard', 'ruddy turnstone', 'dunlin', 'common redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'chihuahua', 'japanese chin', 'maltese', 'pekingese', 'shih tzu', 'king charles spaniel', 'papillon', 'toy terrier', 'rhodesian ridgeback', 'afghan hound', 'basset hound', 'beagle', 'bloodhound', 'bluetick coonhound', 'black and tan coonhound', 'treeing walker coonhound', 'english foxhound', 'redbone coonhound', 'borzoi', 'irish wolfhound', 'italian greyhound', 'whippet', 'ibizan hound', 'norwegian elkhound', 'otterhound', 'saluki', 'scottish deerhound', 'weimaraner', 'staffordshire bull terrier', 'american staffordshire terrier', 'bedlington terrier', 'border terrier', 'kerry blue terrier', 'irish terrier', 'norfolk terrier', 'norwich terrier', 'yorkshire terrier', 'wire fox terrier', 'lakeland terrier', 'sealyham terrier', 'airedale terrier', 'cairn terrier', 'australian terrier', 'dandie dinmont terrier', 'boston terrier', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'scottish terrier', 'tibetan terrier', 'australian silky terrier', 'softcoated wheaten terrier', 'west highland white terrier', 'lhasa apso', 'flatcoated retriever', 'curlycoated retriever', 'golden retriever', 'labrador retriever', 'chesapeake bay retriever', 'german shorthaired pointer', 'vizsla', 'english setter', 'irish setter', 'gordon setter', 'brittany dog', 'clumber spaniel', 'english springer spaniel', 'welsh springer spaniel', 'cocker spaniel', 'sussex spaniel', 'irish water spaniel', 'kuvasz', 'schipperke', 'groenendael dog', 'malinois', 'briard', 'australian kelpie', 'komondor', 'old english sheepdog', 'shetland sheepdog', 'collie', 'border collie', 'bouvier des flandres dog', 'rottweiler', 'german shepherd dog', 'dobermann', 'miniature pinscher', 'greater swiss mountain dog', 'bernese mountain dog', 'appenzeller sennenhund', 'entlebucher sennenhund', 'boxer', 'bullmastiff', 'tibetan mastiff', 'french bulldog', 'great dane', 'st bernard', 'husky', 'alaskan malamute', 'siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'leonberger', 'newfoundland dog', 'great pyrenees dog', 'samoyed', 'pomeranian', 'chow chow', 'keeshond', 'brussels griffon', 'pembroke welsh corgi', 'cardigan welsh corgi', 'toy poodle', 'miniature poodle', 'standard poodle', 'mexican hairless dog xoloitzcuintli', 'grey wolf', 'alaskan tundra wolf', 'red wolf or maned wolf', 'coyote', 'dingo', 'dhole', 'african wild dog', 'hyena', 'red fox', 'kit fox', 'arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'persian cat', 'siamese cat', 'egyptian mau', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'american black bear', 'polar bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket insect', 'stick insect', 'cockroach', 'praying mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamerwinged butterfly', 'starfish', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'hare', 'angora rabbit', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'common sorrel horse', 'zebra', 'pig', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram adult male sheep', 'bighorn sheep', 'alpine ibex', 'hartebeest', 'impala antelope', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'european polecat', 'blackfooted ferret', 'otter', 'skunk', 'badger', 'armadillo', 'threetoed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas monkey', 'baboon', 'macaque', 'langur', 'blackandwhite colobus', 'proboscis monkey', 'marmoset', 'whiteheaded capuchin', 'howler monkey', 'titi monkey', 'geoffroys spider monkey', 'common squirrel monkey', 'ringtailed lemur', 'indri', 'asian elephant', 'african bush elephant', 'red panda', 'giant panda', 'snoek fish', 'eel', 'silver salmon', 'rock beauty fish', 'clownfish', 'sturgeon', 'gar fish', 'lionfish', 'pufferfish', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibious vehicle', 'analog clock', 'apiary', 'apron', 'trash can', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint pen', 'bandaid', 'banjo', 'baluster handrail', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'wheelbarrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'swimming cap', 'bath towel', 'bathtub', 'station wagon', 'lighthouse', 'beaker', 'military hat bearskin or shako', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'bikini', 'ring binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookcase', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'highspeed train', 'butcher shop', 'taxicab', 'cauldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', 'tool kit', 'cardboard box carton', 'car wheel', 'automated teller machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'cd player', 'cello', 'mobile phone', 'chain', 'chainlink fence', 'chain mail', 'chainsaw', 'storage chest', 'chiffonier', 'bell or wind chime', 'china cabinet', 'christmas stocking', 'church', 'movie theater', 'cleaver', 'cliff dwelling', 'cloak', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'construction crane', 'crash helmet', 'crate', 'infant bed', 'crock pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'rotary dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'dishwasher', 'disc brake', 'dock', 'dog sled', 'dome', 'doormat', 'drilling rig', 'drum', 'drumstick', 'dumbbell', 'dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fireboat', 'fire truck', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'fourposter bed', 'freight car', 'french horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'goblet', 'gokart', 'golf ball', 'golf cart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'radiator grille', 'grocery store', 'guillotine', 'hair clip', 'hair spray', 'halftrack', 'hammer', 'hamper', 'hair dryer', 'handheld computer', 'handkerchief', 'hard disk drive', 'harmonica', 'harp', 'combine harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoop skirt', 'gymnastic horizontal bar', 'horsedrawn vehicle', 'hourglass', 'ipod', 'clothes iron', 'carved pumpkin', 'jeans', 'jeep', 'tshirt', 'jigsaw puzzle', 'rickshaw', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'ocean liner', 'lipstick', 'slipon shoe', 'lotion', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'mailbox', 'tights', 'onepiece bathing suit', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine cabinet', 'megalith', 'microphone', 'microwave oven', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'ford model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar and pestle', 'graduation cap', 'mosque', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'mousetrap', 'moving van', 'muzzle', 'metal nail', 'neck brace', 'necklace', 'baby pacifier', 'notebook computer', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'pipe organ', 'oscilloscope', 'overskirt', 'bullock cart', 'oxygen mask', 'product packet packaging', 'paddle', 'paddle wheel', 'padlock', 'paintbrush', 'pajamas', 'palace', 'pan flute', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'patio', 'payphone', 'pedestal', 'pencil case', 'pencil sharpener', 'perfume', 'petri dish', 'photocopier', 'plectrum', 'pickelhaube', 'picket fence', 'pickup truck', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'pingpong ball', 'pinwheel', 'pirate ship', 'drink pitcher', 'block plane', 'planetarium', 'plastic bag', 'plate rack', 'farm plow', 'plunger', 'polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'soda bottle', 'plant pot', 'potters wheel', 'power drill', 'prayer rug', 'printer', 'prison', 'missile', 'projector', 'hockey puck', 'punching bag', 'purse', 'quill', 'quilt', 'race car', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safe', 'safety pin', 'salt shaker', 'sandal', 'sarong', 'saxophone', 'scabbard', 'weighing scale', 'school bus', 'schooner', 'scoreboard', 'crt monitor', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe store', 'shoji screen room divider', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar thermal collector', 'sombrero', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'spatula', 'motorboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'through arch bridge', 'steel drum', 'stethoscope', 'scarf', 'stone wall', 'stopwatch', 'stove', 'strainer', 'tram', 'stretcher', 'couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'suspension bridge', 'mop', 'sweatshirt', 'swim trunks shorts', 'swing', 'electrical switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy bear', 'television', 'tennis ball', 'thatched roof', 'front curtain', 'thimble', 'threshing machine', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toy store', 'tractor', 'semitrailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'hot tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright piano', 'vacuum cleaner', 'vase', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'hair wig', 'window screen', 'window shade', 'windsor tie', 'wine bottle', 'airplane wing', 'wok', 'wooden spoon', 'wool', 'splitrail fence', 'shipwreck', 'sailboat', 'yurt', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'popsicle', 'baguette', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'mashed potatoes', 'cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'granny smith apple', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'cherimoya custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate syrup', 'dough', 'meatloaf', 'pizza', 'pot pie', 'burrito', 'red wine', 'espresso', 'tea cup', 'eggnog', 'mountain', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeshore', 'promontory', 'sandbar', 'beach', 'valley', 'volcano', 'baseball player', 'bridegroom', 'scuba diver', 'rapeseed', 'daisy', 'yellow ladys slipper', 'corn', 'acorn', 'rose hip', 'horse chestnut seed', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'bolete', 'corn cob', 'toilet paper']
I0125 01:16:59.255623 139959958596672 dataset_info.py:566] Load dataset info from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:16:59.427663 140212821134400 api.py:459] Data after pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'labels': <tf.Tensor 'strided_slice_4:0' shape=(16,) dtype=int32>}
I0125 01:16:59.481044 139959958596672 dataset_info.py:642] Field info.description from disk and from code do not match. Keeping the one from code.
I0125 01:16:59.481418 139959958596672 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:16:59.542424 140212821134400 discriminative_classifier.py:341] Initialized evaluator in 1.7 seconds
I0125 01:16:59.546820 139959958596672 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split _EvenSplit(split='validation', index=6, count=8, drop_remainder=False), from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:16:59.549939 139959958596672 api.py:459] Data before pre-processing:
{'file_name': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'image': <tf.Tensor 'args_1:0' shape=(None, None, 3) dtype=uint8>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:16:59.741923 139959958596672 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'truediv_1:0' shape=(56, 56, 3) dtype=float32>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:00.319701 139959958596672 api.py:459] Data before pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'texts': <tf.Tensor 'args_1:0' shape=() dtype=string>}
I0125 01:17:00.675264 139959958596672 api.py:459] Data after pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'labels': <tf.Tensor 'strided_slice_4:0' shape=(16,) dtype=int32>}
I0125 01:17:00.792130 139959958596672 discriminative_classifier.py:341] Initialized evaluator in 1.7 seconds
/home/jyang347/CLIPA/clipa_jax/main.py:301: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:344: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:353: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:365: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:376: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(optim.replace_frozen(config.schedule, grads, 0.))
/home/jyang347/CLIPA/clipa_jax/main.py:378: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  ps = jax.tree_leaves(params)
/home/jyang347/CLIPA/clipa_jax/main.py:380: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  us = jax.tree_leaves(updates)
I0125 01:17:01.891776 140581069126720 utils.py:427] TIMING[z/secs/update0]: 127.513927196851
I0125 01:17:01.894662 140581069126720 prompt_engineering.py:92] Using 81 prompts_templates: ['a bad photo of a {}', 'a photo of many {}', 'a sculpture of a {}', 'a photo of the hard to see {}', 'a low resolution photo of the {}', 'a rendering of a {}', 'graffiti of a {}', 'a bad photo of the {}', 'a cropped photo of the {}', 'a tattoo of a {}', 'the embroidered {}', 'a photo of a hard to see {}', 'a bright photo of a {}', 'a photo of a clean {}', 'a photo of a dirty {}', 'a dark photo of the {}', 'a drawing of a {}', 'a photo of my {}', 'the plastic {}', 'a photo of the cool {}', 'a closeup photo of a {}', 'a black and white photo of the {}', 'a painting of the {}', 'a painting of a {}', 'a pixelated photo of the {}', 'a sculpture of the {}', 'a bright photo of the {}', 'a cropped photo of a {}', 'a plastic {}', 'a photo of the dirty {}', 'a jpeg corrupted photo of a {}', 'a blurry photo of the {}', 'a photo of the {}', 'a good photo of the {}', 'a rendering of the {}', 'a {} in a video game', 'a photo of one {}', 'a doodle of a {}', 'a closeup photo of the {}', 'a photo of a {}', 'the origami {}', 'the {} in a video game', 'a sketch of a {}', 'a doodle of the {}', 'a origami {}', 'a low resolution photo of a {}', 'the toy {}', 'a rendition of the {}', 'a photo of the clean {}', 'a photo of a large {}', 'a rendition of a {}', 'a photo of a nice {}', 'a photo of a weird {}', 'a blurry photo of a {}', 'a cartoon {}', 'art of a {}', 'a sketch of the {}', 'a embroidered {}', 'a pixelated photo of a {}', 'itap of the {}', 'a jpeg corrupted photo of the {}', 'a good photo of a {}', 'a plushie {}', 'a photo of the nice {}', 'a photo of the small {}', 'a photo of the weird {}', 'the cartoon {}', 'art of the {}', 'a drawing of the {}', 'a photo of the large {}', 'a black and white photo of a {}', 'the plushie {}', 'a dark photo of a {}', 'itap of a {}', 'graffiti of the {}', 'a toy {}', 'itap of my {}', 'a photo of a cool {}', 'a photo of a small {}', 'a tattoo of the {}', '{}']
I0125 01:17:01.898585 140581069126720 prompt_engineering.py:78] Using 1000 class_names: ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'american robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'american dipper', 'kite bird of prey', 'bald eagle', 'vulture', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'axolotl', 'american bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'green iguana', 'carolina anole', 'desert grassland whiptail lizard', 'agama', 'frillednecked lizard', 'alligator lizard', 'gila monster', 'european green lizard', 'chameleon', 'komodo dragon', 'nile crocodile', 'american alligator', 'triceratops', 'worm snake', 'ringnecked snake', 'eastern hognosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'african rock python', 'indian cobra', 'green mamba', 'sea snake', 'saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'trilobite', 'harvestman', 'scorpion', 'yellow garden spider', 'barn spider', 'european garden spider', 'southern black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie grouse', 'peafowl', 'quail', 'partridge', 'african grey parrot', 'macaw', 'sulphurcrested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'duck', 'redbreasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'american lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'limpkin', 'common gallinule', 'american coot', 'bustard', 'ruddy turnstone', 'dunlin', 'common redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'chihuahua', 'japanese chin', 'maltese', 'pekingese', 'shih tzu', 'king charles spaniel', 'papillon', 'toy terrier', 'rhodesian ridgeback', 'afghan hound', 'basset hound', 'beagle', 'bloodhound', 'bluetick coonhound', 'black and tan coonhound', 'treeing walker coonhound', 'english foxhound', 'redbone coonhound', 'borzoi', 'irish wolfhound', 'italian greyhound', 'whippet', 'ibizan hound', 'norwegian elkhound', 'otterhound', 'saluki', 'scottish deerhound', 'weimaraner', 'staffordshire bull terrier', 'american staffordshire terrier', 'bedlington terrier', 'border terrier', 'kerry blue terrier', 'irish terrier', 'norfolk terrier', 'norwich terrier', 'yorkshire terrier', 'wire fox terrier', 'lakeland terrier', 'sealyham terrier', 'airedale terrier', 'cairn terrier', 'australian terrier', 'dandie dinmont terrier', 'boston terrier', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'scottish terrier', 'tibetan terrier', 'australian silky terrier', 'softcoated wheaten terrier', 'west highland white terrier', 'lhasa apso', 'flatcoated retriever', 'curlycoated retriever', 'golden retriever', 'labrador retriever', 'chesapeake bay retriever', 'german shorthaired pointer', 'vizsla', 'english setter', 'irish setter', 'gordon setter', 'brittany dog', 'clumber spaniel', 'english springer spaniel', 'welsh springer spaniel', 'cocker spaniel', 'sussex spaniel', 'irish water spaniel', 'kuvasz', 'schipperke', 'groenendael dog', 'malinois', 'briard', 'australian kelpie', 'komondor', 'old english sheepdog', 'shetland sheepdog', 'collie', 'border collie', 'bouvier des flandres dog', 'rottweiler', 'german shepherd dog', 'dobermann', 'miniature pinscher', 'greater swiss mountain dog', 'bernese mountain dog', 'appenzeller sennenhund', 'entlebucher sennenhund', 'boxer', 'bullmastiff', 'tibetan mastiff', 'french bulldog', 'great dane', 'st bernard', 'husky', 'alaskan malamute', 'siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'leonberger', 'newfoundland dog', 'great pyrenees dog', 'samoyed', 'pomeranian', 'chow chow', 'keeshond', 'brussels griffon', 'pembroke welsh corgi', 'cardigan welsh corgi', 'toy poodle', 'miniature poodle', 'standard poodle', 'mexican hairless dog xoloitzcuintli', 'grey wolf', 'alaskan tundra wolf', 'red wolf or maned wolf', 'coyote', 'dingo', 'dhole', 'african wild dog', 'hyena', 'red fox', 'kit fox', 'arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'persian cat', 'siamese cat', 'egyptian mau', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'american black bear', 'polar bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket insect', 'stick insect', 'cockroach', 'praying mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamerwinged butterfly', 'starfish', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'hare', 'angora rabbit', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'common sorrel horse', 'zebra', 'pig', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram adult male sheep', 'bighorn sheep', 'alpine ibex', 'hartebeest', 'impala antelope', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'european polecat', 'blackfooted ferret', 'otter', 'skunk', 'badger', 'armadillo', 'threetoed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas monkey', 'baboon', 'macaque', 'langur', 'blackandwhite colobus', 'proboscis monkey', 'marmoset', 'whiteheaded capuchin', 'howler monkey', 'titi monkey', 'geoffroys spider monkey', 'common squirrel monkey', 'ringtailed lemur', 'indri', 'asian elephant', 'african bush elephant', 'red panda', 'giant panda', 'snoek fish', 'eel', 'silver salmon', 'rock beauty fish', 'clownfish', 'sturgeon', 'gar fish', 'lionfish', 'pufferfish', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibious vehicle', 'analog clock', 'apiary', 'apron', 'trash can', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint pen', 'bandaid', 'banjo', 'baluster handrail', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'wheelbarrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'swimming cap', 'bath towel', 'bathtub', 'station wagon', 'lighthouse', 'beaker', 'military hat bearskin or shako', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'bikini', 'ring binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookcase', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'highspeed train', 'butcher shop', 'taxicab', 'cauldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', 'tool kit', 'cardboard box carton', 'car wheel', 'automated teller machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'cd player', 'cello', 'mobile phone', 'chain', 'chainlink fence', 'chain mail', 'chainsaw', 'storage chest', 'chiffonier', 'bell or wind chime', 'china cabinet', 'christmas stocking', 'church', 'movie theater', 'cleaver', 'cliff dwelling', 'cloak', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'construction crane', 'crash helmet', 'crate', 'infant bed', 'crock pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'rotary dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'dishwasher', 'disc brake', 'dock', 'dog sled', 'dome', 'doormat', 'drilling rig', 'drum', 'drumstick', 'dumbbell', 'dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fireboat', 'fire truck', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'fourposter bed', 'freight car', 'french horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'goblet', 'gokart', 'golf ball', 'golf cart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'radiator grille', 'grocery store', 'guillotine', 'hair clip', 'hair spray', 'halftrack', 'hammer', 'hamper', 'hair dryer', 'handheld computer', 'handkerchief', 'hard disk drive', 'harmonica', 'harp', 'combine harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoop skirt', 'gymnastic horizontal bar', 'horsedrawn vehicle', 'hourglass', 'ipod', 'clothes iron', 'carved pumpkin', 'jeans', 'jeep', 'tshirt', 'jigsaw puzzle', 'rickshaw', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'ocean liner', 'lipstick', 'slipon shoe', 'lotion', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'mailbox', 'tights', 'onepiece bathing suit', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine cabinet', 'megalith', 'microphone', 'microwave oven', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'ford model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar and pestle', 'graduation cap', 'mosque', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'mousetrap', 'moving van', 'muzzle', 'metal nail', 'neck brace', 'necklace', 'baby pacifier', 'notebook computer', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'pipe organ', 'oscilloscope', 'overskirt', 'bullock cart', 'oxygen mask', 'product packet packaging', 'paddle', 'paddle wheel', 'padlock', 'paintbrush', 'pajamas', 'palace', 'pan flute', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'patio', 'payphone', 'pedestal', 'pencil case', 'pencil sharpener', 'perfume', 'petri dish', 'photocopier', 'plectrum', 'pickelhaube', 'picket fence', 'pickup truck', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'pingpong ball', 'pinwheel', 'pirate ship', 'drink pitcher', 'block plane', 'planetarium', 'plastic bag', 'plate rack', 'farm plow', 'plunger', 'polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'soda bottle', 'plant pot', 'potters wheel', 'power drill', 'prayer rug', 'printer', 'prison', 'missile', 'projector', 'hockey puck', 'punching bag', 'purse', 'quill', 'quilt', 'race car', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safe', 'safety pin', 'salt shaker', 'sandal', 'sarong', 'saxophone', 'scabbard', 'weighing scale', 'school bus', 'schooner', 'scoreboard', 'crt monitor', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe store', 'shoji screen room divider', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar thermal collector', 'sombrero', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'spatula', 'motorboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'through arch bridge', 'steel drum', 'stethoscope', 'scarf', 'stone wall', 'stopwatch', 'stove', 'strainer', 'tram', 'stretcher', 'couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'suspension bridge', 'mop', 'sweatshirt', 'swim trunks shorts', 'swing', 'electrical switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy bear', 'television', 'tennis ball', 'thatched roof', 'front curtain', 'thimble', 'threshing machine', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toy store', 'tractor', 'semitrailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'hot tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright piano', 'vacuum cleaner', 'vase', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'hair wig', 'window screen', 'window shade', 'windsor tie', 'wine bottle', 'airplane wing', 'wok', 'wooden spoon', 'wool', 'splitrail fence', 'shipwreck', 'sailboat', 'yurt', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'popsicle', 'baguette', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'mashed potatoes', 'cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'granny smith apple', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'cherimoya custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate syrup', 'dough', 'meatloaf', 'pizza', 'pot pie', 'burrito', 'red wine', 'espresso', 'tea cup', 'eggnog', 'mountain', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeshore', 'promontory', 'sandbar', 'beach', 'valley', 'volcano', 'baseball player', 'bridegroom', 'scuba diver', 'rapeseed', 'daisy', 'yellow ladys slipper', 'corn', 'acorn', 'rose hip', 'horse chestnut seed', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'bolete', 'corn cob', 'toilet paper']
/home/jyang347/CLIPA/clipa_jax/main.py:301: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:344: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:353: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:365: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:376: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(optim.replace_frozen(config.schedule, grads, 0.))
/home/jyang347/CLIPA/clipa_jax/main.py:378: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  ps = jax.tree_leaves(params)
/home/jyang347/CLIPA/clipa_jax/main.py:380: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  us = jax.tree_leaves(updates)
I0125 01:17:02.023373 140493899304000 utils.py:427] TIMING[z/secs/update0]: 125.3177469309885
I0125 01:17:02.026159 140493899304000 prompt_engineering.py:92] Using 81 prompts_templates: ['a bad photo of a {}', 'a photo of many {}', 'a sculpture of a {}', 'a photo of the hard to see {}', 'a low resolution photo of the {}', 'a rendering of a {}', 'graffiti of a {}', 'a bad photo of the {}', 'a cropped photo of the {}', 'a tattoo of a {}', 'the embroidered {}', 'a photo of a hard to see {}', 'a bright photo of a {}', 'a photo of a clean {}', 'a photo of a dirty {}', 'a dark photo of the {}', 'a drawing of a {}', 'a photo of my {}', 'the plastic {}', 'a photo of the cool {}', 'a closeup photo of a {}', 'a black and white photo of the {}', 'a painting of the {}', 'a painting of a {}', 'a pixelated photo of the {}', 'a sculpture of the {}', 'a bright photo of the {}', 'a cropped photo of a {}', 'a plastic {}', 'a photo of the dirty {}', 'a jpeg corrupted photo of a {}', 'a blurry photo of the {}', 'a photo of the {}', 'a good photo of the {}', 'a rendering of the {}', 'a {} in a video game', 'a photo of one {}', 'a doodle of a {}', 'a closeup photo of the {}', 'a photo of a {}', 'the origami {}', 'the {} in a video game', 'a sketch of a {}', 'a doodle of the {}', 'a origami {}', 'a low resolution photo of a {}', 'the toy {}', 'a rendition of the {}', 'a photo of the clean {}', 'a photo of a large {}', 'a rendition of a {}', 'a photo of a nice {}', 'a photo of a weird {}', 'a blurry photo of a {}', 'a cartoon {}', 'art of a {}', 'a sketch of the {}', 'a embroidered {}', 'a pixelated photo of a {}', 'itap of the {}', 'a jpeg corrupted photo of the {}', 'a good photo of a {}', 'a plushie {}', 'a photo of the nice {}', 'a photo of the small {}', 'a photo of the weird {}', 'the cartoon {}', 'art of the {}', 'a drawing of the {}', 'a photo of the large {}', 'a black and white photo of a {}', 'the plushie {}', 'a dark photo of a {}', 'itap of a {}', 'graffiti of the {}', 'a toy {}', 'itap of my {}', 'a photo of a cool {}', 'a photo of a small {}', 'a tattoo of the {}', '{}']
I0125 01:17:02.030072 140493899304000 prompt_engineering.py:78] Using 1000 class_names: ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'american robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'american dipper', 'kite bird of prey', 'bald eagle', 'vulture', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'axolotl', 'american bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'green iguana', 'carolina anole', 'desert grassland whiptail lizard', 'agama', 'frillednecked lizard', 'alligator lizard', 'gila monster', 'european green lizard', 'chameleon', 'komodo dragon', 'nile crocodile', 'american alligator', 'triceratops', 'worm snake', 'ringnecked snake', 'eastern hognosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'african rock python', 'indian cobra', 'green mamba', 'sea snake', 'saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'trilobite', 'harvestman', 'scorpion', 'yellow garden spider', 'barn spider', 'european garden spider', 'southern black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie grouse', 'peafowl', 'quail', 'partridge', 'african grey parrot', 'macaw', 'sulphurcrested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'duck', 'redbreasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'american lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'limpkin', 'common gallinule', 'american coot', 'bustard', 'ruddy turnstone', 'dunlin', 'common redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'chihuahua', 'japanese chin', 'maltese', 'pekingese', 'shih tzu', 'king charles spaniel', 'papillon', 'toy terrier', 'rhodesian ridgeback', 'afghan hound', 'basset hound', 'beagle', 'bloodhound', 'bluetick coonhound', 'black and tan coonhound', 'treeing walker coonhound', 'english foxhound', 'redbone coonhound', 'borzoi', 'irish wolfhound', 'italian greyhound', 'whippet', 'ibizan hound', 'norwegian elkhound', 'otterhound', 'saluki', 'scottish deerhound', 'weimaraner', 'staffordshire bull terrier', 'american staffordshire terrier', 'bedlington terrier', 'border terrier', 'kerry blue terrier', 'irish terrier', 'norfolk terrier', 'norwich terrier', 'yorkshire terrier', 'wire fox terrier', 'lakeland terrier', 'sealyham terrier', 'airedale terrier', 'cairn terrier', 'australian terrier', 'dandie dinmont terrier', 'boston terrier', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'scottish terrier', 'tibetan terrier', 'australian silky terrier', 'softcoated wheaten terrier', 'west highland white terrier', 'lhasa apso', 'flatcoated retriever', 'curlycoated retriever', 'golden retriever', 'labrador retriever', 'chesapeake bay retriever', 'german shorthaired pointer', 'vizsla', 'english setter', 'irish setter', 'gordon setter', 'brittany dog', 'clumber spaniel', 'english springer spaniel', 'welsh springer spaniel', 'cocker spaniel', 'sussex spaniel', 'irish water spaniel', 'kuvasz', 'schipperke', 'groenendael dog', 'malinois', 'briard', 'australian kelpie', 'komondor', 'old english sheepdog', 'shetland sheepdog', 'collie', 'border collie', 'bouvier des flandres dog', 'rottweiler', 'german shepherd dog', 'dobermann', 'miniature pinscher', 'greater swiss mountain dog', 'bernese mountain dog', 'appenzeller sennenhund', 'entlebucher sennenhund', 'boxer', 'bullmastiff', 'tibetan mastiff', 'french bulldog', 'great dane', 'st bernard', 'husky', 'alaskan malamute', 'siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'leonberger', 'newfoundland dog', 'great pyrenees dog', 'samoyed', 'pomeranian', 'chow chow', 'keeshond', 'brussels griffon', 'pembroke welsh corgi', 'cardigan welsh corgi', 'toy poodle', 'miniature poodle', 'standard poodle', 'mexican hairless dog xoloitzcuintli', 'grey wolf', 'alaskan tundra wolf', 'red wolf or maned wolf', 'coyote', 'dingo', 'dhole', 'african wild dog', 'hyena', 'red fox', 'kit fox', 'arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'persian cat', 'siamese cat', 'egyptian mau', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'american black bear', 'polar bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket insect', 'stick insect', 'cockroach', 'praying mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamerwinged butterfly', 'starfish', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'hare', 'angora rabbit', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'common sorrel horse', 'zebra', 'pig', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram adult male sheep', 'bighorn sheep', 'alpine ibex', 'hartebeest', 'impala antelope', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'european polecat', 'blackfooted ferret', 'otter', 'skunk', 'badger', 'armadillo', 'threetoed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas monkey', 'baboon', 'macaque', 'langur', 'blackandwhite colobus', 'proboscis monkey', 'marmoset', 'whiteheaded capuchin', 'howler monkey', 'titi monkey', 'geoffroys spider monkey', 'common squirrel monkey', 'ringtailed lemur', 'indri', 'asian elephant', 'african bush elephant', 'red panda', 'giant panda', 'snoek fish', 'eel', 'silver salmon', 'rock beauty fish', 'clownfish', 'sturgeon', 'gar fish', 'lionfish', 'pufferfish', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibious vehicle', 'analog clock', 'apiary', 'apron', 'trash can', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint pen', 'bandaid', 'banjo', 'baluster handrail', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'wheelbarrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'swimming cap', 'bath towel', 'bathtub', 'station wagon', 'lighthouse', 'beaker', 'military hat bearskin or shako', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'bikini', 'ring binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookcase', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'highspeed train', 'butcher shop', 'taxicab', 'cauldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', 'tool kit', 'cardboard box carton', 'car wheel', 'automated teller machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'cd player', 'cello', 'mobile phone', 'chain', 'chainlink fence', 'chain mail', 'chainsaw', 'storage chest', 'chiffonier', 'bell or wind chime', 'china cabinet', 'christmas stocking', 'church', 'movie theater', 'cleaver', 'cliff dwelling', 'cloak', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'construction crane', 'crash helmet', 'crate', 'infant bed', 'crock pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'rotary dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'dishwasher', 'disc brake', 'dock', 'dog sled', 'dome', 'doormat', 'drilling rig', 'drum', 'drumstick', 'dumbbell', 'dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fireboat', 'fire truck', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'fourposter bed', 'freight car', 'french horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'goblet', 'gokart', 'golf ball', 'golf cart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'radiator grille', 'grocery store', 'guillotine', 'hair clip', 'hair spray', 'halftrack', 'hammer', 'hamper', 'hair dryer', 'handheld computer', 'handkerchief', 'hard disk drive', 'harmonica', 'harp', 'combine harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoop skirt', 'gymnastic horizontal bar', 'horsedrawn vehicle', 'hourglass', 'ipod', 'clothes iron', 'carved pumpkin', 'jeans', 'jeep', 'tshirt', 'jigsaw puzzle', 'rickshaw', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'ocean liner', 'lipstick', 'slipon shoe', 'lotion', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'mailbox', 'tights', 'onepiece bathing suit', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine cabinet', 'megalith', 'microphone', 'microwave oven', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'ford model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar and pestle', 'graduation cap', 'mosque', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'mousetrap', 'moving van', 'muzzle', 'metal nail', 'neck brace', 'necklace', 'baby pacifier', 'notebook computer', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'pipe organ', 'oscilloscope', 'overskirt', 'bullock cart', 'oxygen mask', 'product packet packaging', 'paddle', 'paddle wheel', 'padlock', 'paintbrush', 'pajamas', 'palace', 'pan flute', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'patio', 'payphone', 'pedestal', 'pencil case', 'pencil sharpener', 'perfume', 'petri dish', 'photocopier', 'plectrum', 'pickelhaube', 'picket fence', 'pickup truck', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'pingpong ball', 'pinwheel', 'pirate ship', 'drink pitcher', 'block plane', 'planetarium', 'plastic bag', 'plate rack', 'farm plow', 'plunger', 'polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'soda bottle', 'plant pot', 'potters wheel', 'power drill', 'prayer rug', 'printer', 'prison', 'missile', 'projector', 'hockey puck', 'punching bag', 'purse', 'quill', 'quilt', 'race car', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safe', 'safety pin', 'salt shaker', 'sandal', 'sarong', 'saxophone', 'scabbard', 'weighing scale', 'school bus', 'schooner', 'scoreboard', 'crt monitor', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe store', 'shoji screen room divider', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar thermal collector', 'sombrero', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'spatula', 'motorboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'through arch bridge', 'steel drum', 'stethoscope', 'scarf', 'stone wall', 'stopwatch', 'stove', 'strainer', 'tram', 'stretcher', 'couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'suspension bridge', 'mop', 'sweatshirt', 'swim trunks shorts', 'swing', 'electrical switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy bear', 'television', 'tennis ball', 'thatched roof', 'front curtain', 'thimble', 'threshing machine', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toy store', 'tractor', 'semitrailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'hot tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright piano', 'vacuum cleaner', 'vase', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'hair wig', 'window screen', 'window shade', 'windsor tie', 'wine bottle', 'airplane wing', 'wok', 'wooden spoon', 'wool', 'splitrail fence', 'shipwreck', 'sailboat', 'yurt', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'popsicle', 'baguette', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'mashed potatoes', 'cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'granny smith apple', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'cherimoya custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate syrup', 'dough', 'meatloaf', 'pizza', 'pot pie', 'burrito', 'red wine', 'espresso', 'tea cup', 'eggnog', 'mountain', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeshore', 'promontory', 'sandbar', 'beach', 'valley', 'volcano', 'baseball player', 'bridegroom', 'scuba diver', 'rapeseed', 'daisy', 'yellow ladys slipper', 'corn', 'acorn', 'rose hip', 'horse chestnut seed', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'bolete', 'corn cob', 'toilet paper']
I0125 01:17:02.035515 140581069126720 dataset_info.py:566] Load dataset info from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
/home/jyang347/CLIPA/clipa_jax/main.py:301: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:344: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:353: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:365: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:376: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(optim.replace_frozen(config.schedule, grads, 0.))
/home/jyang347/CLIPA/clipa_jax/main.py:378: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  ps = jax.tree_leaves(params)
/home/jyang347/CLIPA/clipa_jax/main.py:380: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  us = jax.tree_leaves(updates)
I0125 01:17:02.161544 139956134382656 utils.py:427] TIMING[z/secs/update0]: 126.90820232313126
I0125 01:17:02.164364 139956134382656 prompt_engineering.py:92] Using 81 prompts_templates: ['a bad photo of a {}', 'a photo of many {}', 'a sculpture of a {}', 'a photo of the hard to see {}', 'a low resolution photo of the {}', 'a rendering of a {}', 'graffiti of a {}', 'a bad photo of the {}', 'a cropped photo of the {}', 'a tattoo of a {}', 'the embroidered {}', 'a photo of a hard to see {}', 'a bright photo of a {}', 'a photo of a clean {}', 'a photo of a dirty {}', 'a dark photo of the {}', 'a drawing of a {}', 'a photo of my {}', 'the plastic {}', 'a photo of the cool {}', 'a closeup photo of a {}', 'a black and white photo of the {}', 'a painting of the {}', 'a painting of a {}', 'a pixelated photo of the {}', 'a sculpture of the {}', 'a bright photo of the {}', 'a cropped photo of a {}', 'a plastic {}', 'a photo of the dirty {}', 'a jpeg corrupted photo of a {}', 'a blurry photo of the {}', 'a photo of the {}', 'a good photo of the {}', 'a rendering of the {}', 'a {} in a video game', 'a photo of one {}', 'a doodle of a {}', 'a closeup photo of the {}', 'a photo of a {}', 'the origami {}', 'the {} in a video game', 'a sketch of a {}', 'a doodle of the {}', 'a origami {}', 'a low resolution photo of a {}', 'the toy {}', 'a rendition of the {}', 'a photo of the clean {}', 'a photo of a large {}', 'a rendition of a {}', 'a photo of a nice {}', 'a photo of a weird {}', 'a blurry photo of a {}', 'a cartoon {}', 'art of a {}', 'a sketch of the {}', 'a embroidered {}', 'a pixelated photo of a {}', 'itap of the {}', 'a jpeg corrupted photo of the {}', 'a good photo of a {}', 'a plushie {}', 'a photo of the nice {}', 'a photo of the small {}', 'a photo of the weird {}', 'the cartoon {}', 'art of the {}', 'a drawing of the {}', 'a photo of the large {}', 'a black and white photo of a {}', 'the plushie {}', 'a dark photo of a {}', 'itap of a {}', 'graffiti of the {}', 'a toy {}', 'itap of my {}', 'a photo of a cool {}', 'a photo of a small {}', 'a tattoo of the {}', '{}']
I0125 01:17:02.165969 140493899304000 dataset_info.py:566] Load dataset info from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:02.168386 139956134382656 prompt_engineering.py:78] Using 1000 class_names: ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'american robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'american dipper', 'kite bird of prey', 'bald eagle', 'vulture', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'axolotl', 'american bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'green iguana', 'carolina anole', 'desert grassland whiptail lizard', 'agama', 'frillednecked lizard', 'alligator lizard', 'gila monster', 'european green lizard', 'chameleon', 'komodo dragon', 'nile crocodile', 'american alligator', 'triceratops', 'worm snake', 'ringnecked snake', 'eastern hognosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'african rock python', 'indian cobra', 'green mamba', 'sea snake', 'saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'trilobite', 'harvestman', 'scorpion', 'yellow garden spider', 'barn spider', 'european garden spider', 'southern black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie grouse', 'peafowl', 'quail', 'partridge', 'african grey parrot', 'macaw', 'sulphurcrested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'duck', 'redbreasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'american lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'limpkin', 'common gallinule', 'american coot', 'bustard', 'ruddy turnstone', 'dunlin', 'common redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'chihuahua', 'japanese chin', 'maltese', 'pekingese', 'shih tzu', 'king charles spaniel', 'papillon', 'toy terrier', 'rhodesian ridgeback', 'afghan hound', 'basset hound', 'beagle', 'bloodhound', 'bluetick coonhound', 'black and tan coonhound', 'treeing walker coonhound', 'english foxhound', 'redbone coonhound', 'borzoi', 'irish wolfhound', 'italian greyhound', 'whippet', 'ibizan hound', 'norwegian elkhound', 'otterhound', 'saluki', 'scottish deerhound', 'weimaraner', 'staffordshire bull terrier', 'american staffordshire terrier', 'bedlington terrier', 'border terrier', 'kerry blue terrier', 'irish terrier', 'norfolk terrier', 'norwich terrier', 'yorkshire terrier', 'wire fox terrier', 'lakeland terrier', 'sealyham terrier', 'airedale terrier', 'cairn terrier', 'australian terrier', 'dandie dinmont terrier', 'boston terrier', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'scottish terrier', 'tibetan terrier', 'australian silky terrier', 'softcoated wheaten terrier', 'west highland white terrier', 'lhasa apso', 'flatcoated retriever', 'curlycoated retriever', 'golden retriever', 'labrador retriever', 'chesapeake bay retriever', 'german shorthaired pointer', 'vizsla', 'english setter', 'irish setter', 'gordon setter', 'brittany dog', 'clumber spaniel', 'english springer spaniel', 'welsh springer spaniel', 'cocker spaniel', 'sussex spaniel', 'irish water spaniel', 'kuvasz', 'schipperke', 'groenendael dog', 'malinois', 'briard', 'australian kelpie', 'komondor', 'old english sheepdog', 'shetland sheepdog', 'collie', 'border collie', 'bouvier des flandres dog', 'rottweiler', 'german shepherd dog', 'dobermann', 'miniature pinscher', 'greater swiss mountain dog', 'bernese mountain dog', 'appenzeller sennenhund', 'entlebucher sennenhund', 'boxer', 'bullmastiff', 'tibetan mastiff', 'french bulldog', 'great dane', 'st bernard', 'husky', 'alaskan malamute', 'siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'leonberger', 'newfoundland dog', 'great pyrenees dog', 'samoyed', 'pomeranian', 'chow chow', 'keeshond', 'brussels griffon', 'pembroke welsh corgi', 'cardigan welsh corgi', 'toy poodle', 'miniature poodle', 'standard poodle', 'mexican hairless dog xoloitzcuintli', 'grey wolf', 'alaskan tundra wolf', 'red wolf or maned wolf', 'coyote', 'dingo', 'dhole', 'african wild dog', 'hyena', 'red fox', 'kit fox', 'arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'persian cat', 'siamese cat', 'egyptian mau', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'american black bear', 'polar bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket insect', 'stick insect', 'cockroach', 'praying mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamerwinged butterfly', 'starfish', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'hare', 'angora rabbit', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'common sorrel horse', 'zebra', 'pig', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram adult male sheep', 'bighorn sheep', 'alpine ibex', 'hartebeest', 'impala antelope', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'european polecat', 'blackfooted ferret', 'otter', 'skunk', 'badger', 'armadillo', 'threetoed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas monkey', 'baboon', 'macaque', 'langur', 'blackandwhite colobus', 'proboscis monkey', 'marmoset', 'whiteheaded capuchin', 'howler monkey', 'titi monkey', 'geoffroys spider monkey', 'common squirrel monkey', 'ringtailed lemur', 'indri', 'asian elephant', 'african bush elephant', 'red panda', 'giant panda', 'snoek fish', 'eel', 'silver salmon', 'rock beauty fish', 'clownfish', 'sturgeon', 'gar fish', 'lionfish', 'pufferfish', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibious vehicle', 'analog clock', 'apiary', 'apron', 'trash can', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint pen', 'bandaid', 'banjo', 'baluster handrail', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'wheelbarrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'swimming cap', 'bath towel', 'bathtub', 'station wagon', 'lighthouse', 'beaker', 'military hat bearskin or shako', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'bikini', 'ring binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookcase', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'highspeed train', 'butcher shop', 'taxicab', 'cauldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', 'tool kit', 'cardboard box carton', 'car wheel', 'automated teller machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'cd player', 'cello', 'mobile phone', 'chain', 'chainlink fence', 'chain mail', 'chainsaw', 'storage chest', 'chiffonier', 'bell or wind chime', 'china cabinet', 'christmas stocking', 'church', 'movie theater', 'cleaver', 'cliff dwelling', 'cloak', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'construction crane', 'crash helmet', 'crate', 'infant bed', 'crock pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'rotary dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'dishwasher', 'disc brake', 'dock', 'dog sled', 'dome', 'doormat', 'drilling rig', 'drum', 'drumstick', 'dumbbell', 'dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fireboat', 'fire truck', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'fourposter bed', 'freight car', 'french horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'goblet', 'gokart', 'golf ball', 'golf cart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'radiator grille', 'grocery store', 'guillotine', 'hair clip', 'hair spray', 'halftrack', 'hammer', 'hamper', 'hair dryer', 'handheld computer', 'handkerchief', 'hard disk drive', 'harmonica', 'harp', 'combine harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoop skirt', 'gymnastic horizontal bar', 'horsedrawn vehicle', 'hourglass', 'ipod', 'clothes iron', 'carved pumpkin', 'jeans', 'jeep', 'tshirt', 'jigsaw puzzle', 'rickshaw', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'ocean liner', 'lipstick', 'slipon shoe', 'lotion', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'mailbox', 'tights', 'onepiece bathing suit', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine cabinet', 'megalith', 'microphone', 'microwave oven', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'ford model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar and pestle', 'graduation cap', 'mosque', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'mousetrap', 'moving van', 'muzzle', 'metal nail', 'neck brace', 'necklace', 'baby pacifier', 'notebook computer', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'pipe organ', 'oscilloscope', 'overskirt', 'bullock cart', 'oxygen mask', 'product packet packaging', 'paddle', 'paddle wheel', 'padlock', 'paintbrush', 'pajamas', 'palace', 'pan flute', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'patio', 'payphone', 'pedestal', 'pencil case', 'pencil sharpener', 'perfume', 'petri dish', 'photocopier', 'plectrum', 'pickelhaube', 'picket fence', 'pickup truck', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'pingpong ball', 'pinwheel', 'pirate ship', 'drink pitcher', 'block plane', 'planetarium', 'plastic bag', 'plate rack', 'farm plow', 'plunger', 'polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'soda bottle', 'plant pot', 'potters wheel', 'power drill', 'prayer rug', 'printer', 'prison', 'missile', 'projector', 'hockey puck', 'punching bag', 'purse', 'quill', 'quilt', 'race car', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safe', 'safety pin', 'salt shaker', 'sandal', 'sarong', 'saxophone', 'scabbard', 'weighing scale', 'school bus', 'schooner', 'scoreboard', 'crt monitor', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe store', 'shoji screen room divider', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar thermal collector', 'sombrero', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'spatula', 'motorboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'through arch bridge', 'steel drum', 'stethoscope', 'scarf', 'stone wall', 'stopwatch', 'stove', 'strainer', 'tram', 'stretcher', 'couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'suspension bridge', 'mop', 'sweatshirt', 'swim trunks shorts', 'swing', 'electrical switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy bear', 'television', 'tennis ball', 'thatched roof', 'front curtain', 'thimble', 'threshing machine', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toy store', 'tractor', 'semitrailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'hot tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright piano', 'vacuum cleaner', 'vase', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'hair wig', 'window screen', 'window shade', 'windsor tie', 'wine bottle', 'airplane wing', 'wok', 'wooden spoon', 'wool', 'splitrail fence', 'shipwreck', 'sailboat', 'yurt', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'popsicle', 'baguette', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'mashed potatoes', 'cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'granny smith apple', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'cherimoya custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate syrup', 'dough', 'meatloaf', 'pizza', 'pot pie', 'burrito', 'red wine', 'espresso', 'tea cup', 'eggnog', 'mountain', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeshore', 'promontory', 'sandbar', 'beach', 'valley', 'volcano', 'baseball player', 'bridegroom', 'scuba diver', 'rapeseed', 'daisy', 'yellow ladys slipper', 'corn', 'acorn', 'rose hip', 'horse chestnut seed', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'bolete', 'corn cob', 'toilet paper']
I0125 01:17:02.253830 140581069126720 dataset_info.py:642] Field info.description from disk and from code do not match. Keeping the one from code.
I0125 01:17:02.254232 140581069126720 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
/home/jyang347/CLIPA/clipa_jax/main.py:301: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:344: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:353: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:365: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:376: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(optim.replace_frozen(config.schedule, grads, 0.))
/home/jyang347/CLIPA/clipa_jax/main.py:378: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  ps = jax.tree_leaves(params)
/home/jyang347/CLIPA/clipa_jax/main.py:380: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  us = jax.tree_leaves(updates)
I0125 01:17:02.319408 139866951023680 utils.py:427] TIMING[z/secs/update0]: 128.22362600220367
I0125 01:17:02.320445 139956134382656 dataset_info.py:566] Load dataset info from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:02.320777 140581069126720 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split _EvenSplit(split='validation', index=7, count=8, drop_remainder=False), from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:02.322034 139866951023680 prompt_engineering.py:92] Using 81 prompts_templates: ['a bad photo of a {}', 'a photo of many {}', 'a sculpture of a {}', 'a photo of the hard to see {}', 'a low resolution photo of the {}', 'a rendering of a {}', 'graffiti of a {}', 'a bad photo of the {}', 'a cropped photo of the {}', 'a tattoo of a {}', 'the embroidered {}', 'a photo of a hard to see {}', 'a bright photo of a {}', 'a photo of a clean {}', 'a photo of a dirty {}', 'a dark photo of the {}', 'a drawing of a {}', 'a photo of my {}', 'the plastic {}', 'a photo of the cool {}', 'a closeup photo of a {}', 'a black and white photo of the {}', 'a painting of the {}', 'a painting of a {}', 'a pixelated photo of the {}', 'a sculpture of the {}', 'a bright photo of the {}', 'a cropped photo of a {}', 'a plastic {}', 'a photo of the dirty {}', 'a jpeg corrupted photo of a {}', 'a blurry photo of the {}', 'a photo of the {}', 'a good photo of the {}', 'a rendering of the {}', 'a {} in a video game', 'a photo of one {}', 'a doodle of a {}', 'a closeup photo of the {}', 'a photo of a {}', 'the origami {}', 'the {} in a video game', 'a sketch of a {}', 'a doodle of the {}', 'a origami {}', 'a low resolution photo of a {}', 'the toy {}', 'a rendition of the {}', 'a photo of the clean {}', 'a photo of a large {}', 'a rendition of a {}', 'a photo of a nice {}', 'a photo of a weird {}', 'a blurry photo of a {}', 'a cartoon {}', 'art of a {}', 'a sketch of the {}', 'a embroidered {}', 'a pixelated photo of a {}', 'itap of the {}', 'a jpeg corrupted photo of the {}', 'a good photo of a {}', 'a plushie {}', 'a photo of the nice {}', 'a photo of the small {}', 'a photo of the weird {}', 'the cartoon {}', 'art of the {}', 'a drawing of the {}', 'a photo of the large {}', 'a black and white photo of a {}', 'the plushie {}', 'a dark photo of a {}', 'itap of a {}', 'graffiti of the {}', 'a toy {}', 'itap of my {}', 'a photo of a cool {}', 'a photo of a small {}', 'a tattoo of the {}', '{}']
I0125 01:17:02.324261 140581069126720 api.py:459] Data before pre-processing:
{'file_name': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'image': <tf.Tensor 'args_1:0' shape=(None, None, 3) dtype=uint8>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:02.326342 139866951023680 prompt_engineering.py:78] Using 1000 class_names: ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'american robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'american dipper', 'kite bird of prey', 'bald eagle', 'vulture', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'axolotl', 'american bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'green iguana', 'carolina anole', 'desert grassland whiptail lizard', 'agama', 'frillednecked lizard', 'alligator lizard', 'gila monster', 'european green lizard', 'chameleon', 'komodo dragon', 'nile crocodile', 'american alligator', 'triceratops', 'worm snake', 'ringnecked snake', 'eastern hognosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'african rock python', 'indian cobra', 'green mamba', 'sea snake', 'saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'trilobite', 'harvestman', 'scorpion', 'yellow garden spider', 'barn spider', 'european garden spider', 'southern black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie grouse', 'peafowl', 'quail', 'partridge', 'african grey parrot', 'macaw', 'sulphurcrested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'duck', 'redbreasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'american lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'limpkin', 'common gallinule', 'american coot', 'bustard', 'ruddy turnstone', 'dunlin', 'common redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'chihuahua', 'japanese chin', 'maltese', 'pekingese', 'shih tzu', 'king charles spaniel', 'papillon', 'toy terrier', 'rhodesian ridgeback', 'afghan hound', 'basset hound', 'beagle', 'bloodhound', 'bluetick coonhound', 'black and tan coonhound', 'treeing walker coonhound', 'english foxhound', 'redbone coonhound', 'borzoi', 'irish wolfhound', 'italian greyhound', 'whippet', 'ibizan hound', 'norwegian elkhound', 'otterhound', 'saluki', 'scottish deerhound', 'weimaraner', 'staffordshire bull terrier', 'american staffordshire terrier', 'bedlington terrier', 'border terrier', 'kerry blue terrier', 'irish terrier', 'norfolk terrier', 'norwich terrier', 'yorkshire terrier', 'wire fox terrier', 'lakeland terrier', 'sealyham terrier', 'airedale terrier', 'cairn terrier', 'australian terrier', 'dandie dinmont terrier', 'boston terrier', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'scottish terrier', 'tibetan terrier', 'australian silky terrier', 'softcoated wheaten terrier', 'west highland white terrier', 'lhasa apso', 'flatcoated retriever', 'curlycoated retriever', 'golden retriever', 'labrador retriever', 'chesapeake bay retriever', 'german shorthaired pointer', 'vizsla', 'english setter', 'irish setter', 'gordon setter', 'brittany dog', 'clumber spaniel', 'english springer spaniel', 'welsh springer spaniel', 'cocker spaniel', 'sussex spaniel', 'irish water spaniel', 'kuvasz', 'schipperke', 'groenendael dog', 'malinois', 'briard', 'australian kelpie', 'komondor', 'old english sheepdog', 'shetland sheepdog', 'collie', 'border collie', 'bouvier des flandres dog', 'rottweiler', 'german shepherd dog', 'dobermann', 'miniature pinscher', 'greater swiss mountain dog', 'bernese mountain dog', 'appenzeller sennenhund', 'entlebucher sennenhund', 'boxer', 'bullmastiff', 'tibetan mastiff', 'french bulldog', 'great dane', 'st bernard', 'husky', 'alaskan malamute', 'siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'leonberger', 'newfoundland dog', 'great pyrenees dog', 'samoyed', 'pomeranian', 'chow chow', 'keeshond', 'brussels griffon', 'pembroke welsh corgi', 'cardigan welsh corgi', 'toy poodle', 'miniature poodle', 'standard poodle', 'mexican hairless dog xoloitzcuintli', 'grey wolf', 'alaskan tundra wolf', 'red wolf or maned wolf', 'coyote', 'dingo', 'dhole', 'african wild dog', 'hyena', 'red fox', 'kit fox', 'arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'persian cat', 'siamese cat', 'egyptian mau', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'american black bear', 'polar bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket insect', 'stick insect', 'cockroach', 'praying mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamerwinged butterfly', 'starfish', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'hare', 'angora rabbit', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'common sorrel horse', 'zebra', 'pig', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram adult male sheep', 'bighorn sheep', 'alpine ibex', 'hartebeest', 'impala antelope', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'european polecat', 'blackfooted ferret', 'otter', 'skunk', 'badger', 'armadillo', 'threetoed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas monkey', 'baboon', 'macaque', 'langur', 'blackandwhite colobus', 'proboscis monkey', 'marmoset', 'whiteheaded capuchin', 'howler monkey', 'titi monkey', 'geoffroys spider monkey', 'common squirrel monkey', 'ringtailed lemur', 'indri', 'asian elephant', 'african bush elephant', 'red panda', 'giant panda', 'snoek fish', 'eel', 'silver salmon', 'rock beauty fish', 'clownfish', 'sturgeon', 'gar fish', 'lionfish', 'pufferfish', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibious vehicle', 'analog clock', 'apiary', 'apron', 'trash can', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint pen', 'bandaid', 'banjo', 'baluster handrail', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'wheelbarrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'swimming cap', 'bath towel', 'bathtub', 'station wagon', 'lighthouse', 'beaker', 'military hat bearskin or shako', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'bikini', 'ring binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookcase', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'highspeed train', 'butcher shop', 'taxicab', 'cauldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', 'tool kit', 'cardboard box carton', 'car wheel', 'automated teller machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'cd player', 'cello', 'mobile phone', 'chain', 'chainlink fence', 'chain mail', 'chainsaw', 'storage chest', 'chiffonier', 'bell or wind chime', 'china cabinet', 'christmas stocking', 'church', 'movie theater', 'cleaver', 'cliff dwelling', 'cloak', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'construction crane', 'crash helmet', 'crate', 'infant bed', 'crock pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'rotary dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'dishwasher', 'disc brake', 'dock', 'dog sled', 'dome', 'doormat', 'drilling rig', 'drum', 'drumstick', 'dumbbell', 'dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fireboat', 'fire truck', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'fourposter bed', 'freight car', 'french horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'goblet', 'gokart', 'golf ball', 'golf cart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'radiator grille', 'grocery store', 'guillotine', 'hair clip', 'hair spray', 'halftrack', 'hammer', 'hamper', 'hair dryer', 'handheld computer', 'handkerchief', 'hard disk drive', 'harmonica', 'harp', 'combine harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoop skirt', 'gymnastic horizontal bar', 'horsedrawn vehicle', 'hourglass', 'ipod', 'clothes iron', 'carved pumpkin', 'jeans', 'jeep', 'tshirt', 'jigsaw puzzle', 'rickshaw', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'ocean liner', 'lipstick', 'slipon shoe', 'lotion', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'mailbox', 'tights', 'onepiece bathing suit', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine cabinet', 'megalith', 'microphone', 'microwave oven', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'ford model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar and pestle', 'graduation cap', 'mosque', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'mousetrap', 'moving van', 'muzzle', 'metal nail', 'neck brace', 'necklace', 'baby pacifier', 'notebook computer', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'pipe organ', 'oscilloscope', 'overskirt', 'bullock cart', 'oxygen mask', 'product packet packaging', 'paddle', 'paddle wheel', 'padlock', 'paintbrush', 'pajamas', 'palace', 'pan flute', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'patio', 'payphone', 'pedestal', 'pencil case', 'pencil sharpener', 'perfume', 'petri dish', 'photocopier', 'plectrum', 'pickelhaube', 'picket fence', 'pickup truck', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'pingpong ball', 'pinwheel', 'pirate ship', 'drink pitcher', 'block plane', 'planetarium', 'plastic bag', 'plate rack', 'farm plow', 'plunger', 'polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'soda bottle', 'plant pot', 'potters wheel', 'power drill', 'prayer rug', 'printer', 'prison', 'missile', 'projector', 'hockey puck', 'punching bag', 'purse', 'quill', 'quilt', 'race car', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safe', 'safety pin', 'salt shaker', 'sandal', 'sarong', 'saxophone', 'scabbard', 'weighing scale', 'school bus', 'schooner', 'scoreboard', 'crt monitor', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe store', 'shoji screen room divider', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar thermal collector', 'sombrero', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'spatula', 'motorboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'through arch bridge', 'steel drum', 'stethoscope', 'scarf', 'stone wall', 'stopwatch', 'stove', 'strainer', 'tram', 'stretcher', 'couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'suspension bridge', 'mop', 'sweatshirt', 'swim trunks shorts', 'swing', 'electrical switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy bear', 'television', 'tennis ball', 'thatched roof', 'front curtain', 'thimble', 'threshing machine', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toy store', 'tractor', 'semitrailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'hot tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright piano', 'vacuum cleaner', 'vase', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'hair wig', 'window screen', 'window shade', 'windsor tie', 'wine bottle', 'airplane wing', 'wok', 'wooden spoon', 'wool', 'splitrail fence', 'shipwreck', 'sailboat', 'yurt', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'popsicle', 'baguette', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'mashed potatoes', 'cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'granny smith apple', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'cherimoya custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate syrup', 'dough', 'meatloaf', 'pizza', 'pot pie', 'burrito', 'red wine', 'espresso', 'tea cup', 'eggnog', 'mountain', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeshore', 'promontory', 'sandbar', 'beach', 'valley', 'volcano', 'baseball player', 'bridegroom', 'scuba diver', 'rapeseed', 'daisy', 'yellow ladys slipper', 'corn', 'acorn', 'rose hip', 'horse chestnut seed', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'bolete', 'corn cob', 'toilet paper']
I0125 01:17:02.386496 140493899304000 dataset_info.py:642] Field info.description from disk and from code do not match. Keeping the one from code.
I0125 01:17:02.386873 140493899304000 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:17:02.459292 140493899304000 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split _EvenSplit(split='validation', index=2, count=8, drop_remainder=False), from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:02.460538 139866951023680 dataset_info.py:566] Load dataset info from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:02.462909 140493899304000 api.py:459] Data before pre-processing:
{'file_name': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'image': <tf.Tensor 'args_1:0' shape=(None, None, 3) dtype=uint8>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:02.523297 140581069126720 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'truediv_1:0' shape=(56, 56, 3) dtype=float32>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:02.534675 139956134382656 dataset_info.py:642] Field info.description from disk and from code do not match. Keeping the one from code.
I0125 01:17:02.535065 139956134382656 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:17:02.604836 139956134382656 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split _EvenSplit(split='validation', index=3, count=8, drop_remainder=False), from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:02.607986 139956134382656 api.py:459] Data before pre-processing:
{'file_name': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'image': <tf.Tensor 'args_1:0' shape=(None, None, 3) dtype=uint8>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:02.660237 140493899304000 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'truediv_1:0' shape=(56, 56, 3) dtype=float32>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:02.695411 139866951023680 dataset_info.py:642] Field info.description from disk and from code do not match. Keeping the one from code.
I0125 01:17:02.695824 139866951023680 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:17:02.761218 139866951023680 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split _EvenSplit(split='validation', index=5, count=8, drop_remainder=False), from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:02.764636 139866951023680 api.py:459] Data before pre-processing:
{'file_name': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'image': <tf.Tensor 'args_1:0' shape=(None, None, 3) dtype=uint8>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:02.808562 139956134382656 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'truediv_1:0' shape=(56, 56, 3) dtype=float32>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:02.966892 139866951023680 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'truediv_1:0' shape=(56, 56, 3) dtype=float32>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:03.055437 140581069126720 api.py:459] Data before pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'texts': <tf.Tensor 'args_1:0' shape=() dtype=string>}
I0125 01:17:03.186611 140493899304000 api.py:459] Data before pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'texts': <tf.Tensor 'args_1:0' shape=() dtype=string>}
I0125 01:17:03.393078 139956134382656 api.py:459] Data before pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'texts': <tf.Tensor 'args_1:0' shape=() dtype=string>}
I0125 01:17:03.415295 140581069126720 api.py:459] Data after pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'labels': <tf.Tensor 'strided_slice_4:0' shape=(16,) dtype=int32>}
I0125 01:17:03.511087 139866951023680 api.py:459] Data before pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'texts': <tf.Tensor 'args_1:0' shape=() dtype=string>}
I0125 01:17:03.534393 140581069126720 discriminative_classifier.py:341] Initialized evaluator in 1.6 seconds
I0125 01:17:03.551955 140493899304000 api.py:459] Data after pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'labels': <tf.Tensor 'strided_slice_4:0' shape=(16,) dtype=int32>}
I0125 01:17:03.669222 140493899304000 discriminative_classifier.py:341] Initialized evaluator in 1.6 seconds
I0125 01:17:03.758687 139956134382656 api.py:459] Data after pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'labels': <tf.Tensor 'strided_slice_4:0' shape=(16,) dtype=int32>}
I0125 01:17:03.871033 139866951023680 api.py:459] Data after pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'labels': <tf.Tensor 'strided_slice_4:0' shape=(16,) dtype=int32>}
I0125 01:17:03.883652 139956134382656 discriminative_classifier.py:341] Initialized evaluator in 1.7 seconds
I0125 01:17:03.994983 139866951023680 discriminative_classifier.py:341] Initialized evaluator in 1.7 seconds
/home/jyang347/CLIPA/clipa_jax/main.py:301: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:344: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:353: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:365: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(
/home/jyang347/CLIPA/clipa_jax/main.py:376: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  gs = jax.tree_leaves(optim.replace_frozen(config.schedule, grads, 0.))
/home/jyang347/CLIPA/clipa_jax/main.py:378: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  ps = jax.tree_leaves(params)
/home/jyang347/CLIPA/clipa_jax/main.py:380: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  us = jax.tree_leaves(updates)
I0125 01:17:04.156627 140592021429312 utils.py:427] TIMING[z/secs/update0]: 129.63646400300786
I0125 01:17:04.159354 140592021429312 prompt_engineering.py:92] Using 81 prompts_templates: ['a bad photo of a {}', 'a photo of many {}', 'a sculpture of a {}', 'a photo of the hard to see {}', 'a low resolution photo of the {}', 'a rendering of a {}', 'graffiti of a {}', 'a bad photo of the {}', 'a cropped photo of the {}', 'a tattoo of a {}', 'the embroidered {}', 'a photo of a hard to see {}', 'a bright photo of a {}', 'a photo of a clean {}', 'a photo of a dirty {}', 'a dark photo of the {}', 'a drawing of a {}', 'a photo of my {}', 'the plastic {}', 'a photo of the cool {}', 'a closeup photo of a {}', 'a black and white photo of the {}', 'a painting of the {}', 'a painting of a {}', 'a pixelated photo of the {}', 'a sculpture of the {}', 'a bright photo of the {}', 'a cropped photo of a {}', 'a plastic {}', 'a photo of the dirty {}', 'a jpeg corrupted photo of a {}', 'a blurry photo of the {}', 'a photo of the {}', 'a good photo of the {}', 'a rendering of the {}', 'a {} in a video game', 'a photo of one {}', 'a doodle of a {}', 'a closeup photo of the {}', 'a photo of a {}', 'the origami {}', 'the {} in a video game', 'a sketch of a {}', 'a doodle of the {}', 'a origami {}', 'a low resolution photo of a {}', 'the toy {}', 'a rendition of the {}', 'a photo of the clean {}', 'a photo of a large {}', 'a rendition of a {}', 'a photo of a nice {}', 'a photo of a weird {}', 'a blurry photo of a {}', 'a cartoon {}', 'art of a {}', 'a sketch of the {}', 'a embroidered {}', 'a pixelated photo of a {}', 'itap of the {}', 'a jpeg corrupted photo of the {}', 'a good photo of a {}', 'a plushie {}', 'a photo of the nice {}', 'a photo of the small {}', 'a photo of the weird {}', 'the cartoon {}', 'art of the {}', 'a drawing of the {}', 'a photo of the large {}', 'a black and white photo of a {}', 'the plushie {}', 'a dark photo of a {}', 'itap of a {}', 'graffiti of the {}', 'a toy {}', 'itap of my {}', 'a photo of a cool {}', 'a photo of a small {}', 'a tattoo of the {}', '{}']
I0125 01:17:04.163256 140592021429312 prompt_engineering.py:78] Using 1000 class_names: ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'american robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'american dipper', 'kite bird of prey', 'bald eagle', 'vulture', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'axolotl', 'american bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'green iguana', 'carolina anole', 'desert grassland whiptail lizard', 'agama', 'frillednecked lizard', 'alligator lizard', 'gila monster', 'european green lizard', 'chameleon', 'komodo dragon', 'nile crocodile', 'american alligator', 'triceratops', 'worm snake', 'ringnecked snake', 'eastern hognosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'african rock python', 'indian cobra', 'green mamba', 'sea snake', 'saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'trilobite', 'harvestman', 'scorpion', 'yellow garden spider', 'barn spider', 'european garden spider', 'southern black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie grouse', 'peafowl', 'quail', 'partridge', 'african grey parrot', 'macaw', 'sulphurcrested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'duck', 'redbreasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'american lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'limpkin', 'common gallinule', 'american coot', 'bustard', 'ruddy turnstone', 'dunlin', 'common redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'chihuahua', 'japanese chin', 'maltese', 'pekingese', 'shih tzu', 'king charles spaniel', 'papillon', 'toy terrier', 'rhodesian ridgeback', 'afghan hound', 'basset hound', 'beagle', 'bloodhound', 'bluetick coonhound', 'black and tan coonhound', 'treeing walker coonhound', 'english foxhound', 'redbone coonhound', 'borzoi', 'irish wolfhound', 'italian greyhound', 'whippet', 'ibizan hound', 'norwegian elkhound', 'otterhound', 'saluki', 'scottish deerhound', 'weimaraner', 'staffordshire bull terrier', 'american staffordshire terrier', 'bedlington terrier', 'border terrier', 'kerry blue terrier', 'irish terrier', 'norfolk terrier', 'norwich terrier', 'yorkshire terrier', 'wire fox terrier', 'lakeland terrier', 'sealyham terrier', 'airedale terrier', 'cairn terrier', 'australian terrier', 'dandie dinmont terrier', 'boston terrier', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'scottish terrier', 'tibetan terrier', 'australian silky terrier', 'softcoated wheaten terrier', 'west highland white terrier', 'lhasa apso', 'flatcoated retriever', 'curlycoated retriever', 'golden retriever', 'labrador retriever', 'chesapeake bay retriever', 'german shorthaired pointer', 'vizsla', 'english setter', 'irish setter', 'gordon setter', 'brittany dog', 'clumber spaniel', 'english springer spaniel', 'welsh springer spaniel', 'cocker spaniel', 'sussex spaniel', 'irish water spaniel', 'kuvasz', 'schipperke', 'groenendael dog', 'malinois', 'briard', 'australian kelpie', 'komondor', 'old english sheepdog', 'shetland sheepdog', 'collie', 'border collie', 'bouvier des flandres dog', 'rottweiler', 'german shepherd dog', 'dobermann', 'miniature pinscher', 'greater swiss mountain dog', 'bernese mountain dog', 'appenzeller sennenhund', 'entlebucher sennenhund', 'boxer', 'bullmastiff', 'tibetan mastiff', 'french bulldog', 'great dane', 'st bernard', 'husky', 'alaskan malamute', 'siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'leonberger', 'newfoundland dog', 'great pyrenees dog', 'samoyed', 'pomeranian', 'chow chow', 'keeshond', 'brussels griffon', 'pembroke welsh corgi', 'cardigan welsh corgi', 'toy poodle', 'miniature poodle', 'standard poodle', 'mexican hairless dog xoloitzcuintli', 'grey wolf', 'alaskan tundra wolf', 'red wolf or maned wolf', 'coyote', 'dingo', 'dhole', 'african wild dog', 'hyena', 'red fox', 'kit fox', 'arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'persian cat', 'siamese cat', 'egyptian mau', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'american black bear', 'polar bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket insect', 'stick insect', 'cockroach', 'praying mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamerwinged butterfly', 'starfish', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'hare', 'angora rabbit', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'common sorrel horse', 'zebra', 'pig', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram adult male sheep', 'bighorn sheep', 'alpine ibex', 'hartebeest', 'impala antelope', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'european polecat', 'blackfooted ferret', 'otter', 'skunk', 'badger', 'armadillo', 'threetoed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas monkey', 'baboon', 'macaque', 'langur', 'blackandwhite colobus', 'proboscis monkey', 'marmoset', 'whiteheaded capuchin', 'howler monkey', 'titi monkey', 'geoffroys spider monkey', 'common squirrel monkey', 'ringtailed lemur', 'indri', 'asian elephant', 'african bush elephant', 'red panda', 'giant panda', 'snoek fish', 'eel', 'silver salmon', 'rock beauty fish', 'clownfish', 'sturgeon', 'gar fish', 'lionfish', 'pufferfish', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibious vehicle', 'analog clock', 'apiary', 'apron', 'trash can', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint pen', 'bandaid', 'banjo', 'baluster handrail', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'wheelbarrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'swimming cap', 'bath towel', 'bathtub', 'station wagon', 'lighthouse', 'beaker', 'military hat bearskin or shako', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'bikini', 'ring binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookcase', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'highspeed train', 'butcher shop', 'taxicab', 'cauldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', 'tool kit', 'cardboard box carton', 'car wheel', 'automated teller machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'cd player', 'cello', 'mobile phone', 'chain', 'chainlink fence', 'chain mail', 'chainsaw', 'storage chest', 'chiffonier', 'bell or wind chime', 'china cabinet', 'christmas stocking', 'church', 'movie theater', 'cleaver', 'cliff dwelling', 'cloak', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'construction crane', 'crash helmet', 'crate', 'infant bed', 'crock pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'rotary dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'dishwasher', 'disc brake', 'dock', 'dog sled', 'dome', 'doormat', 'drilling rig', 'drum', 'drumstick', 'dumbbell', 'dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fireboat', 'fire truck', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'fourposter bed', 'freight car', 'french horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'goblet', 'gokart', 'golf ball', 'golf cart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'radiator grille', 'grocery store', 'guillotine', 'hair clip', 'hair spray', 'halftrack', 'hammer', 'hamper', 'hair dryer', 'handheld computer', 'handkerchief', 'hard disk drive', 'harmonica', 'harp', 'combine harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoop skirt', 'gymnastic horizontal bar', 'horsedrawn vehicle', 'hourglass', 'ipod', 'clothes iron', 'carved pumpkin', 'jeans', 'jeep', 'tshirt', 'jigsaw puzzle', 'rickshaw', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'ocean liner', 'lipstick', 'slipon shoe', 'lotion', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'mailbox', 'tights', 'onepiece bathing suit', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine cabinet', 'megalith', 'microphone', 'microwave oven', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'ford model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar and pestle', 'graduation cap', 'mosque', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'mousetrap', 'moving van', 'muzzle', 'metal nail', 'neck brace', 'necklace', 'baby pacifier', 'notebook computer', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'pipe organ', 'oscilloscope', 'overskirt', 'bullock cart', 'oxygen mask', 'product packet packaging', 'paddle', 'paddle wheel', 'padlock', 'paintbrush', 'pajamas', 'palace', 'pan flute', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'patio', 'payphone', 'pedestal', 'pencil case', 'pencil sharpener', 'perfume', 'petri dish', 'photocopier', 'plectrum', 'pickelhaube', 'picket fence', 'pickup truck', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'pingpong ball', 'pinwheel', 'pirate ship', 'drink pitcher', 'block plane', 'planetarium', 'plastic bag', 'plate rack', 'farm plow', 'plunger', 'polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'soda bottle', 'plant pot', 'potters wheel', 'power drill', 'prayer rug', 'printer', 'prison', 'missile', 'projector', 'hockey puck', 'punching bag', 'purse', 'quill', 'quilt', 'race car', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safe', 'safety pin', 'salt shaker', 'sandal', 'sarong', 'saxophone', 'scabbard', 'weighing scale', 'school bus', 'schooner', 'scoreboard', 'crt monitor', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe store', 'shoji screen room divider', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar thermal collector', 'sombrero', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'spatula', 'motorboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'through arch bridge', 'steel drum', 'stethoscope', 'scarf', 'stone wall', 'stopwatch', 'stove', 'strainer', 'tram', 'stretcher', 'couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'suspension bridge', 'mop', 'sweatshirt', 'swim trunks shorts', 'swing', 'electrical switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy bear', 'television', 'tennis ball', 'thatched roof', 'front curtain', 'thimble', 'threshing machine', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toy store', 'tractor', 'semitrailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'hot tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright piano', 'vacuum cleaner', 'vase', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'hair wig', 'window screen', 'window shade', 'windsor tie', 'wine bottle', 'airplane wing', 'wok', 'wooden spoon', 'wool', 'splitrail fence', 'shipwreck', 'sailboat', 'yurt', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'popsicle', 'baguette', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'mashed potatoes', 'cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'granny smith apple', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'cherimoya custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate syrup', 'dough', 'meatloaf', 'pizza', 'pot pie', 'burrito', 'red wine', 'espresso', 'tea cup', 'eggnog', 'mountain', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeshore', 'promontory', 'sandbar', 'beach', 'valley', 'volcano', 'baseball player', 'bridegroom', 'scuba diver', 'rapeseed', 'daisy', 'yellow ladys slipper', 'corn', 'acorn', 'rose hip', 'horse chestnut seed', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'bolete', 'corn cob', 'toilet paper']
I0125 01:17:04.302424 140592021429312 dataset_info.py:566] Load dataset info from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:04.526142 140592021429312 dataset_info.py:642] Field info.description from disk and from code do not match. Keeping the one from code.
I0125 01:17:04.526558 140592021429312 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:17:04.598775 140592021429312 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split _EvenSplit(split='validation', index=1, count=8, drop_remainder=False), from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:04.602200 140592021429312 api.py:459] Data before pre-processing:
{'file_name': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'image': <tf.Tensor 'args_1:0' shape=(None, None, 3) dtype=uint8>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:04.803235 140592021429312 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'truediv_1:0' shape=(56, 56, 3) dtype=float32>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:04.870450 140307309722688 utils.py:844] [35m[1][0m training_loss = 10.512954711914062
I0125 01:17:04.871487 140307309722688 utils.py:844] [35m[1][0m l2_grad_cls = 2.06858229637146
I0125 01:17:04.872304 140307309722688 utils.py:844] [35m[1][0m l2_grad_embeding = 1.2238881587982178
I0125 01:17:04.873013 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_0 = 0.5442503690719604
I0125 01:17:04.873629 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_1 = 0.47263994812965393
I0125 01:17:04.874323 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_10 = 0.2399647980928421
I0125 01:17:04.874873 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_11 = 0.231858491897583
I0125 01:17:04.875351 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_12 = 0.22240595519542694
I0125 01:17:04.875926 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_13 = 0.21847163140773773
I0125 01:17:04.876415 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_14 = 0.2079472690820694
I0125 01:17:04.876867 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_15 = 0.20569802820682526
I0125 01:17:04.877321 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_16 = 0.19550761580467224
I0125 01:17:04.877763 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_17 = 0.19283266365528107
I0125 01:17:04.878193 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_2 = 0.42618417739868164
I0125 01:17:04.878610 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_3 = 0.36971014738082886
I0125 01:17:04.879015 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_4 = 0.3354593813419342
I0125 01:17:04.879597 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_5 = 0.3376929759979248
I0125 01:17:04.880033 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_6 = 0.3077830672264099
I0125 01:17:04.880577 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_7 = 0.2793828248977661
I0125 01:17:04.881145 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_8 = 0.26582762598991394
I0125 01:17:04.881719 140307309722688 utils.py:844] [35m[1][0m l2_grad_encoderblock_9 = 0.253561794757843
I0125 01:17:04.882156 140307309722688 utils.py:844] [35m[1][0m l2_grad_head = 1.3687316179275513
I0125 01:17:04.882688 140307309722688 utils.py:844] [35m[1][0m l2_grads = 12.119216918945312
I0125 01:17:04.883249 140307309722688 utils.py:844] [35m[1][0m l2_params = 441.74322509765625
I0125 01:17:04.883702 140307309722688 utils.py:844] [35m[1][0m l2_updates = 0.0
I0125 01:17:04.884137 140307309722688 utils.py:844] [35m[1][0m ncorrect = 3.0517578125e-05
I0125 01:17:04.884682 140307309722688 utils.py:844] [35m[1][0m nimg = 22.43639373779297
I0125 01:17:04.885101 140307309722688 utils.py:844] [35m[1][0m ntxt = 22.51953125
I0125 01:17:04.885678 140307309722688 utils.py:844] [35m[1][0m t = 14.285693168640137
I0125 01:17:04.886161 140307309722688 utils.py:844] [35m[1][0m t/parameter = 2.6592600345611572
I0125 01:17:04.886271 140307309722688 utils.py:844] [35m[1][0m uptime = 216.57356629893184
I0125 01:17:04.886355 140307309722688 utils.py:844] [35m[1][0m examples_seen = 32768.0
I0125 01:17:04.886414 140307309722688 utils.py:844] [35m[1][0m progress = 1.785267968722105e-05
I0125 01:17:04.886467 140307309722688 utils.py:844] [35m[1][0m epoch = 0.00012496949034724146
I0125 01:17:04.886516 140307309722688 main.py:119] [33mNOTE[0m: Steps:0/56014 [0.0%]
I0125 01:17:04.904572 140493899304000 discriminative_classifier.py:348] Starting text embedding...
I0125 01:17:04.904685 139956134382656 discriminative_classifier.py:348] Starting text embedding...
I0125 01:17:04.905093 140581069126720 discriminative_classifier.py:348] Starting text embedding...
I0125 01:17:04.905182 139959958596672 discriminative_classifier.py:348] Starting text embedding...
I0125 01:17:04.906134 139866951023680 discriminative_classifier.py:348] Starting text embedding...
I0125 01:17:04.913926 140212821134400 discriminative_classifier.py:348] Starting text embedding...
I0125 01:17:05.355031 140592021429312 api.py:459] Data before pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'texts': <tf.Tensor 'args_1:0' shape=() dtype=string>}
I0125 01:17:05.717308 140592021429312 api.py:459] Data after pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'labels': <tf.Tensor 'strided_slice_4:0' shape=(16,) dtype=int32>}
I0125 01:17:05.838833 140592021429312 discriminative_classifier.py:341] Initialized evaluator in 1.7 seconds
I0125 01:17:05.875039 140592021429312 discriminative_classifier.py:348] Starting text embedding...
I0125 01:17:06.301165 140307309722688 main.py:119] [33mNOTE[0m: Init evaluator: disclf…
Steps:0/56014 [0.0%]
I0125 01:17:06.315855 140307309722688 prompt_engineering.py:92] Using 81 prompts_templates: ['a bad photo of a {}', 'a photo of many {}', 'a sculpture of a {}', 'a photo of the hard to see {}', 'a low resolution photo of the {}', 'a rendering of a {}', 'graffiti of a {}', 'a bad photo of the {}', 'a cropped photo of the {}', 'a tattoo of a {}', 'the embroidered {}', 'a photo of a hard to see {}', 'a bright photo of a {}', 'a photo of a clean {}', 'a photo of a dirty {}', 'a dark photo of the {}', 'a drawing of a {}', 'a photo of my {}', 'the plastic {}', 'a photo of the cool {}', 'a closeup photo of a {}', 'a black and white photo of the {}', 'a painting of the {}', 'a painting of a {}', 'a pixelated photo of the {}', 'a sculpture of the {}', 'a bright photo of the {}', 'a cropped photo of a {}', 'a plastic {}', 'a photo of the dirty {}', 'a jpeg corrupted photo of a {}', 'a blurry photo of the {}', 'a photo of the {}', 'a good photo of the {}', 'a rendering of the {}', 'a {} in a video game', 'a photo of one {}', 'a doodle of a {}', 'a closeup photo of the {}', 'a photo of a {}', 'the origami {}', 'the {} in a video game', 'a sketch of a {}', 'a doodle of the {}', 'a origami {}', 'a low resolution photo of a {}', 'the toy {}', 'a rendition of the {}', 'a photo of the clean {}', 'a photo of a large {}', 'a rendition of a {}', 'a photo of a nice {}', 'a photo of a weird {}', 'a blurry photo of a {}', 'a cartoon {}', 'art of a {}', 'a sketch of the {}', 'a embroidered {}', 'a pixelated photo of a {}', 'itap of the {}', 'a jpeg corrupted photo of the {}', 'a good photo of a {}', 'a plushie {}', 'a photo of the nice {}', 'a photo of the small {}', 'a photo of the weird {}', 'the cartoon {}', 'art of the {}', 'a drawing of the {}', 'a photo of the large {}', 'a black and white photo of a {}', 'the plushie {}', 'a dark photo of a {}', 'itap of a {}', 'graffiti of the {}', 'a toy {}', 'itap of my {}', 'a photo of a cool {}', 'a photo of a small {}', 'a tattoo of the {}', '{}']
I0125 01:17:06.320135 140307309722688 prompt_engineering.py:78] Using 1000 class_names: ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark', 'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'american robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'american dipper', 'kite bird of prey', 'bald eagle', 'vulture', 'great grey owl', 'fire salamander', 'smooth newt', 'newt', 'spotted salamander', 'axolotl', 'american bullfrog', 'tree frog', 'tailed frog', 'loggerhead sea turtle', 'leatherback sea turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'green iguana', 'carolina anole', 'desert grassland whiptail lizard', 'agama', 'frillednecked lizard', 'alligator lizard', 'gila monster', 'european green lizard', 'chameleon', 'komodo dragon', 'nile crocodile', 'american alligator', 'triceratops', 'worm snake', 'ringnecked snake', 'eastern hognosed snake', 'smooth green snake', 'kingsnake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'african rock python', 'indian cobra', 'green mamba', 'sea snake', 'saharan horned viper', 'eastern diamondback rattlesnake', 'sidewinder rattlesnake', 'trilobite', 'harvestman', 'scorpion', 'yellow garden spider', 'barn spider', 'european garden spider', 'southern black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie grouse', 'peafowl', 'quail', 'partridge', 'african grey parrot', 'macaw', 'sulphurcrested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'duck', 'redbreasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'dungeness crab', 'rock crab', 'fiddler crab', 'red king crab', 'american lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'great egret', 'bittern bird', 'crane bird', 'limpkin', 'common gallinule', 'american coot', 'bustard', 'ruddy turnstone', 'dunlin', 'common redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'chihuahua', 'japanese chin', 'maltese', 'pekingese', 'shih tzu', 'king charles spaniel', 'papillon', 'toy terrier', 'rhodesian ridgeback', 'afghan hound', 'basset hound', 'beagle', 'bloodhound', 'bluetick coonhound', 'black and tan coonhound', 'treeing walker coonhound', 'english foxhound', 'redbone coonhound', 'borzoi', 'irish wolfhound', 'italian greyhound', 'whippet', 'ibizan hound', 'norwegian elkhound', 'otterhound', 'saluki', 'scottish deerhound', 'weimaraner', 'staffordshire bull terrier', 'american staffordshire terrier', 'bedlington terrier', 'border terrier', 'kerry blue terrier', 'irish terrier', 'norfolk terrier', 'norwich terrier', 'yorkshire terrier', 'wire fox terrier', 'lakeland terrier', 'sealyham terrier', 'airedale terrier', 'cairn terrier', 'australian terrier', 'dandie dinmont terrier', 'boston terrier', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'scottish terrier', 'tibetan terrier', 'australian silky terrier', 'softcoated wheaten terrier', 'west highland white terrier', 'lhasa apso', 'flatcoated retriever', 'curlycoated retriever', 'golden retriever', 'labrador retriever', 'chesapeake bay retriever', 'german shorthaired pointer', 'vizsla', 'english setter', 'irish setter', 'gordon setter', 'brittany dog', 'clumber spaniel', 'english springer spaniel', 'welsh springer spaniel', 'cocker spaniel', 'sussex spaniel', 'irish water spaniel', 'kuvasz', 'schipperke', 'groenendael dog', 'malinois', 'briard', 'australian kelpie', 'komondor', 'old english sheepdog', 'shetland sheepdog', 'collie', 'border collie', 'bouvier des flandres dog', 'rottweiler', 'german shepherd dog', 'dobermann', 'miniature pinscher', 'greater swiss mountain dog', 'bernese mountain dog', 'appenzeller sennenhund', 'entlebucher sennenhund', 'boxer', 'bullmastiff', 'tibetan mastiff', 'french bulldog', 'great dane', 'st bernard', 'husky', 'alaskan malamute', 'siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'leonberger', 'newfoundland dog', 'great pyrenees dog', 'samoyed', 'pomeranian', 'chow chow', 'keeshond', 'brussels griffon', 'pembroke welsh corgi', 'cardigan welsh corgi', 'toy poodle', 'miniature poodle', 'standard poodle', 'mexican hairless dog xoloitzcuintli', 'grey wolf', 'alaskan tundra wolf', 'red wolf or maned wolf', 'coyote', 'dingo', 'dhole', 'african wild dog', 'hyena', 'red fox', 'kit fox', 'arctic fox', 'grey fox', 'tabby cat', 'tiger cat', 'persian cat', 'siamese cat', 'egyptian mau', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'american black bear', 'polar bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'longhorn beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket insect', 'stick insect', 'cockroach', 'praying mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'red admiral butterfly', 'ringlet butterfly', 'monarch butterfly', 'small white butterfly', 'sulphur butterfly', 'gossamerwinged butterfly', 'starfish', 'sea urchin', 'sea cucumber', 'cottontail rabbit', 'hare', 'angora rabbit', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'common sorrel horse', 'zebra', 'pig', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram adult male sheep', 'bighorn sheep', 'alpine ibex', 'hartebeest', 'impala antelope', 'gazelle', 'arabian camel', 'llama', 'weasel', 'mink', 'european polecat', 'blackfooted ferret', 'otter', 'skunk', 'badger', 'armadillo', 'threetoed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas monkey', 'baboon', 'macaque', 'langur', 'blackandwhite colobus', 'proboscis monkey', 'marmoset', 'whiteheaded capuchin', 'howler monkey', 'titi monkey', 'geoffroys spider monkey', 'common squirrel monkey', 'ringtailed lemur', 'indri', 'asian elephant', 'african bush elephant', 'red panda', 'giant panda', 'snoek fish', 'eel', 'silver salmon', 'rock beauty fish', 'clownfish', 'sturgeon', 'gar fish', 'lionfish', 'pufferfish', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibious vehicle', 'analog clock', 'apiary', 'apron', 'trash can', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint pen', 'bandaid', 'banjo', 'baluster handrail', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'wheelbarrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'swimming cap', 'bath towel', 'bathtub', 'station wagon', 'lighthouse', 'beaker', 'military hat bearskin or shako', 'beer bottle', 'beer glass', 'bell tower', 'baby bib', 'tandem bicycle', 'bikini', 'ring binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsleigh', 'bolo tie', 'poke bonnet', 'bookcase', 'bookstore', 'bottle cap', 'hunting bow', 'bow tie', 'brass memorial plaque', 'bra', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'highspeed train', 'butcher shop', 'taxicab', 'cauldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', 'tool kit', 'cardboard box carton', 'car wheel', 'automated teller machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'cd player', 'cello', 'mobile phone', 'chain', 'chainlink fence', 'chain mail', 'chainsaw', 'storage chest', 'chiffonier', 'bell or wind chime', 'china cabinet', 'christmas stocking', 'church', 'movie theater', 'cleaver', 'cliff dwelling', 'cloak', 'clogs', 'cocktail shaker', 'coffee mug', 'coffeemaker', 'spiral or coil', 'combination lock', 'computer keyboard', 'candy store', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'construction crane', 'crash helmet', 'crate', 'infant bed', 'crock pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'rotary dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishcloth', 'dishwasher', 'disc brake', 'dock', 'dog sled', 'dome', 'doormat', 'drilling rig', 'drum', 'drumstick', 'dumbbell', 'dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso machine', 'face powder', 'feather boa', 'filing cabinet', 'fireboat', 'fire truck', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'fourposter bed', 'freight car', 'french horn', 'frying pan', 'fur coat', 'garbage truck', 'gas mask or respirator', 'gas pump', 'goblet', 'gokart', 'golf ball', 'golf cart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'radiator grille', 'grocery store', 'guillotine', 'hair clip', 'hair spray', 'halftrack', 'hammer', 'hamper', 'hair dryer', 'handheld computer', 'handkerchief', 'hard disk drive', 'harmonica', 'harp', 'combine harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoop skirt', 'gymnastic horizontal bar', 'horsedrawn vehicle', 'hourglass', 'ipod', 'clothes iron', 'carved pumpkin', 'jeans', 'jeep', 'tshirt', 'jigsaw puzzle', 'rickshaw', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop computer', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'ocean liner', 'lipstick', 'slipon shoe', 'lotion', 'music speaker', 'loupe magnifying glass', 'sawmill', 'magnetic compass', 'messenger bag', 'mailbox', 'tights', 'onepiece bathing suit', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine cabinet', 'megalith', 'microphone', 'microwave oven', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'ford model t', 'modem', 'monastery', 'monitor', 'moped', 'mortar and pestle', 'graduation cap', 'mosque', 'mosquito net', 'vespa', 'mountain bike', 'tent', 'computer mouse', 'mousetrap', 'moving van', 'muzzle', 'metal nail', 'neck brace', 'necklace', 'baby pacifier', 'notebook computer', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'pipe organ', 'oscilloscope', 'overskirt', 'bullock cart', 'oxygen mask', 'product packet packaging', 'paddle', 'paddle wheel', 'padlock', 'paintbrush', 'pajamas', 'palace', 'pan flute', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'railroad car', 'patio', 'payphone', 'pedestal', 'pencil case', 'pencil sharpener', 'perfume', 'petri dish', 'photocopier', 'plectrum', 'pickelhaube', 'picket fence', 'pickup truck', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'pingpong ball', 'pinwheel', 'pirate ship', 'drink pitcher', 'block plane', 'planetarium', 'plastic bag', 'plate rack', 'farm plow', 'plunger', 'polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'soda bottle', 'plant pot', 'potters wheel', 'power drill', 'prayer rug', 'printer', 'prison', 'missile', 'projector', 'hockey puck', 'punching bag', 'purse', 'quill', 'quilt', 'race car', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'fishing casting reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'eraser', 'rugby ball', 'ruler measuring stick', 'sneaker', 'safe', 'safety pin', 'salt shaker', 'sandal', 'sarong', 'saxophone', 'scabbard', 'weighing scale', 'school bus', 'schooner', 'scoreboard', 'crt monitor', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe store', 'shoji screen room divider', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'balaclava ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot machine', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar thermal collector', 'sombrero', 'soup bowl', 'keyboard space bar', 'space heater', 'space shuttle', 'spatula', 'motorboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'through arch bridge', 'steel drum', 'stethoscope', 'scarf', 'stone wall', 'stopwatch', 'stove', 'strainer', 'tram', 'stretcher', 'couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglasses', 'sunglasses', 'sunscreen', 'suspension bridge', 'mop', 'sweatshirt', 'swim trunks shorts', 'swing', 'electrical switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy bear', 'television', 'tennis ball', 'thatched roof', 'front curtain', 'thimble', 'threshing machine', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toy store', 'tractor', 'semitrailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'hot tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright piano', 'vacuum cleaner', 'vase', 'vaulted or arched ceiling', 'velvet fabric', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'military aircraft', 'sink', 'washing machine', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'hair wig', 'window screen', 'window shade', 'windsor tie', 'wine bottle', 'airplane wing', 'wok', 'wooden spoon', 'wool', 'splitrail fence', 'shipwreck', 'sailboat', 'yurt', 'website', 'comic book', 'crossword', 'traffic or street sign', 'traffic light', 'dust jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'popsicle', 'baguette', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'mashed potatoes', 'cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'granny smith apple', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'cherimoya custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate syrup', 'dough', 'meatloaf', 'pizza', 'pot pie', 'burrito', 'red wine', 'espresso', 'tea cup', 'eggnog', 'mountain', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeshore', 'promontory', 'sandbar', 'beach', 'valley', 'volcano', 'baseball player', 'bridegroom', 'scuba diver', 'rapeseed', 'daisy', 'yellow ladys slipper', 'corn', 'acorn', 'rose hip', 'horse chestnut seed', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn mushroom', 'earth star fungus', 'hen of the woods mushroom', 'bolete', 'corn cob', 'toilet paper']
I0125 01:17:06.507052 140307309722688 dataset_info.py:566] Load dataset info from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:06.810479 140307309722688 dataset_info.py:642] Field info.description from disk and from code do not match. Keeping the one from code.
I0125 01:17:06.810855 140307309722688 dataset_info.py:642] Field info.module_name from disk and from code do not match. Keeping the one from code.
I0125 01:17:06.953045 140307309722688 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split _EvenSplit(split='validation', index=0, count=8, drop_remainder=False), from gs://jaxtpu-tfds-imagenet-eu-west4-a/imagenet2012/5.1.0
I0125 01:17:06.960455 140307309722688 api.py:459] Data before pre-processing:
{'file_name': <tf.Tensor 'args_0:0' shape=() dtype=string>, 'image': <tf.Tensor 'args_1:0' shape=(None, None, 3) dtype=uint8>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:07.371697 140307309722688 api.py:459] Data after pre-processing:
{'image': <tf.Tensor 'truediv_1:0' shape=(56, 56, 3) dtype=float32>, 'label': <tf.Tensor 'args_2:0' shape=() dtype=int64>}
I0125 01:17:08.365421 140307309722688 api.py:459] Data before pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'texts': <tf.Tensor 'args_1:0' shape=() dtype=string>}
tcmalloc: large alloc 1111490560 bytes == 0xfd7d26000 @  0x7f9bd7bd0680 0x7f9bd7bf0da2 0x5d6aec 0x63908c 0x4fe616 0x4daf8a 0x547447 0x5d5846 0x547447 0x54552a 0x5d5a23 0x5483b6 0x54552a 0x5d5a23 0x547265 0x54552a 0x5d5a23 0x5d4c12 0x7f9bcfbfacf3 0x5d553a 0x5d6066 0x54ca58 0x54552a 0x5d5a23 0x5d4c12 0x548a66 0x54552a 0x5d5a23 0x5d4c12 0x548a66 0x54552a
tcmalloc: large alloc 1389363200 bytes == 0xac2fe000 @  0x7f9bd7bd0680 0x7f9bd7bf0da2 0x5d6aec 0x63908c 0x4fe616 0x4daf8a 0x547447 0x5d5846 0x547447 0x54552a 0x5d5a23 0x5483b6 0x54552a 0x5d5a23 0x547265 0x54552a 0x5d5a23 0x5d4c12 0x7f9bcfbfacf3 0x5d553a 0x5d6066 0x54ca58 0x54552a 0x5d5a23 0x5d4c12 0x548a66 0x54552a 0x5d5a23 0x5d4c12 0x548a66 0x54552a
I0125 01:17:09.643397 140307309722688 api.py:459] Data after pre-processing:
{'label': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'labels': <tf.Tensor 'strided_slice_4:0' shape=(16,) dtype=int32>}
tcmalloc: large alloc 1736704000 bytes == 0xfd7d26000 @  0x7f9bd7bd0680 0x7f9bd7bf0da2 0x5d6aec 0x63908c 0x4fe616 0x4daf8a 0x547447 0x5d5846 0x547447 0x54552a 0x5d5a23 0x5483b6 0x54552a 0x5d5a23 0x547265 0x54552a 0x5d5a23 0x5d4c12 0x7f9bcfbfacf3 0x5d553a 0x5d6066 0x54ca58 0x54552a 0x5d5a23 0x5d4c12 0x548a66 0x54552a 0x5d5a23 0x5d4c12 0x548a66 0x54552a
I0125 01:17:10.333152 140307309722688 discriminative_classifier.py:341] Initialized evaluator in 4.0 seconds
I0125 01:17:10.335540 140307309722688 main.py:119] [33mNOTE[0m: disclf evaluation...
Steps:0/56014 [0.0%]
I0125 01:17:10.335661 140307309722688 discriminative_classifier.py:348] Starting text embedding...
tcmalloc: large alloc 2170880000 bytes == 0x103f566000 @  0x7f9bd7bd0680 0x7f9bd7bf0da2 0x5d6aec 0x63908c 0x4fe616 0x4daf8a 0x547447 0x5d5846 0x547447 0x54552a 0x5d5a23 0x5483b6 0x54552a 0x5d5a23 0x547265 0x54552a 0x5d5a23 0x5d4c12 0x7f9bcfbfacf3 0x5d553a 0x5d6066 0x54ca58 0x54552a 0x5d5a23 0x5d4c12 0x548a66 0x54552a 0x5d5a23 0x5d4c12 0x548a66 0x54552a
I0125 01:17:18.796037 139959958596672 discriminative_classifier.py:365] Compiled text embeddings in 13.9s
I0125 01:17:18.796722 140212821134400 discriminative_classifier.py:365] Compiled text embeddings in 13.9s
I0125 01:17:18.848600 140493899304000 discriminative_classifier.py:365] Compiled text embeddings in 13.9s
I0125 01:17:18.942504 140581069126720 discriminative_classifier.py:365] Compiled text embeddings in 14.0s
I0125 01:17:18.972481 139866951023680 discriminative_classifier.py:365] Compiled text embeddings in 14.1s
I0125 01:17:18.974431 139956134382656 discriminative_classifier.py:365] Compiled text embeddings in 14.1s
I0125 01:17:19.101879 140592021429312 discriminative_classifier.py:365] Compiled text embeddings in 13.2s
I0125 01:17:19.236765 140307309722688 discriminative_classifier.py:365] Compiled text embeddings in 8.9s
I0125 01:17:20.023937 139959958596672 discriminative_classifier.py:383] Embedded imagenet2012 text in 4 steps - ...[32768 32768 15464     0]
I0125 01:17:20.024337 139959958596672 discriminative_classifier.py:385] Totalling 81000 text in 1.2s
I0125 01:17:20.024427 139959958596672 discriminative_classifier.py:386] Total texts embeddings size 165.9M
I0125 01:17:20.027008 140307309722688 discriminative_classifier.py:383] Embedded imagenet2012 text in 4 steps - ...[32768 32768 15464     0]
I0125 01:17:20.027438 140307309722688 discriminative_classifier.py:385] Totalling 81000 text in 0.8s
I0125 01:17:20.027533 140307309722688 discriminative_classifier.py:386] Total texts embeddings size 165.9M
I0125 01:17:20.028102 139959958596672 discriminative_classifier.py:400] Starting image embedding...
I0125 01:17:20.028078 140581069126720 discriminative_classifier.py:383] Embedded imagenet2012 text in 4 steps - ...[32768 32768 15464     0]
I0125 01:17:20.028462 140581069126720 discriminative_classifier.py:385] Totalling 81000 text in 1.1s
I0125 01:17:20.028532 140581069126720 discriminative_classifier.py:386] Total texts embeddings size 165.9M
I0125 01:17:20.027937 140212821134400 discriminative_classifier.py:383] Embedded imagenet2012 text in 4 steps - ...[32768 32768 15464     0]
I0125 01:17:20.028303 140212821134400 discriminative_classifier.py:385] Totalling 81000 text in 1.2s
I0125 01:17:20.028370 140212821134400 discriminative_classifier.py:386] Total texts embeddings size 165.9M
I0125 01:17:20.029410 139956134382656 discriminative_classifier.py:383] Embedded imagenet2012 text in 4 steps - ...[32768 32768 15464     0]
I0125 01:17:20.029804 139956134382656 discriminative_classifier.py:385] Totalling 81000 text in 1.1s
I0125 01:17:20.029920 139956134382656 discriminative_classifier.py:386] Total texts embeddings size 165.9M
I0125 01:17:20.031329 140307309722688 discriminative_classifier.py:400] Starting image embedding...
I0125 01:17:20.032153 140212821134400 discriminative_classifier.py:400] Starting image embedding...
I0125 01:17:20.032355 140581069126720 discriminative_classifier.py:400] Starting image embedding...
I0125 01:17:20.033688 139956134382656 discriminative_classifier.py:400] Starting image embedding...
I0125 01:17:20.036205 140592021429312 discriminative_classifier.py:383] Embedded imagenet2012 text in 4 steps - ...[32768 32768 15464     0]
I0125 01:17:20.036580 140592021429312 discriminative_classifier.py:385] Totalling 81000 text in 0.9s
I0125 01:17:20.036655 140592021429312 discriminative_classifier.py:386] Total texts embeddings size 165.9M
I0125 01:17:20.037382 139866951023680 discriminative_classifier.py:383] Embedded imagenet2012 text in 4 steps - ...[32768 32768 15464     0]
I0125 01:17:20.037762 139866951023680 discriminative_classifier.py:385] Totalling 81000 text in 1.1s
I0125 01:17:20.037832 139866951023680 discriminative_classifier.py:386] Total texts embeddings size 165.9M
I0125 01:17:20.039635 140493899304000 discriminative_classifier.py:383] Embedded imagenet2012 text in 4 steps - ...[32768 32768 15464     0]
I0125 01:17:20.040016 140493899304000 discriminative_classifier.py:385] Totalling 81000 text in 1.2s
I0125 01:17:20.040083 140493899304000 discriminative_classifier.py:386] Total texts embeddings size 165.9M
I0125 01:17:20.040606 140592021429312 discriminative_classifier.py:400] Starting image embedding...
I0125 01:17:20.041610 139866951023680 discriminative_classifier.py:400] Starting image embedding...
I0125 01:17:20.043987 140493899304000 discriminative_classifier.py:400] Starting image embedding...
I0125 01:17:24.091698 140307309722688 vit.py:166] remat policy: actcp
I0125 01:17:24.091845 140307309722688 vit.py:171] activation checkpointing actcp
I0125 01:17:24.091756 139959958596672 vit.py:166] remat policy: actcp
I0125 01:17:24.091912 139959958596672 vit.py:171] activation checkpointing actcp
I0125 01:17:24.092252 140493899304000 vit.py:166] remat policy: actcp
I0125 01:17:24.092432 140493899304000 vit.py:171] activation checkpointing actcp
I0125 01:17:24.092205 139956134382656 vit.py:166] remat policy: actcp
I0125 01:17:24.092401 139956134382656 vit.py:171] activation checkpointing actcp
I0125 01:17:24.092839 140581069126720 vit.py:166] remat policy: actcp
I0125 01:17:24.093018 140581069126720 vit.py:171] activation checkpointing actcp
I0125 01:17:24.093801 140592021429312 vit.py:166] remat policy: actcp
I0125 01:17:24.093976 140592021429312 vit.py:171] activation checkpointing actcp
I0125 01:17:24.101355 140212821134400 vit.py:166] remat policy: actcp
I0125 01:17:24.101552 140212821134400 vit.py:171] activation checkpointing actcp
I0125 01:17:24.107204 139866951023680 vit.py:166] remat policy: actcp
I0125 01:17:24.107381 139866951023680 vit.py:171] activation checkpointing actcp
I0125 01:17:31.917869 140307309722688 discriminative_classifier.py:433] Compiled image embeddings in 11.9s
I0125 01:17:31.922517 140212821134400 discriminative_classifier.py:433] Compiled image embeddings in 11.9s
I0125 01:17:32.017836 139959958596672 discriminative_classifier.py:433] Compiled image embeddings in 12.0s
I0125 01:17:32.024301 140581069126720 discriminative_classifier.py:433] Compiled image embeddings in 12.0s
I0125 01:17:32.033471 140493899304000 discriminative_classifier.py:433] Compiled image embeddings in 12.0s
I0125 01:17:32.255991 139866951023680 discriminative_classifier.py:433] Compiled image embeddings in 12.2s
I0125 01:17:32.301041 140592021429312 discriminative_classifier.py:433] Compiled image embeddings in 12.3s
I0125 01:17:32.385168 139956134382656 discriminative_classifier.py:433] Compiled image embeddings in 12.4s
I0125 01:17:32.674568 140212821134400 discriminative_classifier.py:447] Embedded imagenet2012 image in 3 steps - ...[32768 17232     0]
I0125 01:17:32.674938 140212821134400 discriminative_classifier.py:449] Totalling 50000 image in 0.8s
I0125 01:17:32.675026 140212821134400 discriminative_classifier.py:455] Dataset imagenet2012, results {'accuracy': 0.0011, 'correct': 55, 'count': 50000}
I0125 01:17:32.674662 140307309722688 discriminative_classifier.py:447] Embedded imagenet2012 image in 3 steps - ...[32768 17232     0]
I0125 01:17:32.675012 140307309722688 discriminative_classifier.py:449] Totalling 50000 image in 0.8s
I0125 01:17:32.675099 140307309722688 discriminative_classifier.py:455] Dataset imagenet2012, results {'accuracy': 0.0011, 'correct': 55, 'count': 50000}
I0125 01:17:32.674802 140592021429312 discriminative_classifier.py:447] Embedded imagenet2012 image in 3 steps - ...[32768 17232     0]
I0125 01:17:32.675164 140592021429312 discriminative_classifier.py:449] Totalling 50000 image in 0.4s
I0125 01:17:32.675249 140592021429312 discriminative_classifier.py:455] Dataset imagenet2012, results {'accuracy': 0.0011, 'correct': 55, 'count': 50000}
I0125 01:17:32.675312 140212821134400 utils.py:427] TIMING[z/secs/eval/disclf]: 27.761429206933826
I0125 01:17:32.674839 139956134382656 discriminative_classifier.py:447] Embedded imagenet2012 image in 3 steps - ...[32768 17232     0]
I0125 01:17:32.675198 139956134382656 discriminative_classifier.py:449] Totalling 50000 image in 0.3s
I0125 01:17:32.675330 139956134382656 discriminative_classifier.py:455] Dataset imagenet2012, results {'accuracy': 0.0011, 'correct': 55, 'count': 50000}
I0125 01:17:32.675464 140307309722688 utils.py:844] [35m[1][0m z/0shot/imagenet2012_accuracy = 0.0011
I0125 01:17:32.674975 140581069126720 discriminative_classifier.py:447] Embedded imagenet2012 image in 3 steps - ...[32768 17232     0]
I0125 01:17:32.675335 140581069126720 discriminative_classifier.py:449] Totalling 50000 image in 0.7s
I0125 01:17:32.675426 140581069126720 discriminative_classifier.py:455] Dataset imagenet2012, results {'accuracy': 0.0011, 'correct': 55, 'count': 50000}
I0125 01:17:32.675597 140307309722688 utils.py:844] [35m[1][0m z/secs/eval/disclf = 22.339927405118942
I0125 01:17:32.675657 140307309722688 utils.py:427] TIMING[z/secs/eval/disclf]: 22.339927405118942
I0125 01:17:32.675605 140592021429312 utils.py:427] TIMING[z/secs/eval/disclf]: 26.800581685034558
I0125 01:17:32.675482 139866951023680 discriminative_classifier.py:447] Embedded imagenet2012 image in 3 steps - ...[32768 17232     0]
I0125 01:17:32.675823 139866951023680 discriminative_classifier.py:449] Totalling 50000 image in 0.4s
I0125 01:17:32.675798 140581069126720 utils.py:427] TIMING[z/secs/eval/disclf]: 27.770738750929013
I0125 01:17:32.675900 139866951023680 discriminative_classifier.py:455] Dataset imagenet2012, results {'accuracy': 0.0011, 'correct': 55, 'count': 50000}
I0125 01:17:32.675776 139956134382656 utils.py:427] TIMING[z/secs/eval/disclf]: 27.771119676996022
I0125 01:17:32.675729 139959958596672 discriminative_classifier.py:447] Embedded imagenet2012 image in 3 steps - ...[32768 17232     0]
I0125 01:17:32.676080 139959958596672 discriminative_classifier.py:449] Totalling 50000 image in 0.7s
I0125 01:17:32.676175 139866951023680 utils.py:427] TIMING[z/secs/eval/disclf]: 27.770075303968042
I0125 01:17:32.676159 139959958596672 discriminative_classifier.py:455] Dataset imagenet2012, results {'accuracy': 0.0011, 'correct': 55, 'count': 50000}
I0125 01:17:32.676423 139959958596672 utils.py:427] TIMING[z/secs/eval/disclf]: 27.77127759810537
I0125 01:17:32.676597 140493899304000 discriminative_classifier.py:447] Embedded imagenet2012 image in 3 steps - ...[32768 17232     0]
I0125 01:17:32.676953 140493899304000 discriminative_classifier.py:449] Totalling 50000 image in 0.6s
I0125 01:17:32.677035 140493899304000 discriminative_classifier.py:455] Dataset imagenet2012, results {'accuracy': 0.0011, 'correct': 55, 'count': 50000}
I0125 01:17:32.677396 140493899304000 utils.py:427] TIMING[z/secs/eval/disclf]: 27.772851874120533
I0125 01:17:32.747477 140307309722688 utils.py:844] [35m[2][0m global_schedule = 0.0006249999860301614
I0125 01:17:33.409944 140307309722688 utils.py:844] [35m[2][0m training_loss = 10.512762069702148
I0125 01:17:33.410749 140307309722688 utils.py:844] [35m[2][0m l2_grad_cls = 2.05238676071167
I0125 01:17:33.411345 140307309722688 utils.py:844] [35m[2][0m l2_grad_embeding = 1.1890137195587158
I0125 01:17:33.411911 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_0 = 0.5377572774887085
I0125 01:17:33.412425 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_1 = 0.46582821011543274
I0125 01:17:33.412903 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_10 = 0.23510408401489258
I0125 01:17:33.413458 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_11 = 0.22724884748458862
I0125 01:17:33.413985 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_12 = 0.21821177005767822
I0125 01:17:33.414439 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_13 = 0.21393994987010956
I0125 01:17:33.414883 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_14 = 0.20357486605644226
I0125 01:17:33.415337 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_15 = 0.20133376121520996
I0125 01:17:33.415832 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_16 = 0.19132140278816223
I0125 01:17:33.416238 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_17 = 0.18845394253730774
I0125 01:17:33.416817 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_2 = 0.4193580150604248
I0125 01:17:33.417349 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_3 = 0.3643416464328766
I0125 01:17:33.417797 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_4 = 0.3306252062320709
I0125 01:17:33.418365 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_5 = 0.33210739493370056
I0125 01:17:33.418815 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_6 = 0.30272918939590454
I0125 01:17:33.419280 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_7 = 0.2744525969028473
I0125 01:17:33.419789 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_8 = 0.26111429929733276
I0125 01:17:33.420257 140307309722688 utils.py:844] [35m[2][0m l2_grad_encoderblock_9 = 0.24891452491283417
I0125 01:17:33.420814 140307309722688 utils.py:844] [35m[2][0m l2_grad_head = 1.334206223487854
I0125 01:17:33.421345 140307309722688 utils.py:844] [35m[2][0m l2_grads = 11.810163497924805
I0125 01:17:33.422028 140307309722688 utils.py:844] [35m[2][0m l2_params = 441.7431945800781
I0125 01:17:33.422587 140307309722688 utils.py:844] [35m[2][0m l2_updates = 0.008150698617100716
I0125 01:17:33.423096 140307309722688 utils.py:844] [35m[2][0m ncorrect = 0.0
I0125 01:17:33.423637 140307309722688 utils.py:844] [35m[2][0m nimg = 22.44195556640625
I0125 01:17:33.424115 140307309722688 utils.py:844] [35m[2][0m ntxt = 22.51654052734375
I0125 01:17:33.424774 140307309722688 utils.py:844] [35m[2][0m t = 14.285693168640137
I0125 01:17:33.425313 140307309722688 utils.py:844] [35m[2][0m t/parameter = 2.6592600345611572
I0125 01:17:33.425416 140307309722688 utils.py:844] [35m[2][0m uptime = 245.11271158210002
I0125 01:17:33.425476 140307309722688 utils.py:844] [35m[2][0m examples_seen = 65536.0
I0125 01:17:33.425529 140307309722688 utils.py:844] [35m[2][0m progress = 3.57053593744421e-05
I0125 01:17:33.425583 140307309722688 utils.py:844] [35m[2][0m epoch = 0.00024993898069448293
I0125 01:17:33.425630 140307309722688 main.py:119] [33mNOTE[0m: Steps:0/56014 [0.0%]
I0125 01:17:46.638065 140307309722688 utils.py:844] [35m[50][0m global_schedule = 0.0306249987334013
I0125 01:18:06.696316 140307309722688 utils.py:844] [35m[50][0m training_loss = 10.309473037719727
I0125 01:18:06.697817 140307309722688 utils.py:844] [35m[50][0m l2_grad_cls = 0.26011422276496887
I0125 01:18:06.698382 140307309722688 utils.py:844] [35m[50][0m l2_grad_embeding = 0.10422414541244507
I0125 01:18:06.699083 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_0 = 0.04591339826583862
I0125 01:18:06.699625 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_1 = 0.04042055830359459
I0125 01:18:06.700070 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_10 = 0.02443365380167961
I0125 01:18:06.700549 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_11 = 0.023947205394506454
I0125 01:18:06.701021 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_12 = 0.022920407354831696
I0125 01:18:06.701467 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_13 = 0.023115644231438637
I0125 01:18:06.701873 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_14 = 0.022632785141468048
I0125 01:18:06.702296 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_15 = 0.022667845711112022
I0125 01:18:06.702688 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_16 = 0.021830949932336807
I0125 01:18:06.703030 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_17 = 0.021939396858215332
I0125 01:18:06.703495 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_2 = 0.03714881092309952
I0125 01:18:06.703953 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_3 = 0.03249496966600418
I0125 01:18:06.704478 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_4 = 0.029695989564061165
I0125 01:18:06.704895 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_5 = 0.030129410326480865
I0125 01:18:06.705416 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_6 = 0.02898571640253067
I0125 01:18:06.705817 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_7 = 0.026624392718076706
I0125 01:18:06.706327 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_8 = 0.025483673438429832
I0125 01:18:06.706697 140307309722688 utils.py:844] [35m[50][0m l2_grad_encoderblock_9 = 0.02536490559577942
I0125 01:18:06.707194 140307309722688 utils.py:844] [35m[50][0m l2_grad_head = 0.17206227779388428
I0125 01:18:06.707613 140307309722688 utils.py:844] [35m[50][0m l2_grads = 1.4080578088760376
I0125 01:18:06.708129 140307309722688 utils.py:844] [35m[50][0m l2_params = 441.69500732421875
I0125 01:18:06.708520 140307309722688 utils.py:844] [35m[50][0m l2_updates = 0.07597565650939941
I0125 01:18:06.708916 140307309722688 utils.py:844] [35m[50][0m ncorrect = 6.103515625e-05
I0125 01:18:06.709283 140307309722688 utils.py:844] [35m[50][0m nimg = 26.580608367919922
I0125 01:18:06.709781 140307309722688 utils.py:844] [35m[50][0m ntxt = 25.170162200927734
I0125 01:18:06.710178 140307309722688 utils.py:844] [35m[50][0m t = 14.28271198272705
I0125 01:18:06.710633 140307309722688 utils.py:844] [35m[50][0m t/parameter = 2.6590511798858643
I0125 01:18:06.710744 140307309722688 utils.py:844] [35m[50][0m uptime = 278.3980384070892
I0125 01:18:06.710810 140307309722688 utils.py:844] [35m[50][0m examples_seen = 1638400.0
I0125 01:18:06.710862 140307309722688 utils.py:844] [35m[50][0m progress = 0.0008926339843610526
I0125 01:18:06.710912 140307309722688 utils.py:844] [35m[50][0m epoch = 0.006248474517362074
I0125 01:18:06.710964 140307309722688 utils.py:844] [35m[50][0m img/sec/core = 738.343358598162
I0125 01:18:06.711091 140307309722688 utils.py:844] [35m[50][0m core_hours_TPU v3 = 0.5917391435553631
I0125 01:18:06.711142 140307309722688 utils.py:844] [35m[50][0m core_hours = 0.5917391435553631
I0125 01:18:06.711224 140307309722688 main.py:119] [33mNOTE[0m: Steps:50/56014 [0.1%]
Walltime:4m38s (0s eval)
ETA:10h46m
Total train time:10h47m
I0125 01:18:20.830508 140307309722688 utils.py:844] [35m[100][0m global_schedule = 0.06187499687075615
I0125 01:18:41.434122 140307309722688 utils.py:844] [35m[100][0m training_loss = 9.956259727478027
I0125 01:18:41.435405 140307309722688 utils.py:844] [35m[100][0m l2_grad_cls = 1.1835355758666992
I0125 01:18:41.436187 140307309722688 utils.py:844] [35m[100][0m l2_grad_embeding = 0.5695021152496338
I0125 01:18:41.436828 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_0 = 0.24957388639450073
I0125 01:18:41.437293 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_1 = 0.19151531159877777
I0125 01:18:41.437841 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_10 = 0.04702114313840866
I0125 01:18:41.438296 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_11 = 0.04327043890953064
I0125 01:18:41.438831 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_12 = 0.04241826385259628
I0125 01:18:41.439405 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_13 = 0.04051841422915459
I0125 01:18:41.439976 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_14 = 0.037240348756313324
I0125 01:18:41.440486 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_15 = 0.03588394820690155
I0125 01:18:41.441061 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_16 = 0.03487268090248108
I0125 01:18:41.441524 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_17 = 0.034777089953422546
I0125 01:18:41.442027 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_2 = 0.15564702451229095
I0125 01:18:41.442551 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_3 = 0.12091391533613205
I0125 01:18:41.443107 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_4 = 0.09715502709150314
I0125 01:18:41.443610 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_5 = 0.0882451981306076
I0125 01:18:41.444049 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_6 = 0.07580778747797012
I0125 01:18:41.444564 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_7 = 0.0608186312019825
I0125 01:18:41.445025 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_8 = 0.054379694163799286
I0125 01:18:41.445450 140307309722688 utils.py:844] [35m[100][0m l2_grad_encoderblock_9 = 0.04980378970503807
I0125 01:18:41.446011 140307309722688 utils.py:844] [35m[100][0m l2_grad_head = 0.2343708872795105
I0125 01:18:41.446524 140307309722688 utils.py:844] [35m[100][0m l2_grads = 2.408679485321045
I0125 01:18:41.447087 140307309722688 utils.py:844] [35m[100][0m l2_params = 441.5655212402344
I0125 01:18:41.447611 140307309722688 utils.py:844] [35m[100][0m l2_updates = 0.1400211602449417
I0125 01:18:41.448185 140307309722688 utils.py:844] [35m[100][0m ncorrect = 6.103515625e-05
I0125 01:18:41.448645 140307309722688 utils.py:844] [35m[100][0m nimg = 28.882923126220703
I0125 01:18:41.449220 140307309722688 utils.py:844] [35m[100][0m ntxt = 27.040611267089844
I0125 01:18:41.449695 140307309722688 utils.py:844] [35m[100][0m t = 14.276830673217773
I0125 01:18:41.450242 140307309722688 utils.py:844] [35m[100][0m t/parameter = 2.6586391925811768
I0125 01:18:41.450350 140307309722688 utils.py:844] [35m[100][0m uptime = 313.1376446860377
I0125 01:18:41.450413 140307309722688 utils.py:844] [35m[100][0m examples_seen = 3276800.0
I0125 01:18:41.450462 140307309722688 utils.py:844] [35m[100][0m progress = 0.0017852679687221052
I0125 01:18:41.450507 140307309722688 utils.py:844] [35m[100][0m epoch = 0.012496949034724147
I0125 01:18:41.450555 140307309722688 utils.py:844] [35m[100][0m img/sec/core = 736.9110574955795
I0125 01:18:41.450678 140307309722688 utils.py:844] [35m[100][0m core_hours_TPU v3 = 1.209332144070003
I0125 01:18:41.450724 140307309722688 utils.py:844] [35m[100][0m core_hours = 1.209332144070003
I0125 01:18:41.450788 140307309722688 main.py:119] [33mNOTE[0m: Steps:100/56014 [0.2%]
Walltime:5m13s (0s eval)
ETA:10h46m
Total train time:10h48m
I0125 01:18:55.645172 140307309722688 utils.py:844] [35m[150][0m global_schedule = 0.09312500059604645
I0125 01:19:16.134465 140307309722688 utils.py:844] [35m[150][0m training_loss = 9.761112213134766
I0125 01:19:16.135706 140307309722688 utils.py:844] [35m[150][0m l2_grad_cls = 4.445138931274414
I0125 01:19:16.136394 140307309722688 utils.py:844] [35m[150][0m l2_grad_embeding = 2.298184394836426
I0125 01:19:16.136961 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_0 = 1.0303199291229248
I0125 01:19:16.137451 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_1 = 0.7766973376274109
I0125 01:19:16.137925 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_10 = 0.12118516862392426
I0125 01:19:16.138493 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_11 = 0.11487451940774918
I0125 01:19:16.139063 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_12 = 0.10920703411102295
I0125 01:19:16.139772 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_13 = 0.10791318863630295
I0125 01:19:16.140309 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_14 = 0.10385121405124664
I0125 01:19:16.140878 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_15 = 0.10133299231529236
I0125 01:19:16.141415 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_16 = 0.1004081517457962
I0125 01:19:16.141948 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_17 = 0.10022031515836716
I0125 01:19:16.142400 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_2 = 0.5973259806632996
I0125 01:19:16.142937 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_3 = 0.4307785630226135
I0125 01:19:16.143515 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_4 = 0.3201668858528137
I0125 01:19:16.143984 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_5 = 0.25877705216407776
I0125 01:19:16.144464 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_6 = 0.21096816658973694
I0125 01:19:16.144944 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_7 = 0.17158819735050201
I0125 01:19:16.145496 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_8 = 0.1512715071439743
I0125 01:19:16.145941 140307309722688 utils.py:844] [35m[150][0m l2_grad_encoderblock_9 = 0.13637878000736237
I0125 01:19:16.146426 140307309722688 utils.py:844] [35m[150][0m l2_grad_head = 0.7256057858467102
I0125 01:19:16.146863 140307309722688 utils.py:844] [35m[150][0m l2_grads = 8.889055252075195
I0125 01:19:16.147333 140307309722688 utils.py:844] [35m[150][0m l2_params = 441.36846923828125
I0125 01:19:16.147952 140307309722688 utils.py:844] [35m[150][0m l2_updates = 0.2161719650030136
I0125 01:19:16.148505 140307309722688 utils.py:844] [35m[150][0m ncorrect = 0.0
I0125 01:19:16.149063 140307309722688 utils.py:844] [35m[150][0m nimg = 29.095603942871094
I0125 01:19:16.149642 140307309722688 utils.py:844] [35m[150][0m ntxt = 28.852270126342773
I0125 01:19:16.150111 140307309722688 utils.py:844] [35m[150][0m t = 14.270320892333984
I0125 01:19:16.150565 140307309722688 utils.py:844] [35m[150][0m t/parameter = 2.6581833362579346
I0125 01:19:16.150679 140307309722688 utils.py:844] [35m[150][0m uptime = 347.83796751103364
I0125 01:19:16.150743 140307309722688 utils.py:844] [35m[150][0m examples_seen = 4915200.0
I0125 01:19:16.150792 140307309722688 utils.py:844] [35m[150][0m progress = 0.002677901953083158
I0125 01:19:16.150839 140307309722688 utils.py:844] [35m[150][0m epoch = 0.01874542355208622
I0125 01:19:16.150885 140307309722688 utils.py:844] [35m[150][0m img/sec/core = 737.7452979071234
I0125 01:19:16.151005 140307309722688 utils.py:844] [35m[150][0m core_hours_TPU v3 = 1.826226772069931
I0125 01:19:16.151052 140307309722688 utils.py:844] [35m[150][0m core_hours = 1.826226772069931
I0125 01:19:16.151114 140307309722688 main.py:119] [33mNOTE[0m: Steps:150/56014 [0.3%]
Walltime:5m48s (0s eval)
ETA:10h46m
Total train time:10h47m
I0125 01:19:30.443432 140307309722688 utils.py:844] [35m[200][0m global_schedule = 0.12437500059604645
I0125 01:19:50.832392 140307309722688 utils.py:844] [35m[200][0m training_loss = 9.465949058532715
I0125 01:19:50.834016 140307309722688 utils.py:844] [35m[200][0m l2_grad_cls = 2.8856077194213867
I0125 01:19:50.834615 140307309722688 utils.py:844] [35m[200][0m l2_grad_embeding = 1.2271541357040405
I0125 01:19:50.835269 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_0 = 0.5562513470649719
I0125 01:19:50.835746 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_1 = 0.3639671206474304
I0125 01:19:50.836182 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_10 = 0.05836406350135803
I0125 01:19:50.836779 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_11 = 0.05442257225513458
I0125 01:19:50.837318 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_12 = 0.05000416189432144
I0125 01:19:50.837823 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_13 = 0.04831397905945778
I0125 01:19:50.838247 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_14 = 0.04594383016228676
I0125 01:19:50.838673 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_15 = 0.0448368601500988
I0125 01:19:50.839093 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_16 = 0.04458890110254288
I0125 01:19:50.839666 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_17 = 0.04430138319730759
I0125 01:19:50.840113 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_2 = 0.2621293365955353
I0125 01:19:50.840530 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_3 = 0.19138328731060028
I0125 01:19:50.841069 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_4 = 0.14654186367988586
I0125 01:19:50.841611 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_5 = 0.11705628037452698
I0125 01:19:50.842056 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_6 = 0.09849531948566437
I0125 01:19:50.842612 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_7 = 0.08116354793310165
I0125 01:19:50.843147 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_8 = 0.07136392593383789
I0125 01:19:50.843589 140307309722688 utils.py:844] [35m[200][0m l2_grad_encoderblock_9 = 0.0660574808716774
I0125 01:19:50.844035 140307309722688 utils.py:844] [35m[200][0m l2_grad_head = 0.33088770508766174
I0125 01:19:50.844566 140307309722688 utils.py:844] [35m[200][0m l2_grads = 4.581153869628906
I0125 01:19:50.845090 140307309722688 utils.py:844] [35m[200][0m l2_params = 441.10736083984375
I0125 01:19:50.845484 140307309722688 utils.py:844] [35m[200][0m l2_updates = 0.2236170619726181
I0125 01:19:50.845904 140307309722688 utils.py:844] [35m[200][0m ncorrect = 3.0517578125e-05
I0125 01:19:50.846428 140307309722688 utils.py:844] [35m[200][0m nimg = 29.942039489746094
I0125 01:19:50.846984 140307309722688 utils.py:844] [35m[200][0m ntxt = 29.177228927612305
I0125 01:19:50.847556 140307309722688 utils.py:844] [35m[200][0m t = 14.266701698303223
I0125 01:19:50.848138 140307309722688 utils.py:844] [35m[200][0m t/parameter = 2.6579296588897705
I0125 01:19:50.848255 140307309722688 utils.py:844] [35m[200][0m uptime = 382.53554917592555
I0125 01:19:50.848328 140307309722688 utils.py:844] [35m[200][0m examples_seen = 6553600.0
I0125 01:19:50.848381 140307309722688 utils.py:844] [35m[200][0m progress = 0.0035705359374442105
I0125 01:19:50.848430 140307309722688 utils.py:844] [35m[200][0m epoch = 0.024993898069448295
I0125 01:19:50.848481 140307309722688 utils.py:844] [35m[200][0m img/sec/core = 737.8035808732708
I0125 01:19:50.848625 140307309722688 utils.py:844] [35m[200][0m core_hours_TPU v3 = 2.4430726683346764
I0125 01:19:50.848679 140307309722688 utils.py:844] [35m[200][0m core_hours = 2.4430726683346764
I0125 01:19:50.848755 140307309722688 main.py:119] [33mNOTE[0m: Steps:200/56014 [0.4%]
Walltime:6m23s (0s eval)
ETA:10h45m
Total train time:10h47m
I0125 01:20:05.026277 140307309722688 utils.py:844] [35m[250][0m global_schedule = 0.15562500059604645
I0125 01:20:25.551040 140307309722688 utils.py:844] [35m[250][0m training_loss = 9.265380859375
I0125 01:20:25.552065 140307309722688 utils.py:844] [35m[250][0m l2_grad_cls = 5.713597774505615
I0125 01:20:25.552840 140307309722688 utils.py:844] [35m[250][0m l2_grad_embeding = 1.7983410358428955
I0125 01:20:25.553422 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_0 = 0.5987347364425659
I0125 01:20:25.554028 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_1 = 0.3750588595867157
I0125 01:20:25.554507 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_10 = 0.05155292898416519
I0125 01:20:25.554975 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_11 = 0.04623110964894295
I0125 01:20:25.555460 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_12 = 0.043621670454740524
I0125 01:20:25.555924 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_13 = 0.04120350629091263
I0125 01:20:25.556386 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_14 = 0.039335865527391434
I0125 01:20:25.556797 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_15 = 0.03808069974184036
I0125 01:20:25.557337 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_16 = 0.03708215057849884
I0125 01:20:25.557880 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_17 = 0.03702164068818092
I0125 01:20:25.558304 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_2 = 0.252299964427948
I0125 01:20:25.558748 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_3 = 0.18224218487739563
I0125 01:20:25.559159 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_4 = 0.13751359283924103
I0125 01:20:25.559619 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_5 = 0.10952693969011307
I0125 01:20:25.560071 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_6 = 0.08861201256513596
I0125 01:20:25.560504 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_7 = 0.07405995577573776
I0125 01:20:25.560915 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_8 = 0.06563408672809601
I0125 01:20:25.561316 140307309722688 utils.py:844] [35m[250][0m l2_grad_encoderblock_9 = 0.05837530270218849
I0125 01:20:25.561716 140307309722688 utils.py:844] [35m[250][0m l2_grad_head = 0.31193751096725464
I0125 01:20:25.562125 140307309722688 utils.py:844] [35m[250][0m l2_grads = 6.8758721351623535
I0125 01:20:25.562655 140307309722688 utils.py:844] [35m[250][0m l2_params = 440.7991027832031
I0125 01:20:25.563205 140307309722688 utils.py:844] [35m[250][0m l2_updates = 0.2721897065639496
I0125 01:20:25.563658 140307309722688 utils.py:844] [35m[250][0m ncorrect = 6.103515625e-05
I0125 01:20:25.564079 140307309722688 utils.py:844] [35m[250][0m nimg = 30.499555587768555
I0125 01:20:25.564633 140307309722688 utils.py:844] [35m[250][0m ntxt = 29.569705963134766
I0125 01:20:25.565212 140307309722688 utils.py:844] [35m[250][0m t = 14.270936012268066
I0125 01:20:25.565661 140307309722688 utils.py:844] [35m[250][0m t/parameter = 2.658226490020752
I0125 01:20:25.565765 140307309722688 utils.py:844] [35m[250][0m uptime = 417.2530600770842
I0125 01:20:25.565830 140307309722688 utils.py:844] [35m[250][0m examples_seen = 8192000.0
I0125 01:20:25.565891 140307309722688 utils.py:844] [35m[250][0m progress = 0.004463169921805263
I0125 01:20:25.565939 140307309722688 utils.py:844] [35m[250][0m epoch = 0.031242372586810365
I0125 01:20:25.565988 140307309722688 utils.py:844] [35m[250][0m img/sec/core = 737.3800521841448
I0125 01:20:25.566125 140307309722688 utils.py:844] [35m[250][0m core_hours_TPU v3 = 3.060272862133053
I0125 01:20:25.566181 140307309722688 utils.py:844] [35m[250][0m core_hours = 3.060272862133053
I0125 01:20:25.566248 140307309722688 main.py:119] [33mNOTE[0m: Steps:250/56014 [0.4%]
Walltime:6m57s (0s eval)
ETA:10h45m
Total train time:10h48m
I0125 01:20:39.710311 140307309722688 utils.py:844] [35m[300][0m global_schedule = 0.18687500059604645
I0125 01:21:00.259194 140307309722688 utils.py:844] [35m[300][0m training_loss = 9.109678268432617
I0125 01:21:00.260443 140307309722688 utils.py:844] [35m[300][0m l2_grad_cls = 4.776937961578369
I0125 01:21:00.261075 140307309722688 utils.py:844] [35m[300][0m l2_grad_embeding = 2.0062129497528076
I0125 01:21:00.261689 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_0 = 0.7789252400398254
I0125 01:21:00.262238 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_1 = 0.57090163230896
I0125 01:21:00.262756 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_10 = 0.08162619918584824
I0125 01:21:00.263192 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_11 = 0.07342049479484558
I0125 01:21:00.263661 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_12 = 0.06645191460847855
I0125 01:21:00.264426 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_13 = 0.06178741529583931
I0125 01:21:00.264998 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_14 = 0.0576108954846859
I0125 01:21:00.265439 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_15 = 0.05634608119726181
I0125 01:21:00.265981 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_16 = 0.05285561457276344
I0125 01:21:00.266512 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_17 = 0.054104436188936234
I0125 01:21:00.267060 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_2 = 0.43786293268203735
I0125 01:21:00.267521 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_3 = 0.3448244035243988
I0125 01:21:00.267961 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_4 = 0.26830217242240906
I0125 01:21:00.268407 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_5 = 0.2080620974302292
I0125 01:21:00.268959 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_6 = 0.16353590786457062
I0125 01:21:00.269372 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_7 = 0.13370580971240997
I0125 01:21:00.269905 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_8 = 0.11160464584827423
I0125 01:21:00.270486 140307309722688 utils.py:844] [35m[300][0m l2_grad_encoderblock_9 = 0.09701523929834366
I0125 01:21:00.271066 140307309722688 utils.py:844] [35m[300][0m l2_grad_head = 0.43034854531288147
I0125 01:21:00.271552 140307309722688 utils.py:844] [35m[300][0m l2_grads = 6.588191509246826
I0125 01:21:00.272033 140307309722688 utils.py:844] [35m[300][0m l2_params = 440.4483947753906
I0125 01:21:00.272479 140307309722688 utils.py:844] [35m[300][0m l2_updates = 0.3657773733139038
I0125 01:21:00.272914 140307309722688 utils.py:844] [35m[300][0m ncorrect = 3.0517578125e-05
I0125 01:21:00.273350 140307309722688 utils.py:844] [35m[300][0m nimg = 30.711349487304688
I0125 01:21:00.273778 140307309722688 utils.py:844] [35m[300][0m ntxt = 29.724689483642578
I0125 01:21:00.274221 140307309722688 utils.py:844] [35m[300][0m t = 14.29069709777832
I0125 01:21:00.274638 140307309722688 utils.py:844] [35m[300][0m t/parameter = 2.6596100330352783
I0125 01:21:00.274749 140307309722688 utils.py:844] [35m[300][0m uptime = 451.9620430120267
I0125 01:21:00.274816 140307309722688 utils.py:844] [35m[300][0m examples_seen = 9830400.0
I0125 01:21:00.274883 140307309722688 utils.py:844] [35m[300][0m progress = 0.005355803906166316
I0125 01:21:00.274942 140307309722688 utils.py:844] [35m[300][0m epoch = 0.03749084710417244
I0125 01:21:00.274990 140307309722688 utils.py:844] [35m[300][0m img/sec/core = 737.5612258067
I0125 01:21:00.275117 140307309722688 utils.py:844] [35m[300][0m core_hours_TPU v3 = 3.677321447643141
I0125 01:21:00.275163 140307309722688 utils.py:844] [35m[300][0m core_hours = 3.677321447643141
I0125 01:21:00.275241 140307309722688 main.py:119] [33mNOTE[0m: Steps:300/56014 [0.5%]
Walltime:7m32s (0s eval)
ETA:10h44m
Total train time:10h48m
I0125 01:21:14.483299 140307309722688 utils.py:844] [35m[350][0m global_schedule = 0.21812500059604645
I0125 01:21:34.977117 140307309722688 utils.py:844] [35m[350][0m training_loss = 8.951194763183594
I0125 01:21:34.978600 140307309722688 utils.py:844] [35m[350][0m l2_grad_cls = 7.181154727935791
I0125 01:21:34.979374 140307309722688 utils.py:844] [35m[350][0m l2_grad_embeding = 2.5313475131988525
I0125 01:21:34.980053 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_0 = 0.8542829155921936
I0125 01:21:34.980603 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_1 = 0.5488003492355347
I0125 01:21:34.981228 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_10 = 0.07375636696815491
I0125 01:21:34.981699 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_11 = 0.06501435488462448
I0125 01:21:34.982270 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_12 = 0.06001429259777069
I0125 01:21:34.982888 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_13 = 0.053912967443466187
I0125 01:21:34.983500 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_14 = 0.04927318915724754
I0125 01:21:34.983974 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_15 = 0.04757784307003021
I0125 01:21:34.984482 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_16 = 0.04559670016169548
I0125 01:21:34.985072 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_17 = 0.0443480983376503
I0125 01:21:34.985537 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_2 = 0.3748653829097748
I0125 01:21:34.986006 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_3 = 0.2813241481781006
I0125 01:21:34.986475 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_4 = 0.21271875500679016
I0125 01:21:34.986981 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_5 = 0.1699201911687851
I0125 01:21:34.987605 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_6 = 0.1388939470052719
I0125 01:21:34.988060 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_7 = 0.11535809934139252
I0125 01:21:34.988627 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_8 = 0.09838446229696274
I0125 01:21:34.989237 140307309722688 utils.py:844] [35m[350][0m l2_grad_encoderblock_9 = 0.08569354563951492
I0125 01:21:34.989821 140307309722688 utils.py:844] [35m[350][0m l2_grad_head = 0.3912636935710907
I0125 01:21:34.990266 140307309722688 utils.py:844] [35m[350][0m l2_grads = 8.643799781799316
I0125 01:21:34.990828 140307309722688 utils.py:844] [35m[350][0m l2_params = 440.07769775390625
I0125 01:21:34.991447 140307309722688 utils.py:844] [35m[350][0m l2_updates = 0.4055320620536804
I0125 01:21:34.992037 140307309722688 utils.py:844] [35m[350][0m ncorrect = 0.000244140625
I0125 01:21:34.992499 140307309722688 utils.py:844] [35m[350][0m nimg = 31.053253173828125
I0125 01:21:34.993087 140307309722688 utils.py:844] [35m[350][0m ntxt = 29.72576141357422
I0125 01:21:34.993568 140307309722688 utils.py:844] [35m[350][0m t = 14.322818756103516
I0125 01:21:34.994096 140307309722688 utils.py:844] [35m[350][0m t/parameter = 2.6618552207946777
I0125 01:21:34.994227 140307309722688 utils.py:844] [35m[350][0m uptime = 486.6815108440351
I0125 01:21:34.994336 140307309722688 utils.py:844] [35m[350][0m examples_seen = 11468800.0
I0125 01:21:34.994421 140307309722688 utils.py:844] [35m[350][0m progress = 0.006248437890527368
I0125 01:21:34.994512 140307309722688 utils.py:844] [35m[350][0m epoch = 0.043739321621534516
I0125 01:21:34.994606 140307309722688 utils.py:844] [35m[350][0m img/sec/core = 737.3384904361636
I0125 01:21:34.994802 140307309722688 utils.py:844] [35m[350][0m core_hours_TPU v3 = 4.29455643132329
I0125 01:21:34.994881 140307309722688 utils.py:844] [35m[350][0m core_hours = 4.29455643132329
I0125 01:21:34.994989 140307309722688 main.py:119] [33mNOTE[0m: Steps:350/56014 [0.6%]
Walltime:8m7s (0s eval)
ETA:10h43m
Total train time:10h48m
I0125 01:21:49.205570 140307309722688 utils.py:844] [35m[400][0m global_schedule = 0.24937500059604645
I0125 01:22:09.697768 140307309722688 utils.py:844] [35m[400][0m training_loss = 8.75680923461914
I0125 01:22:09.699258 140307309722688 utils.py:844] [35m[400][0m l2_grad_cls = 3.3455452919006348
I0125 01:22:09.700017 140307309722688 utils.py:844] [35m[400][0m l2_grad_embeding = 1.619807243347168
I0125 01:22:09.700569 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_0 = 0.5555894374847412
I0125 01:22:09.701012 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_1 = 0.41064971685409546
I0125 01:22:09.701562 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_10 = 0.04969032481312752
I0125 01:22:09.702012 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_11 = 0.04415883123874664
I0125 01:22:09.702504 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_12 = 0.040470559149980545
I0125 01:22:09.703142 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_13 = 0.036867257207632065
I0125 01:22:09.703674 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_14 = 0.03455333411693573
I0125 01:22:09.704102 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_15 = 0.03293280303478241
I0125 01:22:09.704593 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_16 = 0.03129039332270622
I0125 01:22:09.705152 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_17 = 0.03104196861386299
I0125 01:22:09.705685 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_2 = 0.2949328124523163
I0125 01:22:09.706100 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_3 = 0.21079379320144653
I0125 01:22:09.706597 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_4 = 0.15686272084712982
I0125 01:22:09.707205 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_5 = 0.11737523227930069
I0125 01:22:09.707666 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_6 = 0.09467402845621109
I0125 01:22:09.708086 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_7 = 0.07617899030447006
I0125 01:22:09.708594 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_8 = 0.0639021173119545
I0125 01:22:09.709188 140307309722688 utils.py:844] [35m[400][0m l2_grad_encoderblock_9 = 0.05653826519846916
I0125 01:22:09.709814 140307309722688 utils.py:844] [35m[400][0m l2_grad_head = 0.25395631790161133
I0125 01:22:09.710247 140307309722688 utils.py:844] [35m[400][0m l2_grads = 4.51914119720459
I0125 01:22:09.710774 140307309722688 utils.py:844] [35m[400][0m l2_params = 439.68792724609375
I0125 01:22:09.711320 140307309722688 utils.py:844] [35m[400][0m l2_updates = 0.44808682799339294
I0125 01:22:09.711873 140307309722688 utils.py:844] [35m[400][0m ncorrect = 0.000152587890625
I0125 01:22:09.712282 140307309722688 utils.py:844] [35m[400][0m nimg = 31.11556625366211
I0125 01:22:09.712769 140307309722688 utils.py:844] [35m[400][0m ntxt = 29.691648483276367
I0125 01:22:09.713231 140307309722688 utils.py:844] [35m[400][0m t = 14.388079643249512
I0125 01:22:09.713676 140307309722688 utils.py:844] [35m[400][0m t/parameter = 2.666400909423828
I0125 01:22:09.713809 140307309722688 utils.py:844] [35m[400][0m uptime = 521.4011033158749
I0125 01:22:09.713876 140307309722688 utils.py:844] [35m[400][0m examples_seen = 13107200.0
I0125 01:22:09.713928 140307309722688 utils.py:844] [35m[400][0m progress = 0.007141071874888421
I0125 01:22:09.713975 140307309722688 utils.py:844] [35m[400][0m epoch = 0.04998779613889659
I0125 01:22:09.714025 140307309722688 utils.py:844] [35m[400][0m img/sec/core = 737.335843465429
I0125 01:22:09.714160 140307309722688 utils.py:844] [35m[400][0m core_hours_TPU v3 = 4.9117936308226655
I0125 01:22:09.714211 140307309722688 utils.py:844] [35m[400][0m core_hours = 4.9117936308226655
I0125 01:22:09.714278 140307309722688 main.py:119] [33mNOTE[0m: Steps:400/56014 [0.7%]
Walltime:8m41s (0s eval)
ETA:10h43m
Total train time:10h48m
I0125 01:22:23.905302 140307309722688 utils.py:844] [35m[450][0m global_schedule = 0.28062498569488525
I0125 01:22:44.416703 140307309722688 utils.py:844] [35m[450][0m training_loss = 8.715189933776855
I0125 01:22:44.418204 140307309722688 utils.py:844] [35m[450][0m l2_grad_cls = 2.0129871368408203
I0125 01:22:44.418889 140307309722688 utils.py:844] [35m[450][0m l2_grad_embeding = 1.2477186918258667
I0125 01:22:44.434046 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_0 = 0.36679330468177795
I0125 01:22:44.434749 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_1 = 0.2694185972213745
I0125 01:22:44.442149 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_10 = 0.04303107038140297
I0125 01:22:44.443118 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_11 = 0.03790592402219772
I0125 01:22:44.446891 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_12 = 0.03537469357252121
I0125 01:22:44.454701 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_13 = 0.03280114755034447
I0125 01:22:44.458811 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_14 = 0.03061906434595585
I0125 01:22:44.459663 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_15 = 0.029029233381152153
I0125 01:22:44.460147 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_16 = 0.028238048776984215
I0125 01:22:44.460610 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_17 = 0.026816098019480705
I0125 01:22:44.461117 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_2 = 0.19138017296791077
I0125 01:22:44.461556 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_3 = 0.14487747848033905
I0125 01:22:44.462033 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_4 = 0.1115608811378479
I0125 01:22:44.462451 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_5 = 0.09059185534715652
I0125 01:22:44.463066 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_6 = 0.07497423142194748
I0125 01:22:44.463544 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_7 = 0.06179974973201752
I0125 01:22:44.463986 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_8 = 0.05417351797223091
I0125 01:22:44.464414 140307309722688 utils.py:844] [35m[450][0m l2_grad_encoderblock_9 = 0.04850535839796066
I0125 01:22:44.464966 140307309722688 utils.py:844] [35m[450][0m l2_grad_head = 0.3005354702472687
I0125 01:22:44.465391 140307309722688 utils.py:844] [35m[450][0m l2_grads = 3.243464708328247
I0125 01:22:44.465793 140307309722688 utils.py:844] [35m[450][0m l2_params = 439.3037109375
I0125 01:22:44.466236 140307309722688 utils.py:844] [35m[450][0m l2_updates = 0.5140893459320068
I0125 01:22:44.466776 140307309722688 utils.py:844] [35m[450][0m ncorrect = 0.00018310546875
I0125 01:22:44.467182 140307309722688 utils.py:844] [35m[450][0m nimg = 31.864225387573242
I0125 01:22:44.467626 140307309722688 utils.py:844] [35m[450][0m ntxt = 29.96029281616211
I0125 01:22:44.468069 140307309722688 utils.py:844] [35m[450][0m t = 14.457817077636719
I0125 01:22:44.468496 140307309722688 utils.py:844] [35m[450][0m t/parameter = 2.671236038208008
I0125 01:22:44.468596 140307309722688 utils.py:844] [35m[450][0m uptime = 556.1558920410462
I0125 01:22:44.468657 140307309722688 utils.py:844] [35m[450][0m examples_seen = 14745600.0
I0125 01:22:44.468704 140307309722688 utils.py:844] [35m[450][0m progress = 0.008033705859249474
I0125 01:22:44.468758 140307309722688 utils.py:844] [35m[450][0m epoch = 0.056236270656258656
I0125 01:22:44.468805 140307309722688 utils.py:844] [35m[450][0m img/sec/core = 736.589141785205
I0125 01:22:44.468937 140307309722688 utils.py:844] [35m[450][0m core_hours_TPU v3 = 5.5296565414923755
I0125 01:22:44.468985 140307309722688 utils.py:844] [35m[450][0m core_hours = 5.5296565414923755
I0125 01:22:44.469049 140307309722688 main.py:119] [33mNOTE[0m: Steps:450/56014 [0.8%]
Walltime:9m16s (0s eval)
ETA:10h42m
Total train time:10h48m
I0125 01:22:58.680627 140307309722688 utils.py:844] [35m[500][0m global_schedule = 0.31187498569488525
I0125 01:23:19.146878 140307309722688 utils.py:844] [35m[500][0m training_loss = 8.51384162902832
I0125 01:23:19.148086 140307309722688 utils.py:844] [35m[500][0m l2_grad_cls = 2.729520797729492
I0125 01:23:19.148802 140307309722688 utils.py:844] [35m[500][0m l2_grad_embeding = 1.2740263938903809
I0125 01:23:19.149437 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_0 = 0.44345709681510925
I0125 01:23:19.149910 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_1 = 0.28637316823005676
I0125 01:23:19.150469 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_10 = 0.04760933667421341
I0125 01:23:19.150904 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_11 = 0.042474329471588135
I0125 01:23:19.151331 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_12 = 0.03927658870816231
I0125 01:23:19.151762 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_13 = 0.03697735443711281
I0125 01:23:19.152247 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_14 = 0.034028999507427216
I0125 01:23:19.152682 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_15 = 0.0323752835392952
I0125 01:23:19.153114 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_16 = 0.030014796182513237
I0125 01:23:19.153555 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_17 = 0.029727773740887642
I0125 01:23:19.154004 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_2 = 0.20101958513259888
I0125 01:23:19.154439 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_3 = 0.15159501135349274
I0125 01:23:19.154877 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_4 = 0.12064023315906525
I0125 01:23:19.155321 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_5 = 0.10109558701515198
I0125 01:23:19.155732 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_6 = 0.08288156241178513
I0125 01:23:19.156162 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_7 = 0.07013434171676636
I0125 01:23:19.156565 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_8 = 0.06033613532781601
I0125 01:23:19.156991 140307309722688 utils.py:844] [35m[500][0m l2_grad_encoderblock_9 = 0.05508150905370712
I0125 01:23:19.157539 140307309722688 utils.py:844] [35m[500][0m l2_grad_head = 0.30544713139533997
I0125 01:23:19.158057 140307309722688 utils.py:844] [35m[500][0m l2_grads = 4.1329121589660645
I0125 01:23:19.158460 140307309722688 utils.py:844] [35m[500][0m l2_params = 438.9209289550781
I0125 01:23:19.158925 140307309722688 utils.py:844] [35m[500][0m l2_updates = 0.5563822984695435
I0125 01:23:19.159496 140307309722688 utils.py:844] [35m[500][0m ncorrect = 0.000244140625
I0125 01:23:19.159902 140307309722688 utils.py:844] [35m[500][0m nimg = 31.67923927307129
I0125 01:23:19.160305 140307309722688 utils.py:844] [35m[500][0m ntxt = 29.37689208984375
I0125 01:23:19.160747 140307309722688 utils.py:844] [35m[500][0m t = 14.580059051513672
I0125 01:23:19.161173 140307309722688 utils.py:844] [35m[500][0m t/parameter = 2.679654359817505
I0125 01:23:19.161289 140307309722688 utils.py:844] [35m[500][0m uptime = 590.8485756020527
I0125 01:23:19.161379 140307309722688 utils.py:844] [35m[500][0m examples_seen = 16384000.0
I0125 01:23:19.161450 140307309722688 utils.py:844] [35m[500][0m progress = 0.008926339843610525
I0125 01:23:19.161531 140307309722688 utils.py:844] [35m[500][0m epoch = 0.06248474517362073
I0125 01:23:19.161607 140307309722688 utils.py:844] [35m[500][0m img/sec/core = 737.9077480409604
I0125 01:23:19.161779 140307309722688 utils.py:844] [35m[500][0m core_hours_TPU v3 = 6.146415360354714
I0125 01:23:19.161846 140307309722688 utils.py:844] [35m[500][0m core_hours = 6.146415360354714
I0125 01:23:19.161967 140307309722688 main.py:119] [33mNOTE[0m: Steps:500/56014 [0.9%]
Walltime:9m51s (0s eval)
ETA:10h42m
Total train time:10h48m
I0125 01:23:33.383365 140307309722688 utils.py:844] [35m[550][0m global_schedule = 0.34312498569488525
I0125 01:23:53.863726 140307309722688 utils.py:844] [35m[550][0m training_loss = 8.346927642822266
I0125 01:23:53.864699 140307309722688 utils.py:844] [35m[550][0m l2_grad_cls = 1.860252022743225
I0125 01:23:53.865294 140307309722688 utils.py:844] [35m[550][0m l2_grad_embeding = 1.1883214712142944
I0125 01:23:53.865766 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_0 = 0.3430244028568268
I0125 01:23:53.866239 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_1 = 0.24377106130123138
I0125 01:23:53.866823 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_10 = 0.03472232446074486
I0125 01:23:53.867261 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_11 = 0.031224029138684273
I0125 01:23:53.867713 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_12 = 0.02861751616001129
I0125 01:23:53.868179 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_13 = 0.02717369608581066
I0125 01:23:53.868760 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_14 = 0.02523358166217804
I0125 01:23:53.869274 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_15 = 0.024026118218898773
I0125 01:23:53.869662 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_16 = 0.022957883775234222
I0125 01:23:53.870040 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_17 = 0.022103384137153625
I0125 01:23:53.870553 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_2 = 0.16904187202453613
I0125 01:23:53.870935 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_3 = 0.1228063553571701
I0125 01:23:53.871303 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_4 = 0.09284499287605286
I0125 01:23:53.871741 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_5 = 0.07437634468078613
I0125 01:23:53.872149 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_6 = 0.059955742210149765
I0125 01:23:53.872568 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_7 = 0.04984375461935997
I0125 01:23:53.872929 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_8 = 0.04353134706616402
I0125 01:23:53.873281 140307309722688 utils.py:844] [35m[550][0m l2_grad_encoderblock_9 = 0.0383186973631382
I0125 01:23:53.873642 140307309722688 utils.py:844] [35m[550][0m l2_grad_head = 0.21480605006217957
I0125 01:23:53.874054 140307309722688 utils.py:844] [35m[550][0m l2_grads = 2.8645777702331543
I0125 01:23:53.874443 140307309722688 utils.py:844] [35m[550][0m l2_params = 438.5637512207031
I0125 01:23:53.874819 140307309722688 utils.py:844] [35m[550][0m l2_updates = 0.5656459331512451
I0125 01:23:53.875200 140307309722688 utils.py:844] [35m[550][0m ncorrect = 0.00018310546875
I0125 01:23:53.875605 140307309722688 utils.py:844] [35m[550][0m nimg = 31.6014347076416
I0125 01:23:53.875993 140307309722688 utils.py:844] [35m[550][0m ntxt = 29.376251220703125
I0125 01:23:53.876403 140307309722688 utils.py:844] [35m[550][0m t = 14.72622299194336
I0125 01:23:53.877117 140307309722688 utils.py:844] [35m[550][0m t/parameter = 2.689631700515747
I0125 01:23:53.877230 140307309722688 utils.py:844] [35m[550][0m uptime = 625.5645275348797
I0125 01:23:53.877287 140307309722688 utils.py:844] [35m[550][0m examples_seen = 18022400.0
I0125 01:23:53.877331 140307309722688 utils.py:844] [35m[550][0m progress = 0.009818973827971578
I0125 01:23:53.877372 140307309722688 utils.py:844] [35m[550][0m epoch = 0.06873321969098281
I0125 01:23:53.877416 140307309722688 utils.py:844] [35m[550][0m img/sec/core = 737.4131652657616
I0125 01:23:53.877538 140307309722688 utils.py:844] [35m[550][0m core_hours_TPU v3 = 6.763587839160528
I0125 01:23:53.877582 140307309722688 utils.py:844] [35m[550][0m core_hours = 6.763587839160528
I0125 01:23:53.877641 140307309722688 main.py:119] [33mNOTE[0m: Steps:550/56014 [1.0%]
Walltime:10m26s (0s eval)
ETA:10h41m
Total train time:10h48m
I0125 01:24:08.076443 140307309722688 utils.py:844] [35m[600][0m global_schedule = 0.37437498569488525
I0125 01:24:28.562350 140307309722688 utils.py:844] [35m[600][0m training_loss = 8.231414794921875
I0125 01:24:28.563741 140307309722688 utils.py:844] [35m[600][0m l2_grad_cls = 2.150381088256836
I0125 01:24:28.564328 140307309722688 utils.py:844] [35m[600][0m l2_grad_embeding = 1.5826760530471802
I0125 01:24:28.564879 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_0 = 0.3920046091079712
I0125 01:24:28.565310 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_1 = 0.2716537117958069
I0125 01:24:28.565879 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_10 = 0.04039831832051277
I0125 01:24:28.566312 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_11 = 0.03547158092260361
I0125 01:24:28.566757 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_12 = 0.03374020755290985
I0125 01:24:28.567199 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_13 = 0.03062332421541214
I0125 01:24:28.567677 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_14 = 0.02894888073205948
I0125 01:24:28.568130 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_15 = 0.026912659406661987
I0125 01:24:28.568537 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_16 = 0.025195054709911346
I0125 01:24:28.568967 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_17 = 0.02486708201467991
I0125 01:24:28.569486 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_2 = 0.19698458909988403
I0125 01:24:28.569927 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_3 = 0.1460796296596527
I0125 01:24:28.570349 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_4 = 0.11394479870796204
I0125 01:24:28.570756 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_5 = 0.09209641069173813
I0125 01:24:28.571200 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_6 = 0.07305596768856049
I0125 01:24:28.571682 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_7 = 0.06314337998628616
I0125 01:24:28.572087 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_8 = 0.052356474101543427
I0125 01:24:28.572480 140307309722688 utils.py:844] [35m[600][0m l2_grad_encoderblock_9 = 0.04601910337805748
I0125 01:24:28.573023 140307309722688 utils.py:844] [35m[600][0m l2_grad_head = 0.25524356961250305
I0125 01:24:28.573447 140307309722688 utils.py:844] [35m[600][0m l2_grads = 3.4243247509002686
I0125 01:24:28.573875 140307309722688 utils.py:844] [35m[600][0m l2_params = 438.2232971191406
I0125 01:24:28.574302 140307309722688 utils.py:844] [35m[600][0m l2_updates = 0.682734489440918
I0125 01:24:28.574724 140307309722688 utils.py:844] [35m[600][0m ncorrect = 0.000396728515625
I0125 01:24:28.575158 140307309722688 utils.py:844] [35m[600][0m nimg = 31.29742431640625
I0125 01:24:28.575574 140307309722688 utils.py:844] [35m[600][0m ntxt = 29.562559127807617
I0125 01:24:28.576005 140307309722688 utils.py:844] [35m[600][0m t = 14.939851760864258
I0125 01:24:28.576553 140307309722688 utils.py:844] [35m[600][0m t/parameter = 2.704031467437744
I0125 01:24:28.576662 140307309722688 utils.py:844] [35m[600][0m uptime = 660.2639538729563
I0125 01:24:28.576746 140307309722688 utils.py:844] [35m[600][0m examples_seen = 19660800.0
I0125 01:24:28.576799 140307309722688 utils.py:844] [35m[600][0m progress = 0.010711607812332631
I0125 01:24:28.576859 140307309722688 utils.py:844] [35m[600][0m epoch = 0.07498169420834488
I0125 01:24:28.576911 140307309722688 utils.py:844] [35m[600][0m img/sec/core = 737.7643581360435
I0125 01:24:28.577055 140307309722688 utils.py:844] [35m[600][0m core_hours_TPU v3 = 7.380466529615223
I0125 01:24:28.577107 140307309722688 utils.py:844] [35m[600][0m core_hours = 7.380466529615223
I0125 01:24:28.577175 140307309722688 main.py:119] [33mNOTE[0m: Steps:600/56014 [1.1%]
Walltime:11m0s (0s eval)
ETA:10h41m
Total train time:10h48m
I0125 01:24:42.753563 140307309722688 utils.py:844] [35m[650][0m global_schedule = 0.40562498569488525
I0125 01:25:03.264601 140307309722688 utils.py:844] [35m[650][0m training_loss = 8.153020858764648
I0125 01:25:03.266013 140307309722688 utils.py:844] [35m[650][0m l2_grad_cls = 2.0119450092315674
I0125 01:25:03.266668 140307309722688 utils.py:844] [35m[650][0m l2_grad_embeding = 1.0804073810577393
I0125 01:25:03.267198 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_0 = 0.4866461157798767
I0125 01:25:03.267695 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_1 = 0.37817442417144775
I0125 01:25:03.268168 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_10 = 0.050810638815164566
I0125 01:25:03.268609 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_11 = 0.04450206458568573
I0125 01:25:03.269051 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_12 = 0.04097766429185867
I0125 01:25:03.269505 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_13 = 0.0370342880487442
I0125 01:25:03.269967 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_14 = 0.034857604652643204
I0125 01:25:03.270375 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_15 = 0.03239487484097481
I0125 01:25:03.270766 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_16 = 0.030163094401359558
I0125 01:25:03.271163 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_17 = 0.03013562224805355
I0125 01:25:03.271606 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_2 = 0.2703627943992615
I0125 01:25:03.272000 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_3 = 0.1985088586807251
I0125 01:25:03.272372 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_4 = 0.15334826707839966
I0125 01:25:03.272743 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_5 = 0.1184098869562149
I0125 01:25:03.273137 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_6 = 0.09047631919384003
I0125 01:25:03.273542 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_7 = 0.07766474038362503
I0125 01:25:03.274035 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_8 = 0.06465889513492584
I0125 01:25:03.274558 140307309722688 utils.py:844] [35m[650][0m l2_grad_encoderblock_9 = 0.05756088346242905
I0125 01:25:03.275093 140307309722688 utils.py:844] [35m[650][0m l2_grad_head = 0.31881991028785706
I0125 01:25:03.275548 140307309722688 utils.py:844] [35m[650][0m l2_grads = 3.450448989868164
I0125 01:25:03.275983 140307309722688 utils.py:844] [35m[650][0m l2_params = 437.93780517578125
I0125 01:25:03.276509 140307309722688 utils.py:844] [35m[650][0m l2_updates = 0.7815645337104797
I0125 01:25:03.276955 140307309722688 utils.py:844] [35m[650][0m ncorrect = 0.000335693359375
I0125 01:25:03.277384 140307309722688 utils.py:844] [35m[650][0m nimg = 32.009521484375
I0125 01:25:03.277808 140307309722688 utils.py:844] [35m[650][0m ntxt = 29.559783935546875
I0125 01:25:03.278377 140307309722688 utils.py:844] [35m[650][0m t = 15.180397033691406
I0125 01:25:03.278882 140307309722688 utils.py:844] [35m[650][0m t/parameter = 2.7200045585632324
I0125 01:25:03.278988 140307309722688 utils.py:844] [35m[650][0m uptime = 694.9662835430354
I0125 01:25:03.279052 140307309722688 utils.py:844] [35m[650][0m examples_seen = 21299200.0
I0125 01:25:03.279119 140307309722688 utils.py:844] [35m[650][0m progress = 0.011604241796693684
I0125 01:25:03.279168 140307309722688 utils.py:844] [35m[650][0m epoch = 0.08123016872570696
I0125 01:25:03.279230 140307309722688 utils.py:844] [35m[650][0m img/sec/core = 737.7026338975957
I0125 01:25:03.279369 140307309722688 utils.py:844] [35m[650][0m core_hours_TPU v3 = 7.997396834861074
I0125 01:25:03.279422 140307309722688 utils.py:844] [35m[650][0m core_hours = 7.997396834861074
I0125 01:25:03.279491 140307309722688 main.py:119] [33mNOTE[0m: Steps:650/56014 [1.2%]
Walltime:11m35s (0s eval)
ETA:10h40m
Total train time:10h48m
