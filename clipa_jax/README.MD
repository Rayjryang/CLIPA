## An Inverse Scaling Law for CLIP Training

This repo contains official JAX implementation of **CLIPA** in our paper: [An Inverse Scaling Law for CLIP Training]() 


<p align="center">
  <img src="figs/inverse_scaling_law.png" width="1080">
Overview of the Inverse Scaling Law: larger image/text encoders
enable training with fewer image/text tokens while maintaining competitive performance
</p>



### License
This project is under the  Apache 2.0 License.


### Acknowledgement

This project is built on [big vision](https://github.com/google-research/big_vision). Thanks for their contribution and delicate works!

### Contact
If you have any question, please feel free to raise an issue or contact us directily: 
Xianhang Li: xli421@ucsc.edu ;
Zeyu Wang:  zwang615@ucsc.edu
